{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc119a1-28bd-47af-8a5d-38204c005bdf",
   "metadata": {},
   "source": [
    "## 01. Imports & Dataset Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba165936-c2d9-4dd5-b388-62912b63f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import optuna\n",
    "import json\n",
    "import hashlib\n",
    "import joblib\n",
    "import warnings\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Setup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "ASSET_TYPE = \"property\"\n",
    "DATA_PATH = os.environ.get(\"DATA_PATH\", \"../data/df_cleaned_no_outliers.csv\")\n",
    "MODEL_BASE_DIR = \"../models\"\n",
    "\n",
    "ASSET_CONFIG = {\n",
    "    \"property\": {\n",
    "        \"target\": \"valuation_k\",\n",
    "        \"categorical\": [\n",
    "            \"location\", \"energy_class\", \"has_elevator\", \"has_garden\",\n",
    "            \"has_balcony\", \"garage\", \"owner_occupied\", \"public_transport_nearby\"\n",
    "        ],\n",
    "        \"numeric\": [\n",
    "            \"size_m2\", \"rooms\", \"bathrooms\", \"year_built\", \"floor\", \"building_floors\",\n",
    "            \"humidity_level\", \"temperature_avg\", \"noise_level\", \"air_quality_index\",\n",
    "            \"luxury_score\", \"env_score\", \"distance_to_center_km\", \"valuation_k\",\n",
    "            \"last_verified_ts\"\n",
    "        ],\n",
    "        \"exclude\": [\n",
    "            \"asset_id\", \"asset_type\", \"condition_score\", \"risk_score\",\n",
    "            \"prediction_ts\", \"age_years\", \"age_category\", \"luxury_category\", \"value_segment\", \"timestamp\"\n",
    "        ],\n",
    "    },\n",
    "    \"art\": {\"target\": \"valuation_k\", \"categorical\": [], \"numeric\": [], \"exclude\": []},\n",
    "}\n",
    "\n",
    "assert ASSET_TYPE in ASSET_CONFIG, f\"Unknown asset_type: {ASSET_TYPE}\"\n",
    "cfg = ASSET_CONFIG[ASSET_TYPE]\n",
    "cfg[\"numeric\"] = [c for c in cfg[\"numeric\"] if c not in [\"last_verified_ts\", \"valuation_k\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f3f96-b7be-48ff-a9b2-2c9b9569cb63",
   "metadata": {},
   "source": [
    "## 02. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38892f35-5a7d-488c-83d2-a99bca1e6fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:50:35,329 [INFO] üì• Loaded dataset: ../data/df_cleaned_no_outliers.csv | Shape: (4929, 49)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "logging.info(f\"üì• Loaded dataset: {DATA_PATH} | Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb911ba4-7659-4d24-ac3d-301abbce6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:50:35,650 [INFO] ‚öôÔ∏è Ensuring required engineered features...\n"
     ]
    }
   ],
   "source": [
    "# Ensure important engineered features are present\n",
    "logging.info(\"‚öôÔ∏è Ensuring required engineered features...\")\n",
    "\n",
    "if \"age_years\" not in df.columns and \"year_built\" in df.columns:\n",
    "    current_year = datetime.utcnow().year\n",
    "    df[\"age_years\"] = current_year - df[\"year_built\"]\n",
    "\n",
    "if \"price_per_sqm\" not in df.columns:\n",
    "    df[\"price_per_sqm\"] = df[\"valuation_k\"] * 1000 / df[\"size_m2\"]\n",
    "\n",
    "if \"luxury_score\" not in df.columns:\n",
    "    df[\"luxury_score\"] = (df[\"has_garden\"] + df[\"has_balcony\"] + df[\"garage\"]) / 3\n",
    "\n",
    "if \"efficiency_score\" not in df.columns:\n",
    "    df[\"efficiency_score\"] = (\n",
    "        (df[\"valuation_k\"] / df[\"size_m2\"]) * (1 + df[\"luxury_score\"])\n",
    "    )\n",
    "\n",
    "df = df.drop(columns=[\"efficiency_score\", \"price_per_sqm\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c1d08-0b0e-4ed0-bbd9-94c27b0909e3",
   "metadata": {},
   "source": [
    "## 03. Normalization / Derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e773326-72f1-480d-8473-b685af965df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:50:36,158 [INFO] ‚úÖ Dataset ready | Shape: (4929, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>region</th>\n",
       "      <th>urban_type</th>\n",
       "      <th>size_m2</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_floors</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_room_size</th>\n",
       "      <th>location_premium</th>\n",
       "      <th>amenity_count</th>\n",
       "      <th>price_vs_region_avg</th>\n",
       "      <th>size_bin</th>\n",
       "      <th>days_since_verification</th>\n",
       "      <th>hours_since_verification</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>anomaly_flag</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catania</td>\n",
       "      <td>south</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1964</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988797</td>\n",
       "      <td>(135.4, 151.3]</td>\n",
       "      <td>57</td>\n",
       "      <td>1385.142305</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florence</td>\n",
       "      <td>center</td>\n",
       "      <td>urban</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.431235</td>\n",
       "      <td>(87.7, 103.6]</td>\n",
       "      <td>45</td>\n",
       "      <td>1100.792305</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naples</td>\n",
       "      <td>south</td>\n",
       "      <td>urban</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>(39.841, 55.9]</td>\n",
       "      <td>44</td>\n",
       "      <td>1069.408971</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trieste</td>\n",
       "      <td>northeast</td>\n",
       "      <td>semiurban</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.369051</td>\n",
       "      <td>(119.5, 135.4]</td>\n",
       "      <td>22</td>\n",
       "      <td>547.325638</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turin</td>\n",
       "      <td>north</td>\n",
       "      <td>urban</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203781</td>\n",
       "      <td>(39.841, 55.9]</td>\n",
       "      <td>53</td>\n",
       "      <td>1292.708971</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   location     region urban_type  size_m2  rooms  bathrooms  year_built  \\\n",
       "0   Catania      south  semiurban      142      5          1        1964   \n",
       "1  Florence     center      urban       92      3          2        1987   \n",
       "2    Naples      south      urban       54      4          3        2013   \n",
       "3   Trieste  northeast  semiurban      129      6          2        2009   \n",
       "4     Turin      north      urban       43      6          3        1967   \n",
       "\n",
       "   floor  building_floors  has_elevator  ...  avg_room_size  location_premium  \\\n",
       "0      2                7             1  ...      28.400000               1.0   \n",
       "1      1                9             1  ...      30.666667               1.2   \n",
       "2      0                3             0  ...      13.500000               1.2   \n",
       "3      3                8             1  ...      21.500000               1.0   \n",
       "4      1                5             1  ...       7.166667               1.2   \n",
       "\n",
       "   amenity_count  price_vs_region_avg        size_bin  \\\n",
       "0              3             0.988797  (135.4, 151.3]   \n",
       "1              3             0.431235   (87.7, 103.6]   \n",
       "2              1             0.633951  (39.841, 55.9]   \n",
       "3              3             1.369051  (119.5, 135.4]   \n",
       "4              1             0.203781  (39.841, 55.9]   \n",
       "\n",
       "   days_since_verification hours_since_verification  anomaly_score  \\\n",
       "0                       57              1385.142305              1   \n",
       "1                       45              1100.792305              1   \n",
       "2                       44              1069.408971              1   \n",
       "3                       22               547.325638              1   \n",
       "4                       53              1292.708971             -1   \n",
       "\n",
       "   anomaly_flag  age_years  \n",
       "0         False         61  \n",
       "1         False         38  \n",
       "2         False         12  \n",
       "3         False         16  \n",
       "4          True         58  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anno corrente per derivare et√† immobile\n",
    "current_year = datetime.utcnow().year\n",
    "\n",
    "# Correzione naming colonne se necessario\n",
    "if \"year_build\" in df.columns and \"year_built\" not in df.columns:\n",
    "    df = df.rename(columns={\"year_build\": \"year_built\"})\n",
    "\n",
    "# Calcolo et√† se mancante\n",
    "if \"age_years\" not in df.columns and \"year_built\" in df.columns:\n",
    "    df[\"age_years\"] = current_year - df[\"year_built\"]\n",
    "\n",
    "# Aggiungila alle feature numeriche se presente\n",
    "if \"age_years\" in df.columns and \"age_years\" not in cfg[\"numeric\"]:\n",
    "    cfg[\"numeric\"].append(\"age_years\")\n",
    "\n",
    "# Pulizia finale delle colonne exclude\n",
    "df = df.drop(columns=[col for col in cfg[\"exclude\"] if col in df.columns])\n",
    "\n",
    "if \"year_built\" in df.columns:\n",
    "    current_year = datetime.utcnow().year\n",
    "    df[\"age_years\"] = current_year - df[\"year_built\"]\n",
    "\n",
    "logging.info(f\"‚úÖ Dataset ready | Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd9da4-99c6-42a0-9bb3-575d54a25cc9",
   "metadata": {},
   "source": [
    "## 04. Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69b68095-70f4-4b5d-ad0d-7b47ba5f9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:50:36,652 [INFO] üìä FEATURE SELECTION OVERVIEW\n",
      "2025-07-29 04:50:36,653 [INFO] üéØ Target: valuation_k\n",
      "2025-07-29 04:50:36,654 [INFO] üß© Categorical: ['energy_class', 'garage', 'has_balcony', 'has_elevator', 'has_garden', 'location', 'owner_occupied', 'public_transport_nearby']\n",
      "2025-07-29 04:50:36,655 [INFO] üìê Numeric: ['age_years', 'air_quality_index', 'bathrooms', 'building_floors', 'distance_to_center_km', 'env_score', 'floor', 'humidity_level', 'luxury_score', 'noise_level', 'rooms', 'size_m2', 'temperature_avg', 'year_built']\n",
      "2025-07-29 04:50:36,656 [INFO] üö´ Excluded: ['asset_id', 'asset_type', 'condition_score', 'risk_score', 'prediction_ts', 'age_years', 'age_category', 'luxury_category', 'value_segment', 'timestamp']\n",
      "2025-07-29 04:50:36,657 [INFO] ‚úÖ Feature pool: ['location', 'region', 'urban_type', 'size_m2', 'rooms', 'bathrooms', 'year_built', 'floor', 'building_floors', 'has_elevator', 'has_garden', 'has_balcony', 'garage', 'owner_occupied', 'public_transport_nearby', 'distance_to_center_km', 'energy_class', 'humidity_level', 'temperature_avg', 'noise_level', 'air_quality_index', 'luxury_score', 'env_score', 'last_verified_ts', 'quarter_built', 'decade_built', 'rooms_per_sqm', 'bathrooms_per_room', 'avg_room_size', 'location_premium', 'amenity_count', 'price_vs_region_avg', 'size_bin', 'days_since_verification', 'hours_since_verification', 'anomaly_score', 'anomaly_flag']\n"
     ]
    }
   ],
   "source": [
    "# Verifica che tutte le colonne richieste siano presenti\n",
    "required_base = list(set([cfg[\"target\"]] + cfg[\"categorical\"] + cfg[\"numeric\"]))\n",
    "missing = [col for col in required_base if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùå Missing required columns: {missing}\")\n",
    "\n",
    "# Rimozione duplicati eventuali\n",
    "cfg[\"categorical\"] = sorted(set(cfg[\"categorical\"]))\n",
    "cfg[\"numeric\"] = sorted(set(cfg[\"numeric\"]))\n",
    "\n",
    "# Filtro automatico delle feature non presenti nel dataset\n",
    "cfg[\"numeric\"] = [col for col in cfg[\"numeric\"] if col in df.columns]\n",
    "cfg[\"categorical\"] = [col for col in cfg[\"categorical\"] if col in df.columns]\n",
    "\n",
    "# Determina le colonne usabili come feature\n",
    "excluded = set(cfg[\"exclude\"] + [cfg[\"target\"]])\n",
    "feature_candidates = [col for col in df.columns if col not in excluded]\n",
    "\n",
    "# Logging dettagliato\n",
    "logging.info(\"üìä FEATURE SELECTION OVERVIEW\")\n",
    "logging.info(f\"üéØ Target: {cfg['target']}\")\n",
    "logging.info(f\"üß© Categorical: {cfg['categorical']}\")\n",
    "logging.info(f\"üìê Numeric: {cfg['numeric']}\")\n",
    "logging.info(f\"üö´ Excluded: {cfg['exclude']}\")\n",
    "logging.info(f\"‚úÖ Feature pool: {feature_candidates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60aec06-522b-4e18-ad3b-71c1f0e62d1b",
   "metadata": {},
   "source": [
    "## 05. Overfitting check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3379aac2-ab77-48cc-a77d-693a20d1104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_overfitting_check(pipeline, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Analisi completa dell'overfitting tramite MAE su training, test e cross-validation.\n",
    "    \"\"\"\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        n_jobs=-1  # üîÅ sfrutta il parallelismo\n",
    "    )\n",
    "    cv_mae = -cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    logging.info(\"\\nüîç OVERFITTING ANALYSIS\")\n",
    "    logging.info(\"=\" * 50)\n",
    "    logging.info(f\"Training MAE: {train_mae:.2f}\")\n",
    "    logging.info(f\"CV MAE:       {cv_mae:.2f} ¬± {cv_std:.2f}\")\n",
    "    logging.info(f\"Test MAE:     {test_mae:.2f}\")\n",
    "\n",
    "    if train_mae < cv_mae * 0.5:\n",
    "        logging.warning(\"‚ùå SEVERE OVERFITTING: Train MAE << CV MAE\")\n",
    "    if test_mae > cv_mae * 2:\n",
    "        logging.warning(\"‚ùå POOR GENERALIZATION: Test MAE >> CV MAE\")\n",
    "\n",
    "    return {\"train\": train_mae, \"cv\": cv_mae, \"test\": test_mae}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c915f13-189c-4380-9c72-a30680dfdd1b",
   "metadata": {},
   "source": [
    "## 06. Final feature list = categorical + numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd171f89-0d87-4a14-b26a-3e39db97ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:50:38,320 [INFO] üßÆ Final feature list: ['energy_class', 'garage', 'has_balcony', 'has_elevator', 'has_garden', 'location', 'owner_occupied', 'public_transport_nearby', 'age_years', 'air_quality_index', 'bathrooms', 'building_floors', 'distance_to_center_km', 'env_score', 'floor', 'humidity_level', 'luxury_score', 'noise_level', 'rooms', 'size_m2', 'temperature_avg', 'year_built']\n"
     ]
    }
   ],
   "source": [
    "feature_list = cfg[\"categorical\"] + cfg[\"numeric\"]\n",
    "logging.info(f\"üßÆ Final feature list: {feature_list}\")\n",
    "\n",
    "X = df[feature_list].copy()\n",
    "y = df[cfg[\"target\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdc4b9-98c5-43ac-9804-13c954b02c63",
   "metadata": {},
   "source": [
    "## 07. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91aed31d-f657-4b2e-a37a-5bf3a588b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Allineamento categorie\n",
    "for col in X_train.select_dtypes(include=\"object\").columns:\n",
    "    all_categories = pd.Series(pd.concat([X_train[col], X_test[col]])).astype(\"category\").cat.categories\n",
    "    X_train[col] = X_train[col].astype(\"category\").cat.set_categories(all_categories)\n",
    "    X_test[col] = X_test[col].astype(\"category\").cat.set_categories(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cc11f-e303-48de-92c6-d38c9ec38bf1",
   "metadata": {},
   "source": [
    "## 08. Preprocessing + Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9c6c54-9cfc-4c43-8cb6-721f5066387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        Catania\n",
       " 1       Florence\n",
       " 2         Naples\n",
       " 3        Trieste\n",
       " 4          Turin\n",
       "           ...   \n",
       " 4924    Cagliari\n",
       " 4925      Naples\n",
       " 4926       Milan\n",
       " 4927    Cagliari\n",
       " 4928       Turin\n",
       " Name: location, Length: 4929, dtype: object,\n",
       " 0       F\n",
       " 1       E\n",
       " 2       G\n",
       " 3       C\n",
       " 4       E\n",
       "        ..\n",
       " 4924    D\n",
       " 4925    A\n",
       " 4926    B\n",
       " 4927    C\n",
       " 4928    D\n",
       " Name: energy_class, Length: 4929, dtype: object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_verified_ts']\n",
    "df['location'], df['energy_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "804b1295-39ed-4817-b174-162013df79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location_energy_class'] = (\n",
    "    df['location'].astype(str) + \"_\" + df['energy_class'].astype(str)\n",
    ")\n",
    "\n",
    "assert \"last_verified_ts\" in df.columns, \"‚ùå Manca last_verified_ts\"\n",
    "assert \"valuation_k\" in df.columns, \"‚ùå Manca valuation_k\"\n",
    "\n",
    "X_full = df.drop(columns=[\"valuation_k\"])\n",
    "y_full = df[\"valuation_k\"]\n",
    "\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ['valuation_k', 'asset_id', 'timestamp',\n",
    "                             'last_verified_ts', 'location_energy_class']]\n",
    "\n",
    "X_full = df[feature_cols]\n",
    "y_full = df['valuation_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9348895b-c1a5-4959-b50a-2fcba08c188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 05:01:39,848 [INFO] [TS] Fold0 ‚Üí Train: (824, 37), Valid: (821, 37)\n",
      "2025-07-29 05:01:39,868 [INFO] üß© Preprocessed shapes ‚Üí Tune: (824, 48), Valid: (821, 48)\n",
      "[I 2025-07-29 05:01:39,883] A new study created in memory with name: no-name-e0d616cb-76ec-41c3-a406-5fdf50d99118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4908f9fcfa46f281ececf621e1a8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid's l1: 0.250238\n",
      "[I 2025-07-29 05:01:40,144] Trial 0 finished with value: 0.25023809274411835 and parameters: {'num_leaves': 30, 'max_depth': 7, 'min_child_samples': 30, 'feature_fraction': 0.7999203021779528, 'bagging_fraction': 0.9988975945363576, 'reg_alpha': 0.39884519067979063, 'reg_lambda': 0.8704689287147821}. Best is trial 0 with value: 0.25023809274411835.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid's l1: 0.250847\n",
      "[I 2025-07-29 05:01:40,399] Trial 1 finished with value: 0.250847044009419 and parameters: {'num_leaves': 50, 'max_depth': 12, 'min_child_samples': 42, 'feature_fraction': 0.6522713353931427, 'bagging_fraction': 0.8884499405135903, 'reg_alpha': 0.4977054879179267, 'reg_lambda': 0.8114807804222434}. Best is trial 0 with value: 0.25023809274411835.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid's l1: 0.25129\n",
      "[I 2025-07-29 05:01:40,777] Trial 2 finished with value: 0.2512902710513251 and parameters: {'num_leaves': 58, 'max_depth': 11, 'min_child_samples': 47, 'feature_fraction': 0.67162385137672, 'bagging_fraction': 0.6033831498657942, 'reg_alpha': 0.08602604288920124, 'reg_lambda': 0.6360943762967118}. Best is trial 0 with value: 0.25023809274411835.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid's l1: 0.255995\n",
      "[I 2025-07-29 05:01:41,289] Trial 3 finished with value: 0.25599473780532805 and parameters: {'num_leaves': 78, 'max_depth': 6, 'min_child_samples': 15, 'feature_fraction': 0.6251868948028614, 'bagging_fraction': 0.8724540829373737, 'reg_alpha': 0.168115732905593, 'reg_lambda': 0.40633999949259725}. Best is trial 0 with value: 0.25023809274411835.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid's l1: 0.253721\n",
      "[I 2025-07-29 05:01:41,766] Trial 4 finished with value: 0.25372134568270716 and parameters: {'num_leaves': 55, 'max_depth': 12, 'min_child_samples': 14, 'feature_fraction': 0.6098165129198588, 'bagging_fraction': 0.793443123836466, 'reg_alpha': 0.6939800121818818, 'reg_lambda': 0.6856755843344174}. Best is trial 0 with value: 0.25023809274411835.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid's l1: 0.249413\n",
      "[I 2025-07-29 05:01:42,056] Trial 5 finished with value: 0.24941334250648112 and parameters: {'num_leaves': 27, 'max_depth': 6, 'min_child_samples': 35, 'feature_fraction': 0.915985720193621, 'bagging_fraction': 0.6206537738907193, 'reg_alpha': 0.27305717157722953, 'reg_lambda': 0.8428429982196819}. Best is trial 5 with value: 0.24941334250648112.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid's l1: 0.248821\n",
      "[I 2025-07-29 05:01:42,340] Trial 6 finished with value: 0.2488209022965155 and parameters: {'num_leaves': 39, 'max_depth': 9, 'min_child_samples': 41, 'feature_fraction': 0.8972251536944521, 'bagging_fraction': 0.862738528611761, 'reg_alpha': 0.2224405262446918, 'reg_lambda': 0.9153824063681654}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid's l1: 0.249849\n",
      "[I 2025-07-29 05:01:42,678] Trial 7 finished with value: 0.24984870651156996 and parameters: {'num_leaves': 64, 'max_depth': 5, 'min_child_samples': 12, 'feature_fraction': 0.9767218258743934, 'bagging_fraction': 0.820769491830752, 'reg_alpha': 0.28861316885518895, 'reg_lambda': 0.7256092154104713}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[361]\tvalid's l1: 0.249495\n",
      "[I 2025-07-29 05:01:42,948] Trial 8 finished with value: 0.24949473298571564 and parameters: {'num_leaves': 52, 'max_depth': 11, 'min_child_samples': 45, 'feature_fraction': 0.7946669392028655, 'bagging_fraction': 0.6984772055828301, 'reg_alpha': 0.10880828799832487, 'reg_lambda': 0.9351747143291201}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid's l1: 0.250626\n",
      "[I 2025-07-29 05:01:43,180] Trial 9 finished with value: 0.2506264822327145 and parameters: {'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 45, 'feature_fraction': 0.6283221286455692, 'bagging_fraction': 0.715604188170277, 'reg_alpha': 0.5093798096641208, 'reg_lambda': 0.13987534057000706}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid's l1: 0.249447\n",
      "[I 2025-07-29 05:01:43,397] Trial 10 finished with value: 0.2494474410520757 and parameters: {'num_leaves': 39, 'max_depth': 9, 'min_child_samples': 29, 'feature_fraction': 0.8825739443171764, 'bagging_fraction': 0.9747105340694845, 'reg_alpha': 0.8621822647051829, 'reg_lambda': 0.43183287352291755}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid's l1: 0.249501\n",
      "[I 2025-07-29 05:01:43,582] Trial 11 finished with value: 0.2495005416244833 and parameters: {'num_leaves': 21, 'max_depth': 9, 'min_child_samples': 37, 'feature_fraction': 0.9180765651215737, 'bagging_fraction': 0.6282459450592894, 'reg_alpha': 0.2865857491017628, 'reg_lambda': 0.9869121812492111}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid's l1: 0.249513\n",
      "[I 2025-07-29 05:01:43,792] Trial 12 finished with value: 0.2495130874955163 and parameters: {'num_leaves': 38, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8736645722303793, 'bagging_fraction': 0.740838167794627, 'reg_alpha': 0.01786847159516841, 'reg_lambda': 0.5458407662212962}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid's l1: 0.250013\n",
      "[I 2025-07-29 05:01:43,981] Trial 13 finished with value: 0.2500133541252684 and parameters: {'num_leaves': 20, 'max_depth': 4, 'min_child_samples': 23, 'feature_fraction': 0.9967946037872724, 'bagging_fraction': 0.9178692011434031, 'reg_alpha': 0.27738063724200296, 'reg_lambda': 0.0767983999511691}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid's l1: 0.248934\n",
      "[I 2025-07-29 05:01:44,178] Trial 14 finished with value: 0.24893389912196892 and parameters: {'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 39, 'feature_fraction': 0.929170142988238, 'bagging_fraction': 0.8066153456399164, 'reg_alpha': 0.45461095548993613, 'reg_lambda': 0.27132237809460313}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid's l1: 0.24954\n",
      "[I 2025-07-29 05:01:44,364] Trial 15 finished with value: 0.24954023986227314 and parameters: {'num_leaves': 41, 'max_depth': 9, 'min_child_samples': 50, 'feature_fraction': 0.7448529286733484, 'bagging_fraction': 0.8294680355657489, 'reg_alpha': 0.6872506546910886, 'reg_lambda': 0.23503456793235236}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid's l1: 0.24947\n",
      "[I 2025-07-29 05:01:44,546] Trial 16 finished with value: 0.24946980520453654 and parameters: {'num_leaves': 45, 'max_depth': 10, 'min_child_samples': 40, 'feature_fraction': 0.8590656446338217, 'bagging_fraction': 0.7725765687019177, 'reg_alpha': 0.495769769281512, 'reg_lambda': 0.2910706594660156}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid's l1: 0.249223\n",
      "[I 2025-07-29 05:01:44,770] Trial 17 finished with value: 0.24922293935854697 and parameters: {'num_leaves': 29, 'max_depth': 8, 'min_child_samples': 23, 'feature_fraction': 0.9481246127303277, 'bagging_fraction': 0.9224270549840505, 'reg_alpha': 0.6547502791916597, 'reg_lambda': 0.2787480754973391}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\tvalid's l1: 0.24991\n",
      "[I 2025-07-29 05:01:44,985] Trial 18 finished with value: 0.2499102198713192 and parameters: {'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 32, 'feature_fraction': 0.8417824773293782, 'bagging_fraction': 0.8610358780138709, 'reg_alpha': 0.9607729632804437, 'reg_lambda': 0.5465566123995798}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid's l1: 0.250235\n",
      "[I 2025-07-29 05:01:45,171] Trial 19 finished with value: 0.2502349818168515 and parameters: {'num_leaves': 47, 'max_depth': 10, 'min_child_samples': 41, 'feature_fraction': 0.7194609218916461, 'bagging_fraction': 0.6726291800298164, 'reg_alpha': 0.3958205888411779, 'reg_lambda': 0.38632125930817096}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid's l1: 0.251976\n",
      "[I 2025-07-29 05:01:45,414] Trial 20 finished with value: 0.25197638475352285 and parameters: {'num_leaves': 71, 'max_depth': 7, 'min_child_samples': 26, 'feature_fraction': 0.9188552558974269, 'bagging_fraction': 0.7792014973647512, 'reg_alpha': 0.1876142367282686, 'reg_lambda': 0.03805472016381661}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid's l1: 0.248949\n",
      "[I 2025-07-29 05:01:45,659] Trial 21 finished with value: 0.2489492597031632 and parameters: {'num_leaves': 31, 'max_depth': 8, 'min_child_samples': 20, 'feature_fraction': 0.9619378421521576, 'bagging_fraction': 0.9310583687108964, 'reg_alpha': 0.6720071015255105, 'reg_lambda': 0.23807394183258335}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid's l1: 0.250045\n",
      "[I 2025-07-29 05:01:45,923] Trial 22 finished with value: 0.2500453694553814 and parameters: {'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 19, 'feature_fraction': 0.9518528993104577, 'bagging_fraction': 0.9501552120779082, 'reg_alpha': 0.6101724327691902, 'reg_lambda': 0.1447377548887761}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid's l1: 0.249448\n",
      "[I 2025-07-29 05:01:46,153] Trial 23 finished with value: 0.24944797085023634 and parameters: {'num_leaves': 25, 'max_depth': 10, 'min_child_samples': 18, 'feature_fraction': 0.9586624969173156, 'bagging_fraction': 0.8395384774420355, 'reg_alpha': 0.8183219054062973, 'reg_lambda': 0.20466125433080162}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid's l1: 0.249131\n",
      "[I 2025-07-29 05:01:46,360] Trial 24 finished with value: 0.24913090526432854 and parameters: {'num_leaves': 43, 'max_depth': 9, 'min_child_samples': 34, 'feature_fraction': 0.8982160479350596, 'bagging_fraction': 0.9013415700647595, 'reg_alpha': 0.7717375204424536, 'reg_lambda': 0.33215499901355744}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid's l1: 0.249559\n",
      "[I 2025-07-29 05:01:46,561] Trial 25 finished with value: 0.24955907898427523 and parameters: {'num_leaves': 34, 'max_depth': 7, 'min_child_samples': 38, 'feature_fraction': 0.8357174936948053, 'bagging_fraction': 0.9396769856783045, 'reg_alpha': 0.5833800653136818, 'reg_lambda': 0.48596698316188347}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid's l1: 0.250772\n",
      "[I 2025-07-29 05:01:46,853] Trial 26 finished with value: 0.2507715108743738 and parameters: {'num_leaves': 36, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.9878775260220268, 'bagging_fraction': 0.8430991698741475, 'reg_alpha': 0.4479812213882557, 'reg_lambda': 0.17822821535342512}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid's l1: 0.250492\n",
      "[I 2025-07-29 05:01:47,130] Trial 27 finished with value: 0.25049225209636466 and parameters: {'num_leaves': 25, 'max_depth': 6, 'min_child_samples': 27, 'feature_fraction': 0.9341623940338263, 'bagging_fraction': 0.8086394949929847, 'reg_alpha': 0.37857511400152183, 'reg_lambda': 0.0038683440750025277}. Best is trial 6 with value: 0.2488209022965155.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's l1: 0.248812\n",
      "[I 2025-07-29 05:01:47,314] Trial 28 finished with value: 0.24881221827657832 and parameters: {'num_leaves': 32, 'max_depth': 9, 'min_child_samples': 43, 'feature_fraction': 0.829187859630345, 'bagging_fraction': 0.7503112928106812, 'reg_alpha': 0.5559309518702159, 'reg_lambda': 0.3251275477726099}. Best is trial 28 with value: 0.24881221827657832.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid's l1: 0.249585\n",
      "[I 2025-07-29 05:01:47,512] Trial 29 finished with value: 0.24958470391489723 and parameters: {'num_leaves': 30, 'max_depth': 11, 'min_child_samples': 50, 'feature_fraction': 0.7967144501999643, 'bagging_fraction': 0.738170641623199, 'reg_alpha': 0.3397896592584973, 'reg_lambda': 0.3621524554529159}. Best is trial 28 with value: 0.24881221827657832.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid's l1: 0.248628\n",
      "[I 2025-07-29 05:01:47,702] Trial 30 finished with value: 0.2486279146289142 and parameters: {'num_leaves': 41, 'max_depth': 10, 'min_child_samples': 44, 'feature_fraction': 0.8239575125517296, 'bagging_fraction': 0.7541817512334323, 'reg_alpha': 0.5504753270543531, 'reg_lambda': 0.48443596304549874}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[353]\tvalid's l1: 0.249044\n",
      "[I 2025-07-29 05:01:47,911] Trial 31 finished with value: 0.2490435144408201 and parameters: {'num_leaves': 42, 'max_depth': 10, 'min_child_samples': 44, 'feature_fraction': 0.8190064966843078, 'bagging_fraction': 0.7700119817340649, 'reg_alpha': 0.554226588444182, 'reg_lambda': 0.4986848734964757}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid's l1: 0.249963\n",
      "[I 2025-07-29 05:01:48,109] Trial 32 finished with value: 0.24996266702480413 and parameters: {'num_leaves': 38, 'max_depth': 9, 'min_child_samples': 39, 'feature_fraction': 0.7724104541208893, 'bagging_fraction': 0.7421767945984026, 'reg_alpha': 0.4323492329524603, 'reg_lambda': 0.5790434454365627}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid's l1: 0.248681\n",
      "[I 2025-07-29 05:01:48,315] Trial 33 finished with value: 0.24868104705616587 and parameters: {'num_leaves': 48, 'max_depth': 11, 'min_child_samples': 43, 'feature_fraction': 0.8570783016841569, 'bagging_fraction': 0.794456527925991, 'reg_alpha': 0.5309164356358507, 'reg_lambda': 0.7688142690265239}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid's l1: 0.249093\n",
      "[I 2025-07-29 05:01:48,520] Trial 34 finished with value: 0.2490934998495248 and parameters: {'num_leaves': 49, 'max_depth': 11, 'min_child_samples': 43, 'feature_fraction': 0.8190623373397006, 'bagging_fraction': 0.6802938330032591, 'reg_alpha': 0.5417954337200437, 'reg_lambda': 0.7361274312055093}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[398]\tvalid's l1: 0.24942\n",
      "[I 2025-07-29 05:01:48,743] Trial 35 finished with value: 0.2494203517008584 and parameters: {'num_leaves': 53, 'max_depth': 12, 'min_child_samples': 48, 'feature_fraction': 0.7691361050374966, 'bagging_fraction': 0.8741732475618045, 'reg_alpha': 0.6245489186120934, 'reg_lambda': 0.9343504831202707}. Best is trial 30 with value: 0.2486279146289142.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid's l1: 0.248309\n",
      "[I 2025-07-29 05:01:48,940] Trial 36 finished with value: 0.24830894181600313 and parameters: {'num_leaves': 46, 'max_depth': 11, 'min_child_samples': 47, 'feature_fraction': 0.853430402119601, 'bagging_fraction': 0.7571165540274516, 'reg_alpha': 0.7290327686695539, 'reg_lambda': 0.6448608525395376}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid's l1: 0.248471\n",
      "[I 2025-07-29 05:01:49,123] Trial 37 finished with value: 0.24847109767460057 and parameters: {'num_leaves': 47, 'max_depth': 11, 'min_child_samples': 48, 'feature_fraction': 0.8500857598812015, 'bagging_fraction': 0.7560484511711858, 'reg_alpha': 0.7469478112530479, 'reg_lambda': 0.6307768489998813}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid's l1: 0.248508\n",
      "[I 2025-07-29 05:01:49,307] Trial 38 finished with value: 0.24850814120161183 and parameters: {'num_leaves': 57, 'max_depth': 12, 'min_child_samples': 47, 'feature_fraction': 0.8530556981897043, 'bagging_fraction': 0.7236876685899268, 'reg_alpha': 0.7769883631019927, 'reg_lambda': 0.6459951405540402}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[443]\tvalid's l1: 0.249917\n",
      "[I 2025-07-29 05:01:49,524] Trial 39 finished with value: 0.24991735275994742 and parameters: {'num_leaves': 61, 'max_depth': 12, 'min_child_samples': 47, 'feature_fraction': 0.7296663419082015, 'bagging_fraction': 0.7075896709768494, 'reg_alpha': 0.7815173042645799, 'reg_lambda': 0.6648276052764619}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid's l1: 0.25038\n",
      "[I 2025-07-29 05:01:49,712] Trial 40 finished with value: 0.2503795680980392 and parameters: {'num_leaves': 65, 'max_depth': 12, 'min_child_samples': 47, 'feature_fraction': 0.6914741009587401, 'bagging_fraction': 0.656871813048805, 'reg_alpha': 0.9489363836105045, 'reg_lambda': 0.6272656120641324}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid's l1: 0.248556\n",
      "[I 2025-07-29 05:01:49,906] Trial 41 finished with value: 0.24855615575003162 and parameters: {'num_leaves': 50, 'max_depth': 11, 'min_child_samples': 48, 'feature_fraction': 0.8565351583607222, 'bagging_fraction': 0.7231679051302957, 'reg_alpha': 0.8870541344596241, 'reg_lambda': 0.8158692830413087}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid's l1: 0.249056\n",
      "[I 2025-07-29 05:01:50,101] Trial 42 finished with value: 0.2490560005181712 and parameters: {'num_leaves': 57, 'max_depth': 11, 'min_child_samples': 46, 'feature_fraction': 0.8635531284245641, 'bagging_fraction': 0.7232740672063362, 'reg_alpha': 0.8934877585224709, 'reg_lambda': 0.7831754718573714}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's l1: 0.24836\n",
      "[I 2025-07-29 05:01:50,276] Trial 43 finished with value: 0.24836008452925218 and parameters: {'num_leaves': 51, 'max_depth': 12, 'min_child_samples': 49, 'feature_fraction': 0.8910712293102969, 'bagging_fraction': 0.7579361284382095, 'reg_alpha': 0.7401129906171457, 'reg_lambda': 0.8588766262427197}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid's l1: 0.248631\n",
      "[I 2025-07-29 05:01:50,651] Trial 44 finished with value: 0.24863071911187953 and parameters: {'num_leaves': 52, 'max_depth': 12, 'min_child_samples': 49, 'feature_fraction': 0.9014376770461061, 'bagging_fraction': 0.6913989243277776, 'reg_alpha': 0.746343310334356, 'reg_lambda': 0.8527796763211922}. Best is trial 36 with value: 0.24830894181600313.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's l1: 0.248289\n",
      "[I 2025-07-29 05:01:50,832] Trial 45 finished with value: 0.24828915149712902 and parameters: {'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 48, 'feature_fraction': 0.8855866825667198, 'bagging_fraction': 0.7203459498133352, 'reg_alpha': 0.8760221724573516, 'reg_lambda': 0.689118480461569}. Best is trial 45 with value: 0.24828915149712902.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid's l1: 0.248516\n",
      "[I 2025-07-29 05:01:51,013] Trial 46 finished with value: 0.2485163564845001 and parameters: {'num_leaves': 54, 'max_depth': 12, 'min_child_samples': 46, 'feature_fraction': 0.8872426290336476, 'bagging_fraction': 0.6405903123708923, 'reg_alpha': 0.7349839675920162, 'reg_lambda': 0.6169435906162745}. Best is trial 45 with value: 0.24828915149712902.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid's l1: 0.248962\n",
      "[I 2025-07-29 05:01:51,197] Trial 47 finished with value: 0.24896185720863082 and parameters: {'num_leaves': 67, 'max_depth': 12, 'min_child_samples': 50, 'feature_fraction': 0.806318877491757, 'bagging_fraction': 0.7619965309193121, 'reg_alpha': 0.8290598876523522, 'reg_lambda': 0.6902308653047495}. Best is trial 45 with value: 0.24828915149712902.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid's l1: 0.24846\n",
      "[I 2025-07-29 05:01:51,377] Trial 48 finished with value: 0.24845996613175822 and parameters: {'num_leaves': 57, 'max_depth': 11, 'min_child_samples': 48, 'feature_fraction': 0.8775835434406243, 'bagging_fraction': 0.786457433732515, 'reg_alpha': 0.7200259051326903, 'reg_lambda': 0.7150999674651437}. Best is trial 45 with value: 0.24828915149712902.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 05:01:51,589 [INFO] üéØ Best trial: 49\n",
      "2025-07-29 05:01:51,590 [INFO] ‚úÖ Best parameters: {'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 45, 'feature_fraction': 0.8800100949787368, 'bagging_fraction': 0.7812723686785915, 'reg_alpha': 0.729114739812065, 'reg_lambda': 0.882750507925878}\n",
      "2025-07-29 05:01:51,591 [INFO] ‚úÖ TS best_iteration: 326\n",
      "2025-07-29 05:01:51,591 [INFO] üìâ TS Best MAE (log1p): 0.2480\n",
      "2025-07-29 05:01:51,606 [INFO] üéØ Final LGBM params: {'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 45, 'feature_fraction': 0.8800100949787368, 'bagging_fraction': 0.7812723686785915, 'reg_alpha': 0.729114739812065, 'reg_lambda': 0.882750507925878, 'objective': 'regression', 'metric': 'mae', 'boosting_type': 'gbdt', 'verbosity': -1, 'seed': 42, 'learning_rate': 0.01, 'n_estimators': 326}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[326]\tvalid's l1: 0.247982\n",
      "[I 2025-07-29 05:01:51,555] Trial 49 finished with value: 0.247981525311835 and parameters: {'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 45, 'feature_fraction': 0.8800100949787368, 'bagging_fraction': 0.7812723686785915, 'reg_alpha': 0.729114739812065, 'reg_lambda': 0.882750507925878}. Best is trial 49 with value: 0.247981525311835.\n"
     ]
    }
   ],
   "source": [
    "# --- CODICE COMPLETO PULITO ---\n",
    "\n",
    "# 1) Preprocessing\n",
    "missing_cat = [c for c in cfg[\"categorical\"] if c not in X_full.columns]\n",
    "missing_num = [c for c in cfg[\"numeric\"] if c not in X_full.columns]\n",
    "if missing_cat or missing_num:\n",
    "    logging.warning(f\"Colonne mancanti ‚Üí categorical: {missing_cat}, numeric: {missing_num}\")\n",
    "\n",
    "categorical_cols = [c for c in cfg[\"categorical\"] if c in X_full.columns]\n",
    "numeric_cols = [c for c in cfg[\"numeric\"] if c in X_full.columns]\n",
    "assert categorical_cols or numeric_cols, \"‚ö†Ô∏è Nessuna colonna valida per preprocessing!\"\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "    (\"num\", \"passthrough\", numeric_cols),\n",
    "])\n",
    "\n",
    "# 2) TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "train_idx, valid_idx = next(tscv.split(X_full))\n",
    "X_tune, X_valid = X_full.iloc[train_idx], X_full.iloc[valid_idx]\n",
    "y_tune, y_valid = y_full.iloc[train_idx], y_full.iloc[valid_idx]\n",
    "logging.info(f\"[TS] Fold0 ‚Üí Train: {X_tune.shape}, Valid: {X_valid.shape}\")\n",
    "\n",
    "# 3) Transform\n",
    "X_tune_enc = preprocessor.fit_transform(X_tune)\n",
    "X_valid_enc = preprocessor.transform(X_valid)\n",
    "logging.info(f\"üß© Preprocessed shapes ‚Üí Tune: {X_tune_enc.shape}, Valid: {X_valid_enc.shape}\")\n",
    "\n",
    "# 4) LightGBM datasets\n",
    "y_tune_log = np.log1p(y_tune)\n",
    "y_valid_log = np.log1p(y_valid)\n",
    "dtrain = lgb.Dataset(data=X_tune_enc, label=y_tune_log)\n",
    "dvalid = lgb.Dataset(data=X_valid_enc, label=y_valid_log)\n",
    "\n",
    "# 5) Optuna objective\n",
    "def objective_function(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 80),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        \"feature_pre_filter\": False,\n",
    "    }\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=dtrain,\n",
    "        valid_sets=[dvalid],\n",
    "        valid_names=[\"valid\"],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=0),\n",
    "            lgb.record_evaluation(evals_result)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    best_iteration = model.best_iteration\n",
    "    best_score = evals_result['valid']['l1'][best_iteration - 1] if best_iteration > 0 else float('inf')\n",
    "    \n",
    "    trial.set_user_attr(\"best_model\", model)\n",
    "    trial.set_user_attr(\"best_iteration\", best_iteration)\n",
    "    trial.set_user_attr(\"best_score\", best_score)\n",
    "    \n",
    "    return best_score\n",
    "\n",
    "# 6) Run Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective_function, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# 7) Extract results\n",
    "best_trial = study.best_trial\n",
    "best_model = best_trial.user_attrs[\"best_model\"]\n",
    "best_iter_ts = best_trial.user_attrs[\"best_iteration\"]\n",
    "best_mae_ts = best_trial.user_attrs[\"best_score\"]\n",
    "\n",
    "# 8) Log ONLY these results\n",
    "logging.info(f\"üéØ Best trial: {best_trial.number}\")\n",
    "logging.info(f\"‚úÖ Best parameters: {best_trial.params}\")\n",
    "logging.info(f\"‚úÖ TS best_iteration: {best_iter_ts}\")\n",
    "logging.info(f\"üìâ TS Best MAE (log1p): {best_mae_ts:.4f}\")\n",
    "\n",
    "# RIMUOVI TUTTO IL CODICE SOTTO QUESTA RIGA CHE GENERA I WARNING!\n",
    "# Non serve pi√π questo codice:\n",
    "# - if best_iter_ts <= 0: ...\n",
    "# - best_score_dict = getattr(best_model, \"best_score\", {}) ...\n",
    "# - if best_mae_ts is not None: ...\n",
    "# etc.\n",
    "\n",
    "# 9) Salva il best model parameters per uso futuro\n",
    "best_optuna_params = {\n",
    "    **study.best_params,\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": best_iter_ts,  # Usa il best iteration come n_estimators\n",
    "}\n",
    "\n",
    "logging.info(f\"üéØ Final LGBM params: {best_optuna_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8b0c9-97a8-474b-aac3-e31c9cdb58c2",
   "metadata": {},
   "source": [
    "## 09. Build pipeline con target transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe014bd9-acd1-4be4-989a-16455c836842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:24:22,238 [INFO] üéØ Final LGBM params: {'num_leaves': 64, 'max_depth': 7, 'min_child_samples': 19, 'feature_fraction': 0.8198035545203568, 'bagging_fraction': 0.7430085723759272, 'reg_alpha': 0.8133603299484831, 'reg_lambda': 0.7002265382229789, 'objective': 'regression', 'metric': 'mae', 'boosting_type': 'gbdt', 'verbosity': -1, 'force_col_wise': True, 'random_state': 42, 'n_jobs': -1, 'n_estimators': 100}\n",
      "2025-07-29 04:24:22,239 [INFO] ‚úÖ Pipeline with optimized LightGBM + log1p transformation ready.\n"
     ]
    }
   ],
   "source": [
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 1) Recupero dei parametri ottimali\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# Se hai uno study Optuna:\n",
    "best_optuna_params = study.best_params.copy()\n",
    "\n",
    "# Configurazione finale per LGBM\n",
    "final_params = {\n",
    "    **best_optuna_params,\n",
    "    \"objective\":      \"regression\",\n",
    "    \"metric\":         \"mae\",\n",
    "    \"boosting_type\":  \"gbdt\",\n",
    "    \"verbosity\":      -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"random_state\":   RANDOM_STATE,\n",
    "    \"n_jobs\":         -1,\n",
    "    # Assicuriamoci di usare il numero di iterazioni ottimale\n",
    "    \"n_estimators\":   max(100, getattr(best_model, \"best_iteration\", 0))\n",
    "  \n",
    "}\n",
    "\n",
    "logging.info(f\"üéØ Final LGBM params: {final_params}\")\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 2) Inizializzazione regressore e pipeline\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "lgb_final = lgb.LGBMRegressor(**final_params)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", TransformedTargetRegressor(\n",
    "        regressor=lgb_final,\n",
    "        func=np.log1p,\n",
    "        inverse_func=np.expm1\n",
    "    ))\n",
    "])\n",
    "\n",
    "logging.info(\"‚úÖ Pipeline with optimized LightGBM + log1p transformation ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1f075-89a4-4e49-a30c-2031f17ab419",
   "metadata": {},
   "source": [
    "## 10. Validazione + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a90328c1-1e44-4551-a9e9-bb18e4a8817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:12:21,145 [INFO] ‚úÖ Training data validated | X: (4929, 37), y: (4929,)\n",
      "2025-07-29 04:12:21,779 [INFO] üîÅ CROSS-VALIDATION RESULTS (TimeSeriesSplit)\n",
      "2025-07-29 04:12:21,780 [INFO] ‚úÖ MAE: 72.56 ¬± 1.18 k‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "def validate_training_data(X, y):\n",
    "    assert isinstance(X, pd.DataFrame), \"‚ùå X must be a pandas DataFrame\"\n",
    "    assert isinstance(y, (pd.Series, pd.DataFrame)), \"‚ùå y must be a pandas Series or DataFrame\"\n",
    "    assert X.shape[0] == y.shape[0], \"‚ùå Features and target misaligned\"\n",
    "    assert not X.isnull().values.any(), \"‚ùå Missing values in X\"\n",
    "    assert not y.isnull().values.any(), \"‚ùå Missing values in y\"\n",
    "    logging.info(f\"‚úÖ Training data validated | X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "# Applichiamo la validazione sul dataset intero\n",
    "validate_training_data(X_full, y_full)\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 4) Cross‚Äêvalidation con TimeSeriesSplit\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    pipeline,\n",
    "    X_full,\n",
    "    y_full,\n",
    "    cv=tscv,\n",
    "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ricordiamo che cross_val_score restituisce MAE negativo\n",
    "cv_mae = -cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "logging.info(\"üîÅ CROSS-VALIDATION RESULTS (TimeSeriesSplit)\")\n",
    "logging.info(f\"‚úÖ MAE: {cv_mae:.2f} ¬± {cv_std:.2f} k‚Ç¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ec34b-654a-4ca1-8308-de60b5d7cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper per Prediction Intervals con Quantile Regression ---\n",
    "def train_quantile_models(X_train, y_train, preprocessor, quantiles=[0.05, 0.5, 0.95]):\n",
    "    quantile_models = {}\n",
    "    base_params = {\n",
    "        k: v for k, v in best_optuna_params.items()\n",
    "        if k not in ['objective', 'metric', 'n_estimators']\n",
    "    }\n",
    "\n",
    "    fallback_estimators = max(100, getattr(best_model, \"best_iteration\", 100))\n",
    "    n_estimators = best_optuna_params.get('n_estimators', fallback_estimators)\n",
    "    if n_estimators <= 0:\n",
    "        n_estimators = fallback_estimators\n",
    "\n",
    "    for q in quantiles:\n",
    "        model_q = lgb.LGBMRegressor(\n",
    "            objective='quantile',\n",
    "            alpha=q,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=RANDOM_STATE,\n",
    "            **base_params\n",
    "        )\n",
    "        pipeline_q = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', TransformedTargetRegressor(\n",
    "                regressor=model_q,\n",
    "                func=np.log1p,\n",
    "                inverse_func=np.expm1\n",
    "            ))\n",
    "        ])\n",
    "        pipeline_q.fit(X_train, y_train)\n",
    "        quantile_models[q] = pipeline_q\n",
    "        comprehensive_overfitting_check(pipeline_q, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    return quantile_models\n",
    "\n",
    "def predict_with_intervals(quantile_models, X):\n",
    "    \"\"\"\n",
    "    DataFrame con predizioni per ciascun quantile.\n",
    "    \"\"\"\n",
    "    intervals = {}\n",
    "    for q, model in quantile_models.items():\n",
    "        intervals[f\"q{int(q*100)}\"] = model.predict(X)\n",
    "    return pd.DataFrame(intervals, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c500b99-6141-4582-ab52-ad404cc33422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:27:39,680 [INFO] [Blending] TrainA: (3943, 37), TrainB (meta-train): (986, 37)\n",
      "2025-07-29 04:27:39,884 [INFO]     ‚Ä¢ Base learner lgb trained on A\n",
      "2025-07-29 04:27:40,720 [INFO]     ‚Ä¢ Base learner xgb trained on A\n",
      "2025-07-29 04:27:40,743 [INFO]     ‚Ä¢ Base learner ridge trained on A\n",
      "2025-07-29 04:27:40,814 [INFO] üîç Meta-learner best alpha (nested CV): 10.0\n",
      "2025-07-29 04:27:40,817 [INFO]     ‚Ä¢ Meta-learner (Ridge) trained on meta-features\n",
      "2025-07-29 04:27:40,937 [INFO] üîÑ Base learner lgb refit on full training data\n",
      "2025-07-29 04:27:41,596 [INFO] üîÑ Base learner xgb refit on full training data\n",
      "2025-07-29 04:27:41,618 [INFO] üîÑ Base learner ridge refit on full training data\n",
      "2025-07-29 04:27:41,964 [INFO]               q5         q50         q95\n",
      "4774  225.997773  375.803546  477.339361\n",
      "3398  114.596540  171.662627  234.187230\n",
      "889   149.966917  256.876446  318.992903\n",
      "4198  119.048370  224.280699  259.420246\n",
      "3553  281.245920  454.491045  561.924596\n",
      "2025-07-29 04:27:41,965 [INFO] üìä Interval coverage: 76.77%\n",
      "2025-07-29 04:27:41,965 [INFO] üìä Average interval width: 211.06 k‚Ç¨\n",
      "2025-07-29 04:27:41,990 [INFO] üìà FINAL BLENDING EVALUATION ON TEST SET\n",
      "2025-07-29 04:27:41,991 [INFO] üìä MAE:  60.40 k‚Ç¨\n",
      "2025-07-29 04:27:41,992 [INFO] üìä RMSE: 74.88 k‚Ç¨\n",
      "2025-07-29 04:27:41,992 [INFO] üìä R¬≤:   0.71\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1) Split ‚ÄúA/B‚Äù per blending (80/20)\n",
    "# -------------------------------------------\n",
    "X_A, X_B, y_A, y_B = train_test_split(\n",
    "    X_full, y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True\n",
    ")\n",
    "logging.info(f\"[Blending] TrainA: {X_A.shape}, TrainB (meta-train): {X_B.shape}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2) Fit dei base learners su A\n",
    "# -------------------------------------------\n",
    "safe_best_iter = max(100, getattr(best_model, \"best_iteration\", 0))\n",
    "\n",
    "base_learners = {\n",
    "    \"lgb\": TransformedTargetRegressor(\n",
    "        regressor=lgb.LGBMRegressor(\n",
    "            **best_optuna_params,\n",
    "            n_estimators=safe_best_iter,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        func=np.log1p, inverse_func=np.expm1\n",
    "    ),\n",
    "    \"xgb\": TransformedTargetRegressor(\n",
    "        regressor=XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.01,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        func=np.log1p, inverse_func=np.expm1\n",
    "    ),\n",
    "    \"ridge\": TransformedTargetRegressor(\n",
    "        regressor=Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "        func=np.log1p, inverse_func=np.expm1\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, learner in base_learners.items():\n",
    "    learner.fit(preprocessor.fit_transform(X_A), y_A)\n",
    "    logging.info(f\"    ‚Ä¢ Base learner {name} trained on A\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3) Creazione meta-features su B\n",
    "# -------------------------------------------\n",
    "meta_X = np.vstack([\n",
    "    learner.predict(preprocessor.transform(X_B))\n",
    "    for learner in base_learners.values()\n",
    "]).T\n",
    "meta_y = y_B\n",
    "\n",
    "# -------------------------------------------\n",
    "# 4) Nested CV per tuning alpha (meta-learner)\n",
    "# -------------------------------------------\n",
    "inner_tscv = TimeSeriesSplit(n_splits=3)\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "grid_meta = GridSearchCV(\n",
    "    Ridge(random_state=RANDOM_STATE),\n",
    "    param_grid=param_grid,\n",
    "    cv=inner_tscv,\n",
    "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "grid_meta.fit(meta_X, meta_y)\n",
    "best_alpha = grid_meta.best_params_[\"alpha\"]\n",
    "logging.info(f\"üîç Meta-learner best alpha (nested CV): {best_alpha}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 5) Fit finale del meta-learner\n",
    "# -------------------------------------------\n",
    "meta_learner = Ridge(alpha=best_alpha, random_state=RANDOM_STATE)\n",
    "meta_learner.fit(meta_X, meta_y)\n",
    "logging.info(\"    ‚Ä¢ Meta-learner (Ridge) trained on meta-features\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 6) Refit dei base learners su tutto X_full\n",
    "# -------------------------------------------\n",
    "for name, learner in base_learners.items():\n",
    "    learner.fit(preprocessor.fit_transform(X_full), y_full)\n",
    "    logging.info(f\"üîÑ Base learner {name} refit on full training data\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 7) Funzione blending finale\n",
    "# -------------------------------------------\n",
    "def blending_predict(X):\n",
    "    X_enc = preprocessor.transform(X)\n",
    "    base_preds = np.vstack([lm.predict(X_enc) for lm in base_learners.values()]).T\n",
    "    return meta_learner.predict(base_preds)\n",
    "\n",
    "# -------------------------------------------\n",
    "# 8) Prediction Intervals con modelli quantili\n",
    "# -------------------------------------------\n",
    "if \"train_quantile_models\" in globals() and \"predict_with_intervals\" in globals():\n",
    "    quantiles = [0.05, 0.5, 0.95]\n",
    "    quantile_models = train_quantile_models(X_train, y_train, preprocessor, quantiles=quantiles)\n",
    "    pred_intervals = predict_with_intervals(quantile_models, X_test)\n",
    "\n",
    "    interval_cols = [f\"q{int(q*100)}\" for q in quantiles]\n",
    "    lower_col, median_col, upper_col = interval_cols\n",
    "    logging.info(pred_intervals.head().to_string())\n",
    "\n",
    "    lower = pred_intervals[lower_col].to_numpy()\n",
    "    upper = pred_intervals[upper_col].to_numpy()\n",
    "    actual = y_test.to_numpy()\n",
    "\n",
    "    coverage = np.mean((actual >= lower) & (actual <= upper))\n",
    "    avg_width = np.mean(upper - lower)\n",
    "\n",
    "    logging.info(f\"üìä Interval coverage: {coverage:.2%}\")\n",
    "    logging.info(f\"üìä Average interval width: {avg_width:.2f} k‚Ç¨\")\n",
    "else:\n",
    "    logging.warning(\"‚ö†Ô∏è Funzioni per prediction intervals non trovate.\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 9) Valutazione finale sul test set\n",
    "# -------------------------------------------\n",
    "y_pred_blend = blending_predict(X_test)\n",
    "mae_blend    = mean_absolute_error(y_test, y_pred_blend)\n",
    "rmse_blend   = np.sqrt(mean_squared_error(y_test, y_pred_blend))\n",
    "r2_blend     = r2_score(y_test, y_pred_blend)\n",
    "\n",
    "logging.info(\"üìà FINAL BLENDING EVALUATION ON TEST SET\")\n",
    "logging.info(f\"üìä MAE:  {mae_blend:.2f} k‚Ç¨\")\n",
    "logging.info(f\"üìä RMSE: {rmse_blend:.2f} k‚Ç¨\")\n",
    "logging.info(f\"üìä R¬≤:   {r2_blend:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34a30005-753c-4ccf-b502-1b1f3e27be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:29:13,432 [INFO] \n",
      "üîç OVERFITTING ANALYSIS\n",
      "2025-07-29 04:29:13,433 [INFO] ==================================================\n",
      "2025-07-29 04:29:13,433 [INFO] Training MAE: 47.61\n",
      "2025-07-29 04:29:13,434 [INFO] CV MAE:       71.12 ¬± 0.37\n",
      "2025-07-29 04:29:13,434 [INFO] Test MAE:     70.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 47.61067417161766,\n",
       " 'cv': np.float64(71.12312008246451),\n",
       " 'test': 70.35937010121542}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "lgb_pipeline_check = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", clone(base_learners[\"lgb\"]))\n",
    "])\n",
    "lgb_pipeline_check.fit(X_train, y_train)\n",
    "\n",
    "comprehensive_overfitting_check(\n",
    "    pipeline=lgb_pipeline_check,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc1d70-e1f4-48ce-ac17-2592e450c444",
   "metadata": {},
   "source": [
    "## 12. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c1bc313-6854-4dff-bd07-acd9dbf857bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:31:18,662 [INFO] üß† Analyzing feature importances from the LGBM base learner in the blending model...\n",
      "2025-07-29 04:31:19,745 [INFO] üèÜ Top 10 features by gain importance (and permutation):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain_importance</th>\n",
       "      <th>perm_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>size_m2</td>\n",
       "      <td>4161.029167</td>\n",
       "      <td>0.296195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>luxury_score</td>\n",
       "      <td>184.463932</td>\n",
       "      <td>0.019240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>humidity_level</td>\n",
       "      <td>96.978713</td>\n",
       "      <td>0.016821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>temperature_avg</td>\n",
       "      <td>96.681883</td>\n",
       "      <td>0.018135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>distance_to_center_km</td>\n",
       "      <td>93.722536</td>\n",
       "      <td>0.017329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>air_quality_index</td>\n",
       "      <td>89.542683</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>garage_0</td>\n",
       "      <td>84.590403</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>year_built</td>\n",
       "      <td>80.369337</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>noise_level</td>\n",
       "      <td>78.586451</td>\n",
       "      <td>0.012931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>has_balcony_0</td>\n",
       "      <td>35.576559</td>\n",
       "      <td>0.005598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  gain_importance  perm_importance\n",
       "34                size_m2      4161.029167         0.296195\n",
       "44           luxury_score       184.463932         0.019240\n",
       "40         humidity_level        96.978713         0.016821\n",
       "41        temperature_avg        96.681883         0.018135\n",
       "46  distance_to_center_km        93.722536         0.017329\n",
       "43      air_quality_index        89.542683         0.016887\n",
       "28               garage_0        84.590403         0.002879\n",
       "37             year_built        80.369337         0.015748\n",
       "42            noise_level        78.586451         0.012931\n",
       "26          has_balcony_0        35.576559         0.005598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üîç FEATURE IMPORTANCE ANALYSIS (LightGBM base learner)\n",
    "logging.info(\"üß† Analyzing feature importances from the LGBM base learner in the blending model...\")\n",
    "\n",
    "# 1) Estrai i nomi delle feature dopo OneHotEncoder dal preprocessor\n",
    "try:\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"]\n",
    "    encoded_cat = list(ohe.get_feature_names_out(categorical_cols))\n",
    "except Exception as e:\n",
    "    logging.error(f\"‚ùå Errore estrazione OHE features: {e}\")\n",
    "    encoded_cat = []\n",
    "\n",
    "# 2) Combina feature one-hot + numeriche\n",
    "feature_names = encoded_cat + numeric_cols\n",
    "\n",
    "# 3) Estrai il booster LightGBM dal base learner\n",
    "lgb_booster = base_learners[\"lgb\"].regressor_.booster_\n",
    "\n",
    "# 4) Importanza delle feature per gain\n",
    "gain_importances = lgb_booster.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"gain_importance\": gain_importances\n",
    "})\n",
    "\n",
    "# 5) Calcola la permutation importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "try:\n",
    "    # ‚û§ X_test dev'essere preprocessato\n",
    "    X_test_enc = preprocessor.transform(X_test)\n",
    "    # ‚û§ y_test dev'essere trasformato con log1p perch√© usato da .regressor_\n",
    "    y_test_transformed = np.log1p(y_test)\n",
    "\n",
    "    perm = permutation_importance(\n",
    "        estimator=base_learners[\"lgb\"].regressor_,\n",
    "        X=X_test_enc,\n",
    "        y=y_test_transformed,\n",
    "        n_repeats=5,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "\n",
    "    perm_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"perm_importance\": perm.importances_mean\n",
    "    })\n",
    "\n",
    "    feat_imp_df = feat_imp_df.merge(perm_df, on=\"feature\", how=\"left\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"‚ùå Errore durante la permutation importance: {e}\")\n",
    "    feat_imp_df[\"perm_importance\"] = np.nan\n",
    "\n",
    "# 6) Mostra le prime 10\n",
    "top_feats = feat_imp_df.sort_values(\"gain_importance\", ascending=False).head(10)\n",
    "logging.info(\"üèÜ Top 10 features by gain importance (and permutation):\")\n",
    "display(top_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7e416-e4b5-493f-86d4-30f9b02de1b4",
   "metadata": {},
   "source": [
    "## 13. Aggregated Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2bb987e-dafa-4842-9b9c-aefe4593cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:31:24,332 [INFO] üìä Aggregated importance by categorical feature:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregated_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>garage</th>\n",
       "      <td>85.142953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy_class</th>\n",
       "      <td>69.181798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_garden</th>\n",
       "      <td>37.795526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_balcony</th>\n",
       "      <td>36.183501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>21.402892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner_occupied</th>\n",
       "      <td>8.474746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_transport_nearby</th>\n",
       "      <td>3.749451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_elevator</th>\n",
       "      <td>1.781476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         aggregated_importance\n",
       "garage                               85.142953\n",
       "energy_class                         69.181798\n",
       "has_garden                           37.795526\n",
       "has_balcony                          36.183501\n",
       "location                             21.402892\n",
       "owner_occupied                        8.474746\n",
       "public_transport_nearby               3.749451\n",
       "has_elevator                          1.781476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregated_importance</th>\n",
       "      <th>perm_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>garage</th>\n",
       "      <td>85.142953</td>\n",
       "      <td>0.003008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy_class</th>\n",
       "      <td>69.181798</td>\n",
       "      <td>0.004619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_garden</th>\n",
       "      <td>37.795526</td>\n",
       "      <td>0.002258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_balcony</th>\n",
       "      <td>36.183501</td>\n",
       "      <td>0.005997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>21.402892</td>\n",
       "      <td>0.005649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner_occupied</th>\n",
       "      <td>8.474746</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_transport_nearby</th>\n",
       "      <td>3.749451</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_elevator</th>\n",
       "      <td>1.781476</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         aggregated_importance  perm_importance\n",
       "garage                               85.142953         0.003008\n",
       "energy_class                         69.181798         0.004619\n",
       "has_garden                           37.795526         0.002258\n",
       "has_balcony                          36.183501         0.005997\n",
       "location                             21.402892         0.005649\n",
       "owner_occupied                        8.474746         0.002489\n",
       "public_transport_nearby               3.749451         0.000517\n",
       "has_elevator                          1.781476         0.000222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "def get_categorical_importance_summary(\n",
    "    feat_importance: pd.DataFrame,\n",
    "    categorical_cols: List[str],\n",
    "    importance_col: str = \"gain_importance\",\n",
    "    normalize: bool = False\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calcola l'importanza aggregata per ogni colonna categorica originale.\n",
    "    \"\"\"\n",
    "    cat_importance: Dict[str, float] = {}\n",
    "    for col in categorical_cols:\n",
    "        pattern = re.compile(rf\"^{re.escape(col)}_\")\n",
    "        sub_feats = [f for f in feat_importance[\"feature\"] if pattern.match(f)]\n",
    "        if not sub_feats:\n",
    "            cat_importance[col] = 0.0\n",
    "            continue\n",
    "        total = feat_importance.loc[\n",
    "            feat_importance[\"feature\"].isin(sub_feats), importance_col\n",
    "        ].sum()\n",
    "        if normalize:\n",
    "            total /= len(sub_feats)\n",
    "        cat_importance[col] = total\n",
    "    return cat_importance\n",
    "\n",
    "# 1) Calcolo aggregated gain importance\n",
    "cat_imp = get_categorical_importance_summary(\n",
    "    feat_imp_df, categorical_cols, importance_col=\"gain_importance\", normalize=False\n",
    ")\n",
    "cat_importance_df = (\n",
    "    pd.DataFrame.from_dict(cat_imp, orient=\"index\", columns=[\"aggregated_importance\"])\n",
    "    .sort_values(\"aggregated_importance\", ascending=False)\n",
    ")\n",
    "\n",
    "logging.info(\"üìä Aggregated importance by categorical feature:\")\n",
    "display(cat_importance_df)\n",
    "\n",
    "# 2) (Opzionale) Permutation importance se disponibile\n",
    "if \"perm\" in globals():\n",
    "    perm_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"perm_importance\": perm.importances_mean\n",
    "    })\n",
    "    cat_perm: Dict[str, float] = {}\n",
    "    for col in categorical_cols:\n",
    "        pattern = re.compile(rf\"^{re.escape(col)}_\")\n",
    "        sub_feats = [f for f in perm_df[\"feature\"] if pattern.match(f)]\n",
    "        cat_perm[col] = perm_df.loc[\n",
    "            perm_df[\"feature\"].isin(sub_feats), \"perm_importance\"\n",
    "        ].sum() if sub_feats else 0.0\n",
    "    cat_importance_df[\"perm_importance\"] = cat_importance_df.index.map(cat_perm)\n",
    "    display(cat_importance_df)\n",
    "\n",
    "# 3) Plot\n",
    "plt.figure(figsize=(8, len(cat_importance_df) * 0.4))\n",
    "cat_importance_df[\"aggregated_importance\"].plot.barh()\n",
    "plt.xlabel(\"Aggregated Gain Importance\")\n",
    "plt.title(\"Categorical Features Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c11449-9757-42a3-942b-e91ead0c922c",
   "metadata": {},
   "source": [
    "## 14. Save model & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b2e3e4f-8e12-4028-a0c6-de17ea9fc35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 04:32:30,081 [INFO] ‚úÖ Model saved ‚Üí ../models/property/value_regressor_v2.joblib\n",
      "2025-07-29 04:32:30,083 [INFO] üìÑ Metadata saved ‚Üí ../models/property/value_regressor_v2_meta.json\n"
     ]
    }
   ],
   "source": [
    "# === 2) Crea directory di destinazione se non esiste ===\n",
    "os.makedirs(f\"{MODEL_BASE_DIR}/{ASSET_TYPE}\", exist_ok=True)\n",
    "\n",
    "model_version = \"v2\"\n",
    "model_name = f\"value_regressor_{model_version}\"\n",
    "\n",
    "# === 3) Salvataggio modello ===\n",
    "pipeline_filename = f\"{MODEL_BASE_DIR}/{ASSET_TYPE}/{model_name}.joblib\"\n",
    "joblib.dump(pipeline, pipeline_filename)\n",
    "\n",
    "# === 4) Calcolo hash dataset ===\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "\n",
    "# === 5) Feature encodate post-OHE ===\n",
    "ohe = pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "encoded_cat_features = list(ohe.get_feature_names_out(categorical_cols))\n",
    "encoded_feature_names = numeric_cols + encoded_cat_features\n",
    "\n",
    "X_test_enc = pd.DataFrame(preprocessor.transform(X_test), columns=encoded_feature_names)\n",
    "y_pred_test = np.expm1(best_model.predict(X_test_enc))\n",
    "y_true_test = y_test.values\n",
    "\n",
    "# Metriche classiche\n",
    "mae  = mean_absolute_error(y_true_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_test, y_pred_test))\n",
    "r2   = r2_score(y_true_test, y_pred_test)\n",
    "\n",
    "# === 6) Costruzione metadata ===\n",
    "metadata = {\n",
    "    \"asset_type\": ASSET_TYPE,\n",
    "    \"model_task\": \"valuation_regression\",\n",
    "    \"model_version\": model_version,\n",
    "    \"model_class\": \"TransformedTargetRegressor(LightGBM)\",\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"dataset_file\": DATA_PATH,\n",
    "    \"dataset_hash_sha256\": dataset_hash,\n",
    "    \"n_rows_total\": len(df),\n",
    "    \"n_rows_train\": len(X_train),\n",
    "    \"n_rows_test\": len(X_test),\n",
    "    \"features_categorical\": categorical_cols,\n",
    "    \"features_numeric\": numeric_cols,\n",
    "    \"feature_list_ordered\": feature_list,\n",
    "    \"features_encoded\": encoded_feature_names,\n",
    "    \"encoded_feature_count\": len(encoded_feature_names),\n",
    "    \"engineered_features\": [\n",
    "        \"price_per_sqm\",\n",
    "        \"luxury_score\",\n",
    "        \"efficiency_score\",\n",
    "        \"env_score\",\n",
    "        \"age_years\"\n",
    "    ],\n",
    "    \"metrics\": {\n",
    "        \"mae_k\": round(mae, 4),\n",
    "        \"rmse_k\": round(rmse, 4),\n",
    "        \"r2\": round(r2, 4),\n",
    "        \"coverage_interval\": round(coverage, 4),\n",
    "        \"avg_interval_width_k\": round(avg_width, 4)\n",
    "    },\n",
    "    \"prediction_intervals\": {\n",
    "        \"quantiles\": [0.05, 0.5, 0.95],\n",
    "        \"sample_intervals\": pred_intervals.head(5).to_dict(orient=\"records\")\n",
    "    },\n",
    "    \"feature_importance_top10\": feat_imp_df.head(10).to_dict(orient=\"records\"),\n",
    "    \"best_params\": best_optuna_params,\n",
    "    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "}\n",
    "\n",
    "# === 7) Statistiche su feature ingegnerizzate ===\n",
    "engineered_features = [\n",
    "    \"price_per_sqm\",\n",
    "    \"luxury_score\",\n",
    "    \"efficiency_score\",\n",
    "    \"env_score\",\n",
    "    \"age_years\"\n",
    "]\n",
    "\n",
    "metadata[\"engineered_feature_stats\"] = {\n",
    "    feat: {\n",
    "        \"mean\": round(float(df[feat].mean()), 4),\n",
    "        \"min\": round(float(df[feat].min()), 4),\n",
    "        \"max\": round(float(df[feat].max()), 4),\n",
    "    }\n",
    "    for feat in engineered_features if feat in df.columns\n",
    "}\n",
    "\n",
    "# === 8) Salvataggio metadati ===\n",
    "meta_filename = f\"{MODEL_BASE_DIR}/{ASSET_TYPE}/{model_name}_meta.json\"\n",
    "with open(meta_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# === 9) Logging finale ===\n",
    "logging.info(f\"‚úÖ Model saved ‚Üí {pipeline_filename}\")\n",
    "logging.info(f\"üìÑ Metadata saved ‚Üí {meta_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176f573-6659-4010-b6ab-94feaa798cc5",
   "metadata": {},
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7802d-5dec-4b69-bd53-aeed6a907114",
   "metadata": {},
   "source": [
    "- Aggiungi versioning esplicito nei filename dei modelli\n",
    "- Implementa health checks per monitorare drift\n",
    "- Crea script wrapper per esecuzione automatizzata\n",
    "- Aggiungi unit tests per funzioni critiche\n",
    "__________________________\n",
    "__________________________\n",
    "**Prediction Intervals**\n",
    "*Metrica\tValore*\n",
    "*Coverage Interval* (5‚Äì95%)\t76.77%\n",
    "*Average Interval Width*\t211.06 k‚Ç¨\n",
    "\n",
    "- La copertura ideale teorica sarebbe 90% (dal 5¬∞ al 95¬∞ percentile), ma il tuo 76.77% √® buono considerando la non gaussianit√† di molti dati.\n",
    "- L'intervallo medio di 211k‚Ç¨ √® ragionevole, ma puoi agire su alpha, learning_rate o data augmentation per ottimizzarlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
