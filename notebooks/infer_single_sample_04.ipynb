{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "10c75f60-9ee0-42f9-9b6b-21c018a83790",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Imports & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d6afe71-a30b-4efa-b790-baab0312540d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 01) Imports & Config\n",
        "from __future__ import annotations\n",
        "\n",
        "import os, re, json, logging, warnings, hashlib\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional, List, Tuple\n",
        "\n",
        "import joblib                     # type: ignore\n",
        "import numpy as np                # type: ignore\n",
        "import pandas as pd               # type: ignore\n",
        "\n",
        "# sklearn (per verificare che il modello sia fitted)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "# Shared modules (config, utils, constants)\n",
        "from shared.common.config import configure_logger\n",
        "from shared.common.utils import canonical_json_dumps\n",
        "from shared.common.sanity_checks import leakage_gate, scale_gate\n",
        "from shared.common.constants import SCHEMA_VERSION, NOTE_MAX_BYTES\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Setup & Config\n",
        "# -----------------------------------------------------------------------------\n",
        "ASSET_TYPE = \"property\"\n",
        "PREFERRED_MODEL_VERSION = os.getenv(\"MODEL_VERSION\", \"v2\")\n",
        "\n",
        "# Root modelli: ENV → ./outputs/modeling → fallback\n",
        "_candidates: List[Path] = []\n",
        "env_root = os.getenv(\"MODELS_ROOT\")\n",
        "if env_root and env_root.strip():\n",
        "    _candidates.append(Path(env_root))\n",
        "_candidates += [Path(\"./outputs/modeling\")]\n",
        "MODELS_ROOT: Path = next((c for c in _candidates if c.exists()), Path(\"./outputs/modeling\"))\n",
        "MODEL_DIR = MODELS_ROOT / ASSET_TYPE\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Cartelle inference & log\n",
        "INFER_DIR = Path(\"./outputs/inference\")\n",
        "INFER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "LOG_PATH = Path(\"./outputs/logs/predictions_log.jsonl\")\n",
        "LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# API comparison toggle (opzionale)\n",
        "API_BASE = os.getenv(\"API_BASE\", \"http://127.0.0.1:8000\")\n",
        "COMPARE_WITH_API = os.getenv(\"COMPARE_WITH_API\", \"true\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "\n",
        "# Logger\n",
        "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\")\n",
        "LOG_JSON = os.getenv(\"LOG_JSON\", \"false\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "logger = configure_logger(level=LOG_LEVEL, name=\"nb04_infer\", json_format=LOG_JSON)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "logger.info(\"Model roots resolved\", extra={\"MODELS_ROOT\": str(MODELS_ROOT), \"MODEL_DIR\": str(MODEL_DIR)})\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helpers\n",
        "# -----------------------------------------------------------------------------\n",
        "_version_re = re.compile(r\"value_regressor_(v\\d+)\\.joblib$\")\n",
        "\n",
        "def _list_versions(dirpath: Path) -> List[str]:\n",
        "    items: List[Tuple[int, str]] = []\n",
        "    for p in dirpath.glob(\"value_regressor_v*.joblib\"):\n",
        "        m = _version_re.search(p.name)\n",
        "        if not m:\n",
        "            continue\n",
        "        v = m.group(1)  # 'vN'\n",
        "        try:\n",
        "            n = int(v[1:])\n",
        "        except Exception:\n",
        "            n = -1\n",
        "        items.append((n, v))\n",
        "    items.sort(reverse=True)  # dalla più recente\n",
        "    return [v for _, v in items]\n",
        "\n",
        "def _is_fitted(obj) -> bool:\n",
        "    \"\"\"Check fittedness for Pipeline / TTR / base estimator robustly.\"\"\"\n",
        "    try:\n",
        "        if isinstance(obj, TransformedTargetRegressor):\n",
        "            # preferisci l'estimatore interno\n",
        "            est = getattr(obj, \"regressor_\", None) or getattr(obj, \"regressor\", None)\n",
        "            if est is not None:\n",
        "                return _is_fitted(est)\n",
        "            check_is_fitted(obj)  # fallback\n",
        "            return True\n",
        "        if isinstance(obj, Pipeline):\n",
        "            # scendi fino all'ultimo estimatore\n",
        "            last = obj.steps[-1][1]\n",
        "            return _is_fitted(last)\n",
        "        # stimatore base sklearn\n",
        "        check_is_fitted(obj)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _read_json(path: Path) -> Dict[str, Any]:\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def _sha256_file(path: Path) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with path.open(\"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def _dedup_preserve(seq: List[str]) -> List[str]:\n",
        "    seen, out = set(), []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s); out.append(s)\n",
        "    return out\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Resolve a FITTED model (prefer requested version, else newest fitted)\n",
        "# -----------------------------------------------------------------------------\n",
        "def resolve_fitted_model(base_dir: Path, preferred: Optional[str]) -> Dict[str, Any]:\n",
        "    # 1) tenta versione preferita\n",
        "    if preferred:\n",
        "        p = base_dir / f\"value_regressor_{preferred}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{preferred}_meta.json\"\n",
        "        if p.exists() and m.exists():\n",
        "            pl = joblib.load(p)\n",
        "            if _is_fitted(pl):\n",
        "                return {\n",
        "                    \"version\": preferred,\n",
        "                    \"pipeline\": p,\n",
        "                    \"meta\": m,\n",
        "                    \"manifest\": base_dir / \"training_manifest.json\",\n",
        "                    \"obj\": pl,\n",
        "                }\n",
        "            logger.warning(\"Model %s presente ma non fitted; cerco fallback…\", preferred)\n",
        "\n",
        "    # 2) cerca la più recente fitted tra le disponibili\n",
        "    for ver in _list_versions(base_dir):\n",
        "        p = base_dir / f\"value_regressor_{ver}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{ver}_meta.json\"\n",
        "        if not (p.exists() and m.exists()):\n",
        "            continue\n",
        "        pl = joblib.load(p)\n",
        "        if _is_fitted(pl):\n",
        "            return {\n",
        "                \"version\": ver,\n",
        "                \"pipeline\": p,\n",
        "                \"meta\": m,\n",
        "                \"manifest\": base_dir / \"training_manifest.json\",\n",
        "                \"obj\": pl,\n",
        "            }\n",
        "\n",
        "    raise FileNotFoundError(f\"Nessun modello fitted trovato in {base_dir}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Load pipeline & metadata (fitted fallback) + expected features\n",
        "# -----------------------------------------------------------------------------\n",
        "resolved = resolve_fitted_model(MODEL_DIR, PREFERRED_MODEL_VERSION)\n",
        "MODEL_VERSION: str = resolved[\"version\"]\n",
        "PIPELINE_PATH: Path = resolved[\"pipeline\"]\n",
        "META_PATH: Path = resolved[\"meta\"]\n",
        "MANIFEST_PATH: Path = resolved[\"manifest\"]\n",
        "pipeline = resolved[\"obj\"]\n",
        "\n",
        "logger.info(\n",
        "    \"Using model artifacts\",\n",
        "    extra={\n",
        "        \"asset_type\": ASSET_TYPE,\n",
        "        \"model_version\": MODEL_VERSION,\n",
        "        \"pipeline\": str(PIPELINE_PATH),\n",
        "        \"meta\": str(META_PATH),\n",
        "        \"manifest\": str(MANIFEST_PATH) if MANIFEST_PATH.exists() else None,\n",
        "    },\n",
        ")\n",
        "\n",
        "# integrità bundle (hash del joblib)\n",
        "model_meta: Dict[str, Any] = _read_json(META_PATH)\n",
        "expected_hash = model_meta.get(\"model_hash\") or model_meta.get(\"pipeline_sha256\")\n",
        "actual_hash = _sha256_file(PIPELINE_PATH)\n",
        "if expected_hash and expected_hash != actual_hash:\n",
        "    raise ValueError(\n",
        "        f\"Bundle manomesso: meta={expected_hash[:8]}… != actual={actual_hash[:8]}…\"\n",
        "    )\n",
        "\n",
        "# expected features: preferisci feature_order.json → poi manifest → infine meta.json\n",
        "feature_order_candidates: List[Path] = [PIPELINE_PATH.parent / \"feature_order.json\"]\n",
        "manifest: Dict[str, Any] = {}\n",
        "if MANIFEST_PATH.exists():\n",
        "    try:\n",
        "        manifest = _read_json(MANIFEST_PATH)\n",
        "        p_from_manifest = manifest.get(\"paths\", {}).get(\"feature_order\")\n",
        "        if p_from_manifest:\n",
        "            feature_order_candidates.insert(0, Path(p_from_manifest))\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Manifest presente ma non leggibile; fallback a meta.json\", extra={\"error\": str(e)})\n",
        "\n",
        "FEATURE_ORDER_PATH: Optional[Path] = next((p for p in feature_order_candidates if p and p.exists()), None)\n",
        "\n",
        "categorical_expected: List[str] = list(model_meta.get(\"features_categorical\", []) or [])\n",
        "numeric_expected: List[str] = list(model_meta.get(\"features_numeric\", []) or [])\n",
        "\n",
        "if FEATURE_ORDER_PATH:\n",
        "    try:\n",
        "        feature_order: List[str] = _read_json(FEATURE_ORDER_PATH)\n",
        "        ALL_EXPECTED: List[str] = list(feature_order)\n",
        "    except Exception as e:\n",
        "        logger.warning(\"feature_order.json non leggibile; uso meta/manifest\", extra={\"error\": str(e)})\n",
        "        ALL_EXPECTED = _dedup_preserve(categorical_expected + [c for c in numeric_expected if c not in categorical_expected])\n",
        "else:\n",
        "    # fallback senza feature_order.json → prova anche il manifest\n",
        "    try:\n",
        "        feats_from_manifest = (manifest.get(\"feature_order\")\n",
        "                               or manifest.get(\"expected_features\")\n",
        "                               or manifest.get(\"model\", {}).get(\"feature_list\")\n",
        "                               or manifest.get(\"model\", {}).get(\"features\"))\n",
        "        if isinstance(feats_from_manifest, dict):\n",
        "            categorical_expected = feats_from_manifest.get(\"categorical\", categorical_expected) or categorical_expected\n",
        "            numeric_expected = feats_from_manifest.get(\"numeric\", numeric_expected) or numeric_expected\n",
        "        elif isinstance(feats_from_manifest, list):\n",
        "            categorical_expected = categorical_expected  # invariato\n",
        "            numeric_expected = numeric_expected          # invariato\n",
        "            ALL_EXPECTED = list(map(str, feats_from_manifest))\n",
        "    except Exception:\n",
        "        pass\n",
        "    if 'ALL_EXPECTED' not in globals():\n",
        "        ALL_EXPECTED = _dedup_preserve(categorical_expected + [c for c in numeric_expected if c not in categorical_expected])\n",
        "\n",
        "print(f\"✅ Loaded FITTED model {MODEL_VERSION} from {PIPELINE_PATH.parent}\")\n",
        "print(f\"   Features: {len(ALL_EXPECTED)} (cat={len(categorical_expected)}, num={len(numeric_expected)})\")\n",
        "print(f\"   Inference dir: {INFER_DIR.as_posix()}\")\n",
        "print(f\"   API compare: {COMPARE_WITH_API} → {API_BASE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d55eb44-9ea4-4092-a3d1-7c910a6c2e76",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Input Schema & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9985cd-a991-4471-8629-63b656695c92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 02) Input Schema & Validation (aliases, safe-derives, domain checks, JSON-schema)\n",
        "\n",
        "from __future__ import annotations\n",
        "from typing import Dict, Any, Tuple, Optional, List\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from shared.common.pricing import explain_price\n",
        "from shared.common.constants import LOCATION, SCHEMA_VERSION as _DEF_SCHEMA_VER, NOTE_MAX_BYTES\n",
        "from shared.common.utils import canonical_location, get_utc_now, NumpyJSONEncoder\n",
        "from shared.common.sanity_checks import price_benchmark, validate_property\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# A) INPUT utilities: alias → canonico, derivate **non-leaky**, validator\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "# Alias comuni → chiavi canoniche (soft matching su lower-case)\n",
        "_CANONICAL_ALIASES = {\n",
        "    \"sqm\": \"size_m2\", \"size\": \"size_m2\", \"m2\": \"size_m2\",\n",
        "    \"year\": \"year_built\", \"built_year\": \"year_built\",\n",
        "    \"balcony\": \"has_balcony\", \"garden\": \"has_garden\", \"garage\": \"has_garage\",\n",
        "    \"air_quality\": \"air_quality_index\", \"noise\": \"noise_level\",\n",
        "    \"valuation\": \"valuation_k\", \"price_k\": \"valuation_k\",\n",
        "}\n",
        "\n",
        "# Derivate consentite (no leakage dal target)\n",
        "_SAFE_DERIVED = {\"age_years\", \"luxury_score\", \"env_score\"}\n",
        "\n",
        "def _canonicalize_keys(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Mappa alias comuni verso i nomi campo canonici (lower-case keys).\"\"\"\n",
        "    out: Dict[str, Any] = {}\n",
        "    for k, v in record.items():\n",
        "        k_lc = (str(k) if k is not None else \"\").strip().lower()\n",
        "        out[_CANONICAL_ALIASES.get(k_lc, k_lc)] = v\n",
        "    return out\n",
        "\n",
        "def _autofill_safe(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Deriva SOLO campi sicuri:\n",
        "      - age_years da year_built\n",
        "      - luxury_score: media di has_garden / has_balcony / has_garage\n",
        "      - env_score: combinazione di air_quality_index (↑) e noise_level (↓) normalizzati in [0,1]\n",
        "    \"\"\"\n",
        "    r = dict(record)\n",
        "\n",
        "    # age_years\n",
        "    if \"age_years\" not in r and r.get(\"year_built\") not in (None, \"\"):\n",
        "        try:\n",
        "            r[\"age_years\"] = max(0, get_utc_now().year - int(r[\"year_built\"]))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # luxury_score (0..1)\n",
        "    if \"luxury_score\" not in r:\n",
        "        g = 1.0 if bool(r.get(\"has_garden\", 0)) else 0.0\n",
        "        b = 1.0 if bool(r.get(\"has_balcony\", 0)) else 0.0\n",
        "        ga = 1.0 if bool(r.get(\"has_garage\", 0)) else 0.0\n",
        "        r[\"luxury_score\"] = float((g + b + ga) / 3.0)\n",
        "\n",
        "    # env_score (0..1): aria buona * (1 - rumore)\n",
        "    if \"env_score\" not in r:\n",
        "        try:\n",
        "            aq = float(r.get(\"air_quality_index\", 0.0))\n",
        "            nz = float(r.get(\"noise_level\", 0.0))\n",
        "            aq_n = float(np.clip(aq / 100.0, 0.0, 1.0))\n",
        "            nz_n = float(np.clip(nz / 100.0, 0.0, 1.0))\n",
        "            r[\"env_score\"] = float(np.clip(aq_n * (1.0 - nz_n), 0.0, 1.0))\n",
        "        except Exception:\n",
        "            r[\"env_score\"] = None\n",
        "\n",
        "    return r\n",
        "\n",
        "def validate_input_record(\n",
        "    record: Dict[str, Any],\n",
        "    *,\n",
        "    strict: bool = True,\n",
        "    drop_extras: bool = True,\n",
        "    allowed_features: Optional[List[str]] = None,\n",
        ") -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Canonicalizza → deriva campi sicuri → **VALIDA su versione di dominio** → filtra per il modello.\n",
        "    Ritorna (record_per_modello, report_validator).\n",
        "    \"\"\"\n",
        "    # Snapshot dominio (no rinomina) per il validator\n",
        "    dom = dict(record)\n",
        "    if LOCATION in dom and dom.get(LOCATION):\n",
        "        try:\n",
        "            dom[LOCATION] = canonical_location(dom[LOCATION])\n",
        "        except Exception:\n",
        "            pass\n",
        "    dom.setdefault(\"asset_type\", \"property\")\n",
        "    dom.setdefault(\"last_verified_ts\", get_utc_now().replace(microsecond=0).isoformat().replace(\"+00:00\",\"Z\"))\n",
        "\n",
        "    # Versione per il modello: alias + derive + normalizzazione location\n",
        "    base = _canonicalize_keys(record)\n",
        "    base = _autofill_safe(base)\n",
        "    if LOCATION in base and base.get(LOCATION):\n",
        "        try:\n",
        "            base[LOCATION] = canonical_location(base[LOCATION])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Validazione di dominio\n",
        "    report = validate_property(dom)\n",
        "    if strict and not report.get(\"ok\", True):\n",
        "        raise ValueError(f\"❌ Property validation failed: {report.get('errors') or report}\")\n",
        "\n",
        "    # Filtra extra: consentiti = ALL_EXPECTED (se globale) ∪ derivate sicure\n",
        "    allowed = set(allowed_features or globals().get(\"ALL_EXPECTED\", [])).union(_SAFE_DERIVED)\n",
        "    extras = [k for k in list(base.keys()) if k not in allowed] if allowed else []\n",
        "    if drop_extras:\n",
        "        for k in extras:\n",
        "            base.pop(k, None)\n",
        "    elif strict and extras:\n",
        "        raise ValueError(f\"❌ Unexpected extra features: {extras}\")\n",
        "\n",
        "    return base, report\n",
        "\n",
        "def detect_anomalies(record: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:\n",
        "    \"\"\"True se il validator riporta blocker (fuori dominio, misure impossibili).\"\"\"\n",
        "    _, report = validate_input_record(record, strict=False)\n",
        "    return (not report.get(\"ok\", True)), report\n",
        "\n",
        "def _maybe_explain_price(rec: dict) -> dict | None:\n",
        "    \"\"\"Breakdown euristico del prezzo (no ML), utile per UI/trasparenza.\"\"\"\n",
        "    try:\n",
        "        return explain_price(rec)\n",
        "    except Exception as e:\n",
        "        try: logger.info(\"explain_price unavailable\", extra={\"error\": str(e)})\n",
        "        except Exception: pass\n",
        "        return None\n",
        "\n",
        "def _price_benchmark_flag(rec: dict, yhat_k: float) -> dict | None:\n",
        "    \"\"\"Flag 'fuori banda' rispetto a profili location-based (se disponibili).\"\"\"\n",
        "    try:\n",
        "        return price_benchmark(location=rec.get(\"location\"), valuation_k=float(yhat_k))\n",
        "    except Exception as e:\n",
        "        try: logger.info(\"price_benchmark unavailable\", extra={\"error\": str(e)})\n",
        "        except Exception: pass\n",
        "        return None\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# B) OUTPUT JSON-schema validation (riusabile per single + batch)\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "try:\n",
        "    # usa il validator più recente se presente\n",
        "    from jsonschema import Draft202012Validator as _Validator\n",
        "except Exception:\n",
        "    from jsonschema import Draft7Validator as _Validator  # type: ignore\n",
        "\n",
        "def _norm_schema_tag(ver: str) -> str:\n",
        "    \"\"\"'2'/'2.0'/'v2' → 'v2' ; altrimenti lower verbatim.\"\"\"\n",
        "    v = (ver or \"\").strip().lower()\n",
        "    if v in {\"2\", \"2.0\", \"02\", \"v2\"}: return \"v2\"\n",
        "    return v if v.startswith(\"v\") else v\n",
        "\n",
        "def _to_jsonable(obj: dict) -> dict:\n",
        "    \"\"\"Converte tipi NumPy in JSON-safe.\"\"\"\n",
        "    return json.loads(json.dumps(obj, cls=NumpyJSONEncoder, ensure_ascii=False))\n",
        "\n",
        "def _format_error(e) -> str:\n",
        "    path = \".\".join(str(p) for p in getattr(e, \"path\", [])) or \"<root>\"\n",
        "    spath = \" → \".join(str(p) for p in getattr(e, \"schema_path\", []))\n",
        "    return f\"at '{path}': {getattr(e,'message','error')}  [schema: {spath}]\"\n",
        "\n",
        "def _deep_keys(d, prefix=\"\"):\n",
        "    keys = set()\n",
        "    if isinstance(d, dict):\n",
        "        for k, v in d.items():\n",
        "            newp = f\"{prefix}.{k}\" if prefix else k\n",
        "            keys.add(newp)\n",
        "            keys |= _deep_keys(v, newp)\n",
        "    elif isinstance(d, list):\n",
        "        if d:\n",
        "            keys |= _deep_keys(d[0], prefix + \"[]\")\n",
        "        else:\n",
        "            keys.add(prefix + \"[]\")\n",
        "    return keys\n",
        "\n",
        "def validate_outputs(\n",
        "    single_output: Optional[dict] = None,\n",
        "    batch_outputs: Optional[List[dict]] = None,\n",
        "    *,\n",
        "    schema_version: Optional[str] = None,\n",
        "    schemas_dir: Path = Path(\"../schemas\"),\n",
        "    example_filename: str = \"output_example.json\",\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Valida single_output e/o batch_outputs contro lo schema JSON.\n",
        "    Ritorna un report con esiti e differenze profonde vs esempio (se presente).\n",
        "    \"\"\"\n",
        "    report = {\n",
        "        \"schema\": None,\n",
        "        \"single_ok\": None,\n",
        "        \"batch_ok\": None,\n",
        "        \"batch_error_count\": 0,\n",
        "        \"extra_vs_example\": [],\n",
        "        \"missing_vs_example\": [],\n",
        "    }\n",
        "\n",
        "    # Seleziona schema\n",
        "    tag = _norm_schema_tag(schema_version or _DEF_SCHEMA_VER)\n",
        "    schema_path = schemas_dir / f\"output_schema_{tag}.json\"\n",
        "    if not schema_path.exists():\n",
        "        schema_path = schemas_dir / f\"output_schema_{_norm_schema_tag(_DEF_SCHEMA_VER)}.json\"\n",
        "    if not schema_path.exists():\n",
        "        schema_path = schemas_dir / \"output_schema_v1.json\"\n",
        "\n",
        "    if not schema_path.exists():\n",
        "        msg = f\"❌ Schema file not found: {schema_path}\"\n",
        "        print(msg)\n",
        "        return report\n",
        "\n",
        "    schema = json.loads(schema_path.read_text(encoding=\"utf-8\"))\n",
        "    report[\"schema\"] = schema_path.name\n",
        "    print(f\"🔎 Using schema: {schema_path.name}\")\n",
        "\n",
        "    # Single\n",
        "    if single_output is not None:\n",
        "        from jsonschema import validate, ValidationError\n",
        "        try:\n",
        "            validate(instance=_to_jsonable(single_output), schema=schema)\n",
        "            print(\"✅ Strict schema validation passed (single_output).\")\n",
        "            report[\"single_ok\"] = True\n",
        "        except ValidationError as e:\n",
        "            print(\"❌ Strict schema validation failed (single_output):\", _format_error(e))\n",
        "            report[\"single_ok\"] = False\n",
        "\n",
        "        # Deep diff vs example (se disponibile)\n",
        "        ex_path = schemas_dir / example_filename\n",
        "        if ex_path.exists():\n",
        "            example = json.loads(ex_path.read_text(encoding=\"utf-8\"))\n",
        "            ex_keys = _deep_keys(example)\n",
        "            out_keys = _deep_keys(single_output)\n",
        "            extra = sorted(out_keys - ex_keys)\n",
        "            missing = sorted(ex_keys - out_keys)\n",
        "            report[\"extra_vs_example\"] = extra\n",
        "            report[\"missing_vs_example\"] = missing\n",
        "            if not extra and not missing:\n",
        "                print(\"✅ single_output matches example structure (deep).\")\n",
        "            else:\n",
        "                if extra:\n",
        "                    head = extra[:10]\n",
        "                    print(\"⚠️ Extra keys vs example (deep):\", head, (\"…+\" if len(extra) > 10 else \"\"))\n",
        "                if missing:\n",
        "                    head = missing[:10]\n",
        "                    print(\"⚠️ Missing keys vs example (deep):\", head, (\"…+\" if len(missing) > 10 else \"\"))\n",
        "\n",
        "    # Batch\n",
        "    if batch_outputs:\n",
        "        validator = _Validator(schema)\n",
        "        errors = []\n",
        "        for idx, rec in enumerate(batch_outputs, start=1):\n",
        "            for err in validator.iter_errors(_to_jsonable(rec)):\n",
        "                errors.append((idx, err))\n",
        "        if not errors:\n",
        "            print(f\"✅ Batch outputs: all {len(batch_outputs)} records pass schema validation.\")\n",
        "            report[\"batch_ok\"] = True\n",
        "        else:\n",
        "            print(f\"❌ Batch outputs: {len(errors)} schema errors found on {len(set(i for i, _ in errors))} records.\")\n",
        "            for i, err in errors[:5]:\n",
        "                print(f\"   • [#{i}] {_format_error(err)}\")\n",
        "            if len(errors) > 5:\n",
        "                print(f\"   … and {len(errors)-5} more\")\n",
        "            report[\"batch_ok\"] = False\n",
        "            report[\"batch_error_count\"] = len(errors)\n",
        "\n",
        "    return report\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# C) Auto-run (solo se chi ha già calcolato single_output / batch_outputs)\n",
        "# ---------------------------------------------------------------------\n",
        "if \"single_output\" in globals() or \"batch_outputs\" in globals():\n",
        "    _so = globals().get(\"single_output\")\n",
        "    _bo = globals().get(\"batch_outputs\")\n",
        "    _ = validate_outputs(single_output=_so, batch_outputs=_bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0341141f-3525-4d22-92f8-a68edc266946",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Sample + Predict (+CI) + Drift + Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d920b40-4628-4766-a1f0-231f3487d26d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# R3) Sample → Single Predict → Batch (refactor unico, riusa helpers esistenti)\n",
        "\n",
        "from __future__ import annotations\n",
        "from uuid import uuid4\n",
        "from copy import deepcopy\n",
        "from typing import List\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from shared.common.constants import ASSET_ID, LOCATION\n",
        "\n",
        "# --- A) Sample grezzo (puoi modificare qui liberamente)\n",
        "sample_property_raw = {\n",
        "    \"location\": \"Milan\",\n",
        "    \"size_m2\": 120,\n",
        "    \"rooms\": 4,\n",
        "    \"bathrooms\": 2,\n",
        "    \"year_built\": 1999,\n",
        "    \"floor\": 2,\n",
        "    \"building_floors\": 6,\n",
        "    \"has_elevator\": 1,\n",
        "    \"has_garden\": 0,\n",
        "    \"has_balcony\": 1,\n",
        "    \"has_garage\": 1,\n",
        "    \"energy_class\": \"B\",\n",
        "    \"humidity_level\": 50.0,\n",
        "    \"temperature_avg\": 20.5,\n",
        "    \"noise_level\": 40,\n",
        "    \"air_quality_index\": 70,\n",
        "    \"owner_occupied\": 1,\n",
        "    \"public_transport_nearby\": 1,\n",
        "    \"distance_to_center_km\": 2.5,\n",
        "}\n",
        "\n",
        "# --- B) Validazione + normalizzazioni leggere (riusa la tua cella di validazione)\n",
        "sample_property, validation_report = validate_input_record(sample_property_raw, strict=True)\n",
        "\n",
        "# boolean-like → {0,1} (coerenza con serving/schema)\n",
        "_bool_like = [k for k in sample_property if k.startswith(\"has_\")] + [\"owner_occupied\", \"public_transport_nearby\"]\n",
        "for k in _bool_like:\n",
        "    if k in sample_property:\n",
        "        sample_property[k] = int(bool(sample_property[k]))\n",
        "\n",
        "# asset_id sintetico se mancante (non è feature del modello)\n",
        "if not sample_property.get(ASSET_ID):\n",
        "    sample_property[ASSET_ID] = f\"asset_infer_{uuid4().hex[:8]}\"\n",
        "\n",
        "print(f\"✅ Sample validated. asset_id={sample_property.get(ASSET_ID)}  location={sample_property.get(LOCATION)}\")\n",
        "\n",
        "# --- C) Predizione singola con API locale (predict_asset) — nessuna duplicazione\n",
        "t0 = time.perf_counter()\n",
        "single_output = predict_asset(sample_property, asset_id=sample_property.get(ASSET_ID))\n",
        "latency_ms_single = round((time.perf_counter() - t0) * 1000, 2)\n",
        "\n",
        "print(\n",
        "    f\"ŷ_single = {single_output['metrics']['valuation_k']:.2f} k€  \"\n",
        "    f\"(±{single_output['metrics']['ci_margin_k']:.2f} @ {int(single_output['metrics']['confidence']*100)}%)\"\n",
        ")\n",
        "\n",
        "# --- D) Batch inference (esempi variati) — riusa predict_asset\n",
        "batch_samples: List[dict] = [\n",
        "    deepcopy(sample_property),\n",
        "    {**sample_property, ASSET_ID: None, LOCATION: \"Rome\",     \"size_m2\":  90, \"energy_class\": \"C\"},\n",
        "    {**sample_property, ASSET_ID: None, LOCATION: \"Florence\", \"size_m2\":  70, \"has_garden\": 1, \"energy_class\": \"A\"},\n",
        "    {**sample_property, ASSET_ID: None, LOCATION: \"Turin\",    \"size_m2\": 150, \"energy_class\": \"D\"},\n",
        "]\n",
        "\n",
        "batch_outputs: List[dict] = []\n",
        "for i, raw in enumerate(batch_samples, start=1):\n",
        "    out = predict_asset(raw, asset_id=raw.get(ASSET_ID) or f\"asset_batch_{i:03}\")\n",
        "    batch_outputs.append(out)\n",
        "\n",
        "# Riepilogo compatto batch\n",
        "pd.DataFrame([{\"asset_id\": o[\"asset_id\"], \"valuation_k\": o[\"metrics\"][\"valuation_k\"]} for o in batch_outputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1379e002-a49d-4baa-8bb4-bcba298e5744",
      "metadata": {},
      "outputs": [],
      "source": [
        "# R4) Compact Note (idempotente) — riusa single_output\n",
        "from shared.common.utils import canonical_json_dumps, sha256_hex\n",
        "from shared.common.constants import NOTE_MAX_BYTES\n",
        "\n",
        "def build_compact_note(out: dict) -> dict:\n",
        "    return {\n",
        "        \"schema_version\": \"v2\",\n",
        "        \"asset_id\": out[\"asset_id\"],\n",
        "        \"asset_type\": out[\"asset_type\"],\n",
        "        \"timestamp\": out[\"timestamp\"],\n",
        "        \"model\": {\n",
        "            \"version\": out[\"model_meta\"][\"value_model_version\"],\n",
        "            \"hash\": model_meta.get(\"pipeline_sha256\") or model_meta.get(\"model_hash\"),\n",
        "        },\n",
        "        \"metrics\": {\n",
        "            \"valuation_k\": out[\"metrics\"][\"valuation_k\"],\n",
        "            \"confidence\": out[\"metrics\"][\"confidence\"],\n",
        "            \"ci\": [out[\"metrics\"][\"confidence_low_k\"], out[\"metrics\"][\"confidence_high_k\"]],\n",
        "        },\n",
        "    }\n",
        "\n",
        "note = build_compact_note(single_output)\n",
        "note_bytes = canonical_json_dumps(note).encode(\"utf-8\")\n",
        "note_size = len(note_bytes)\n",
        "note_sha256 = sha256_hex(note_bytes)\n",
        "\n",
        "single_output.setdefault(\"publish\", {}).update({\n",
        "    \"status\": \"skipped\",\n",
        "    \"note_size\": note_size,\n",
        "    \"note_sha256\": note_sha256,\n",
        "    \"is_compacted\": True,\n",
        "    \"fallback_url_used\": False,\n",
        "})\n",
        "\n",
        "assert note_size <= NOTE_MAX_BYTES, f\"Nota troppo grande: {note_size} > {NOTE_MAX_BYTES}\"\n",
        "print(f\"Note size={note_size} bytes | sha256={note_sha256[:16]}…\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b30533-6431-4327-8c9a-b781ecd1601f",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Logging JSONL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4b3446-a1ba-4b53-9cd2-83ae069e8b1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# L1) JSONL Logging (atomic append) — predictions & monitoring\n",
        "from __future__ import annotations\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import os, json\n",
        "\n",
        "from shared.common.utils import canonical_json_dumps, get_utc_now\n",
        "\n",
        "MONITOR_LOG_PATH = Path(\"./outputs/logs/monitoring_log.jsonl\")\n",
        "LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "MONITOR_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def append_jsonl(record: dict, path: Path) -> None:\n",
        "    \"\"\"Append atomico JSONL con timestamp UTC 'Z' + fsync.\"\"\"\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    payload = {**record, \"_logged_at\": get_utc_now().replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")}\n",
        "    line = canonical_json_dumps(payload)\n",
        "    fd = os.open(str(path), os.O_WRONLY | os.O_CREAT | os.O_APPEND)\n",
        "    try:\n",
        "        with os.fdopen(fd, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(line + \"\\n\")\n",
        "            f.flush()\n",
        "            os.fsync(f.fileno())\n",
        "    except Exception:\n",
        "        try: os.close(fd)\n",
        "        except Exception: pass\n",
        "        raise\n",
        "\n",
        "def _to_monitoring(entry: dict) -> dict:\n",
        "    m  = entry.get(\"metrics\", {}) or {}\n",
        "    mm = entry.get(\"model_meta\", {}) or {}\n",
        "    return {\n",
        "        \"asset_id\": entry.get(\"asset_id\"),\n",
        "        \"model_version\": mm.get(\"value_model_version\", MODEL_VERSION),\n",
        "        \"model_class\": mm.get(\"value_model_name\"),\n",
        "        \"latency_ms\": m.get(\"latency_ms\"),\n",
        "        \"valuation_k\": m.get(\"valuation_k\") or m.get(\"valuation_base_k\"),\n",
        "        \"uncertainty_k\": m.get(\"uncertainty_k\") or m.get(\"uncertainty\"),\n",
        "        \"confidence_low_k\": m.get(\"confidence_low_k\"),\n",
        "        \"confidence_high_k\": m.get(\"confidence_high_k\"),\n",
        "        \"ci_method\": m.get(\"ci_method\"),\n",
        "        \"n_estimators\": m.get(\"n_estimators\"),\n",
        "        \"anomaly\": (entry.get(\"flags\") or {}).get(\"anomaly\"),\n",
        "        \"drift_detected\": (entry.get(\"flags\") or {}).get(\"drift_detected\"),\n",
        "    }\n",
        "\n",
        "# --- write predictions log ---\n",
        "n_batch = len(globals().get(\"batch_outputs\", []) or [])\n",
        "if \"single_output\" in globals():\n",
        "    append_jsonl(single_output, LOG_PATH)\n",
        "for o in (globals().get(\"batch_outputs\", []) or []):\n",
        "    append_jsonl(o, LOG_PATH)\n",
        "print(f\"Appended {int('single_output' in globals()) + n_batch} predictions → {LOG_PATH}\")\n",
        "\n",
        "# --- write monitoring log (derived) ---\n",
        "if \"single_output\" in globals():\n",
        "    append_jsonl(_to_monitoring(single_output), MONITOR_LOG_PATH)\n",
        "for o in (globals().get(\"batch_outputs\", []) or []):\n",
        "    append_jsonl(_to_monitoring(o), MONITOR_LOG_PATH)\n",
        "print(f\"Appended monitoring for {int('single_output' in globals()) + n_batch} records → {MONITOR_LOG_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b507a90c-a003-40e6-a97c-d4763895ba1c",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Sensitivity Check (vary size_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1622a58-f3cd-47b3-8e5b-efe2cc2eadcd",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# L2) Sensitivity (“what-if”) su size_m2 — riusa predict_asset (no duplicazioni)\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "sizes = [60, 90, 130, 170, 210]\n",
        "rows  = []\n",
        "\n",
        "# baseline dal sample già validato (usa predict_asset per coerenza)\n",
        "_base = predict_asset(sample_property, asset_id=\"asset_sensitivity_base\")\n",
        "base_pred = float(_base[\"metrics\"][\"valuation_k\"])\n",
        "\n",
        "for s in sizes:\n",
        "    rec_raw = {**sample_property, \"size_m2\": s}\n",
        "    try:\n",
        "        out = predict_asset(rec_raw, asset_id=f\"asset_size_{s}\")\n",
        "        ci_low  = out[\"metrics\"][\"confidence_low_k\"]\n",
        "        ci_high = out[\"metrics\"][\"confidence_high_k\"]\n",
        "        rows.append({\n",
        "            \"size_m2\": s,\n",
        "            \"prediction_k\": out[\"metrics\"][\"valuation_k\"],\n",
        "            \"ci_low_k\": ci_low,\n",
        "            \"ci_high_k\": ci_high,\n",
        "            \"ci_margin_k\": out[\"metrics\"][\"ci_margin_k\"],\n",
        "            \"uncertainty_k\": out[\"metrics\"][\"uncertainty_k\"],\n",
        "            \"delta_vs_base_k\": round(out[\"metrics\"][\"valuation_k\"] - base_pred, 3),\n",
        "        })\n",
        "    except Exception as e:\n",
        "        rows.append({\"size_m2\": s, \"prediction_k\": None, \"error\": str(e)})\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
        "pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84f9f3e-aaad-4843-a735-1c388f17da55",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### API Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40996a99-ed49-473f-8ddb-74d5d36f932d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# L3) API checks (consistency + optional publish) — unificata\n",
        "import os, json, time\n",
        "import requests\n",
        "from uuid import uuid4\n",
        "from shared.common.utils import NumpyJSONEncoder\n",
        "\n",
        "if COMPARE_WITH_API:\n",
        "    def _pick_pred_metrics(payload: dict):\n",
        "        \"\"\"Estrae predizione/CI da response v1/v2/flat.\"\"\"\n",
        "        if not isinstance(payload, dict):\n",
        "            return None, None, None, None\n",
        "        m = payload.get(\"metrics\", {}) if isinstance(payload.get(\"metrics\"), dict) else {}\n",
        "        pred = (m.get(\"valuation_k\") or m.get(\"valuation_base_k\")\n",
        "                or m.get(\"valuation\") or payload.get(\"valuation_k\")\n",
        "                or payload.get(\"prediction\"))\n",
        "        ci_low  = m.get(\"confidence_low_k\")  or payload.get(\"confidence_low_k\")\n",
        "        ci_high = m.get(\"confidence_high_k\") or payload.get(\"confidence_high_k\")\n",
        "        unc     = m.get(\"uncertainty_k\")     or m.get(\"uncertainty\") or payload.get(\"uncertainty_k\")\n",
        "        return pred, ci_low, ci_high, unc\n",
        "\n",
        "    def _model_version(payload: dict):\n",
        "        mm = (payload or {}).get(\"model_meta\", {}) if isinstance(payload, dict) else {}\n",
        "        return mm.get(\"value_model_version\") or mm.get(\"model_version\")\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\", \"X-Idempotency-Key\": uuid4().hex}\n",
        "    token = os.getenv(\"AXM_TOKEN\")\n",
        "    if token:\n",
        "        headers[\"Authorization\"] = f\"Bearer {token}\"\n",
        "\n",
        "    url = f\"{API_BASE}/predict/{ASSET_TYPE}\"\n",
        "\n",
        "    # --- A) Consistency: confronta la singola locale vs API ---\n",
        "    try:\n",
        "        payload_json = json.loads(json.dumps(sample_property, cls=NumpyJSONEncoder, ensure_ascii=False))\n",
        "        t0 = time.perf_counter()\n",
        "        resp = requests.post(url, json=payload_json, headers=headers, timeout=10)\n",
        "        lat_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "        if resp.ok:\n",
        "            api_json = resp.json()\n",
        "            api_pred, api_low, api_high, api_unc = _pick_pred_metrics(api_json)\n",
        "            if api_pred is None:\n",
        "                print(f\"[API] ❌ OK ma 'metrics.valuation_*' mancante.\")\n",
        "            else:\n",
        "                local_pred = float(single_output[\"metrics\"][\"valuation_k\"])\n",
        "                local_low  = float(single_output[\"metrics\"][\"confidence_low_k\"])\n",
        "                local_high = float(single_output[\"metrics\"][\"confidence_high_k\"])\n",
        "                delta = abs(float(api_pred) - local_pred)\n",
        "                pct   = (delta / max(1e-9, abs(local_pred))) * 100.0\n",
        "                ci_overlap = None\n",
        "                if api_low is not None and api_high is not None:\n",
        "                    try:\n",
        "                        ci_overlap = not (float(api_high) < local_low or float(api_low) > local_high)\n",
        "                    except Exception:\n",
        "                        ci_overlap = None\n",
        "                ver_note = \"\"\n",
        "                av, lv = _model_version(api_json), MODEL_VERSION\n",
        "                if av and av != lv:\n",
        "                    ver_note = f\" | ⚠️ model_version API={av} vs LOCAL={lv}\"\n",
        "                print(f\"[API] {lat_ms} ms | API={float(api_pred):.3f} k€ | LOCAL={local_pred:.3f} k€ | \"\n",
        "                      f\"Δ={delta:.4f} ({pct:.2f}%) | CI overlap: {ci_overlap if ci_overlap is not None else 'n/a'}{ver_note}\")\n",
        "        else:\n",
        "            print(f\"[API] ❌ {resp.status_code} | {resp.text[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[API] ⚠️ Consistency check skipped: {e}\")\n",
        "\n",
        "    # --- B) Optional publish path (toggle via env PUBLISH=1) ---\n",
        "    PUBLISH = os.getenv(\"PUBLISH\", \"false\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "    if PUBLISH:\n",
        "        try:\n",
        "            payload_json = json.loads(json.dumps(sample_property, cls=NumpyJSONEncoder, ensure_ascii=False))\n",
        "            t0 = time.perf_counter()\n",
        "            resp = requests.post(url, params={\"publish\": \"true\"}, json=payload_json, headers=headers, timeout=15)\n",
        "            lat_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "            if resp.ok:\n",
        "                api_json = resp.json()\n",
        "                api_pred, api_low, api_high, api_unc = _pick_pred_metrics(api_json)\n",
        "                print(f\"✅ API publish ok in {lat_ms} ms | pred={api_pred} k€ | unc={api_unc}\")\n",
        "            else:\n",
        "                print(f\"❌ API publish failed: {resp.status_code} | {resp.text[:200]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ API publish exception: {e}\")\n",
        "else:\n",
        "    print(\"ℹ️ COMPARE_WITH_API disabled — skip API checks.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb46f5d-8713-442d-a46b-3da6b3f70278",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Artifact Audit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703b2c48-e21a-441c-a574-e266a542cbb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# L4) Artifacts audit — file hash vs meta/manifest\n",
        "import hashlib, json\n",
        "from pathlib import Path\n",
        "\n",
        "def file_sha256(path: Path, chunk_size: int = 1 << 20) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with path.open(\"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b\"\"): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def manifest_expected_hash(manifest_path: Path) -> str | None:\n",
        "    if not manifest_path or not manifest_path.exists():\n",
        "        return None\n",
        "    try:\n",
        "        mf = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
        "        return (\n",
        "            (mf.get(\"paths\") or {}).get(\"pipeline_sha256\")\n",
        "            or (mf.get(\"model_meta\") or {}).get(\"model_hash\")\n",
        "            or (mf.get(\"artifacts\") or {}).get(\"pipeline_sha256\")\n",
        "            or (mf.get(\"artifacts\") or {}).get(\"model_sha256\")\n",
        "            or (mf.get(\"model\") or {}).get(\"sha256\")\n",
        "            or mf.get(\"pipeline_sha256\")\n",
        "        )\n",
        "    except Exception as e:\n",
        "        try: logger.info(\"Manifest unreadable for hash\", extra={\"error\": str(e)})\n",
        "        except Exception: pass\n",
        "        return None\n",
        "\n",
        "model_sha = file_sha256(PIPELINE_PATH)\n",
        "expected_sha_meta = (model_meta.get(\"model_hash\") or model_meta.get(\"pipeline_sha256\"))\n",
        "expected_sha_manifest = manifest_expected_hash(MANIFEST_PATH)\n",
        "\n",
        "print(f\"Model SHA256: {model_sha} (first16={model_sha[:16]})\")\n",
        "if expected_sha_meta:\n",
        "    print(f\"Meta expects   : {expected_sha_meta} (match: {expected_sha_meta == model_sha})\")\n",
        "if expected_sha_manifest:\n",
        "    ok = (expected_sha_manifest == model_sha)\n",
        "    print(f\"Manifest expects: {expected_sha_manifest} (match: {ok})\")\n",
        "    if not ok:\n",
        "        try:\n",
        "            logger.warning(\"Pipeline hash mismatch with manifest\",\n",
        "                           extra={\"expected\": expected_sha_manifest, \"actual\": model_sha})\n",
        "        except Exception:\n",
        "            pass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-oracle",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
