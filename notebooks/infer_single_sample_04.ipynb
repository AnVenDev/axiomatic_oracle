{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "10c75f60-9ee0-42f9-9b6b-21c018a83790",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Imports & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d6afe71-a30b-4efa-b790-baab0312540d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-09-23 02:51:58,373] INFO nb04_infer: Model root resolved\n",
            "[2025-09-23 02:52:01,644] INFO nb04_infer: Using model artifacts\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded FITTED model v2 from outputs\\modeling\\property\n",
            "   Features: 26 (cat=8, num=18)\n",
            "API compare: True → http://127.0.0.1:8000\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Optional, List, Tuple\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import joblib                     # type: ignore\n",
        "import numpy as np                # type: ignore\n",
        "import pandas as pd               # type: ignore\n",
        "\n",
        "# sklearn (per verificare che il modello sia fitted)\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.exceptions import NotFittedError\n",
        "\n",
        "# Shared modules (config, utils, constants)\n",
        "from shared.common.config import configure_logger\n",
        "from shared.common.utils import canonical_json_dumps, sha256_hex\n",
        "from shared.common.sanity_checks import leakage_gate, scale_gate\n",
        "from shared.common.constants import SCHEMA_VERSION, NOTE_MAX_BYTES\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Setup & Config\n",
        "# -----------------------------------------------------------------------------\n",
        "ASSET_TYPE = \"property\"\n",
        "\n",
        "# Prefer a specific version via env or fallback to \"v2\"\n",
        "PREFERRED_MODEL_VERSION = os.getenv(\"MODEL_VERSION\", \"v2\")\n",
        "\n",
        "# --- Model roots (prefer /shared/outputs/models) ---\n",
        "_candidates: List[Path] = []\n",
        "env_root = os.getenv(\"MODELS_ROOT\")\n",
        "if env_root and env_root.strip():\n",
        "    _c = Path(env_root)\n",
        "    _candidates.append(_c)\n",
        "\n",
        "_candidates += [Path(\"./outputs/modeling\")]\n",
        "\n",
        "# default se non esiste ancora nulla\n",
        "MODELS_ROOT: Path = next((c for c in _candidates if c.exists()), Path(\"../shared/outputs/models\"))\n",
        "MODEL_DIR = MODELS_ROOT / ASSET_TYPE\n",
        "\n",
        "# Predictions log path (JSONL append)\n",
        "LOG_PATH = Path(\"./outputs/logs/predictions_log.jsonl\")\n",
        "LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# API comparison toggle (can be overridden via env)\n",
        "API_BASE = os.getenv(\"API_BASE\", \"http://127.0.0.1:8000\")\n",
        "COMPARE_WITH_API = os.getenv(\"COMPARE_WITH_API\", \"true\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "\n",
        "# Configure logger (firma: configure_logger(level, name=None, json_format=None))\n",
        "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\")\n",
        "LOG_JSON = os.getenv(\"LOG_JSON\", \"false\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "logger = configure_logger(level=LOG_LEVEL, name=\"nb04_infer\", json_format=LOG_JSON)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "logger.info(\"Model root resolved\", extra={\"MODELS_ROOT\": str(MODELS_ROOT), \"MODEL_DIR\": str(MODEL_DIR)})\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helpers\n",
        "# -----------------------------------------------------------------------------\n",
        "_version_re = re.compile(r\"value_regressor_(v\\d+)\\.joblib$\")\n",
        "\n",
        "def _list_versions(dirpath: Path) -> List[str]:\n",
        "    items: List[Tuple[int, str]] = []\n",
        "    for p in dirpath.glob(\"value_regressor_v*.joblib\"):\n",
        "        m = _version_re.search(p.name)\n",
        "        if m:\n",
        "            v = m.group(1)  # 'vN'\n",
        "            try:\n",
        "                n = int(v[1:])\n",
        "            except Exception:\n",
        "                n = -1\n",
        "            items.append((n, v))\n",
        "    items.sort(reverse=True)  # dalla più recente\n",
        "    return [v for _, v in items]\n",
        "\n",
        "def _is_fitted_pipeline(pl) -> bool:\n",
        "    try:\n",
        "        # sklearn Pipeline: ultimo step è il modello\n",
        "        if hasattr(pl, \"steps\"):\n",
        "            check_is_fitted(pl.steps[-1][1])\n",
        "        else:\n",
        "            check_is_fitted(pl)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _read_json(path: Path) -> Dict[str, Any]:\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def _sha256_file(path: Path) -> str:\n",
        "    return sha256_hex(path.read_bytes())\n",
        "\n",
        "def _dedup_preserve(seq: List[str]) -> List[str]:\n",
        "    seen, out = set(), []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s); out.append(s)\n",
        "    return out\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Resolve a FITTED model (prefer requested version, else newest fitted)\n",
        "# -----------------------------------------------------------------------------\n",
        "def resolve_fitted_model(base_dir: Path, preferred: Optional[str]) -> Dict[str, Any]:\n",
        "    # 1) prova la versione preferita\n",
        "    if preferred:\n",
        "        p = base_dir / f\"value_regressor_{preferred}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{preferred}_meta.json\"\n",
        "        if p.exists() and m.exists():\n",
        "            pl = joblib.load(p)\n",
        "            if _is_fitted_pipeline(pl):\n",
        "                return {\n",
        "                    \"version\": preferred,\n",
        "                    \"pipeline\": p,\n",
        "                    \"meta\": m,\n",
        "                    \"manifest\": base_dir / \"training_manifest.json\",\n",
        "                    \"obj\": pl,\n",
        "                }\n",
        "            logger.warning(f\"Model {preferred} presente ma non fitted; cerco fallback…\")\n",
        "\n",
        "    # 2) cerca la prima versione fitted tra quelle disponibili (vN ↓)\n",
        "    for ver in _list_versions(base_dir):\n",
        "        p = base_dir / f\"value_regressor_{ver}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{ver}_meta.json\"\n",
        "        if not (p.exists() and m.exists()):\n",
        "            continue\n",
        "        pl = joblib.load(p)\n",
        "        if _is_fitted_pipeline(pl):\n",
        "            return {\n",
        "                \"version\": ver,\n",
        "                \"pipeline\": p,\n",
        "                \"meta\": m,\n",
        "                \"manifest\": base_dir / \"training_manifest.json\",\n",
        "                \"obj\": pl,\n",
        "            }\n",
        "\n",
        "    raise FileNotFoundError(f\"Nessun modello fitted trovato in {base_dir}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Load pipeline & metadata (fitted fallback) + expected features\n",
        "# -----------------------------------------------------------------------------\n",
        "resolved = resolve_fitted_model(MODEL_DIR, PREFERRED_MODEL_VERSION)\n",
        "MODEL_VERSION: str = resolved[\"version\"]\n",
        "PIPELINE_PATH: Path = resolved[\"pipeline\"]\n",
        "META_PATH: Path = resolved[\"meta\"]\n",
        "MANIFEST_PATH: Path = resolved[\"manifest\"]\n",
        "pipeline = resolved[\"obj\"]\n",
        "\n",
        "logger.info(\n",
        "    \"Using model artifacts\",\n",
        "    extra={\n",
        "        \"asset_type\": ASSET_TYPE,\n",
        "        \"model_version\": MODEL_VERSION,\n",
        "        \"pipeline\": str(PIPELINE_PATH),\n",
        "        \"meta\": str(META_PATH),\n",
        "        \"manifest\": str(MANIFEST_PATH) if MANIFEST_PATH.exists() else None,\n",
        "    },\n",
        ")\n",
        "\n",
        "# carica meta + verifica integrità bundle (hash)\n",
        "model_meta: Dict[str, Any] = _read_json(META_PATH)\n",
        "expected_hash = model_meta.get(\"model_hash\") or model_meta.get(\"pipeline_sha256\")\n",
        "actual_hash = _sha256_file(PIPELINE_PATH)\n",
        "if expected_hash and expected_hash != actual_hash:\n",
        "    raise ValueError(\n",
        "        f\"Bundle manomesso: meta={expected_hash[:8]}… != actual={actual_hash[:8]}…\"\n",
        "    )\n",
        "\n",
        "# expected features: preferisci feature_order.json → poi manifest → infine meta.json\n",
        "feature_order_candidates: List[Path] = [\n",
        "    PIPELINE_PATH.parent / \"feature_order.json\",\n",
        "]\n",
        "if MANIFEST_PATH.exists():\n",
        "    try:\n",
        "        manifest = _read_json(MANIFEST_PATH)\n",
        "        path_from_manifest = manifest.get(\"paths\", {}).get(\"feature_order\")\n",
        "        if path_from_manifest:\n",
        "            feature_order_candidates.append(Path(path_from_manifest))\n",
        "    except Exception as e:\n",
        "        logger.warning(\"Manifest presente ma non leggibile; fallback a meta.json\", extra={\"error\": str(e)})\n",
        "        manifest = {}\n",
        "\n",
        "FEATURE_ORDER_PATH: Optional[Path] = next((p for p in feature_order_candidates if p and p.exists()), None)\n",
        "\n",
        "categorical_expected: List[str] = model_meta.get(\"features_categorical\", []) or []\n",
        "numeric_expected: List[str] = model_meta.get(\"features_numeric\", []) or []\n",
        "\n",
        "if FEATURE_ORDER_PATH:\n",
        "    try:\n",
        "        feature_order: List[str] = _read_json(FEATURE_ORDER_PATH)\n",
        "        ALL_EXPECTED: List[str] = list(feature_order)\n",
        "    except Exception as e:\n",
        "        logger.warning(\"feature_order.json non leggibile; uso meta/manifest\", extra={\"error\": str(e)})\n",
        "        ALL_EXPECTED = _dedup_preserve(list(categorical_expected) + [c for c in numeric_expected if c not in categorical_expected])\n",
        "else:\n",
        "    # fallback senza feature_order.json\n",
        "    if MANIFEST_PATH.exists():\n",
        "        try:\n",
        "            # compat: in alcuni manifest i feature possono stare in model.feature_list oppure model.features\n",
        "            feats_from_manifest = (\n",
        "                manifest.get(\"model\", {}).get(\"feature_list\")\n",
        "                or manifest.get(\"model\", {}).get(\"features\", {})\n",
        "            )\n",
        "            if isinstance(feats_from_manifest, dict):\n",
        "                categorical_expected = feats_from_manifest.get(\"categorical\", categorical_expected) or categorical_expected\n",
        "                numeric_expected = feats_from_manifest.get(\"numeric\", numeric_expected) or numeric_expected\n",
        "        except Exception as e:\n",
        "            logger.warning(\"Impossibile leggere feature da manifest; uso meta.json\", extra={\"error\": str(e)})\n",
        "    ALL_EXPECTED = _dedup_preserve(list(categorical_expected) + [c for c in numeric_expected if c not in categorical_expected])\n",
        "\n",
        "print(f\"✅ Loaded FITTED model {MODEL_VERSION} from {PIPELINE_PATH.parent}\")\n",
        "print(f\"   Features: {len(ALL_EXPECTED)} (cat={len(categorical_expected)}, num={len(numeric_expected)})\")\n",
        "print(f\"API compare: {COMPARE_WITH_API} → {API_BASE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d55eb44-9ea4-4092-a3d1-7c910a6c2e76",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Validation Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ae9985cd-a991-4471-8629-63b656695c92",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Dict, Any, Tuple\n",
        "import numpy as np\n",
        "\n",
        "from shared.common.pricing import explain_price\n",
        "from shared.common.constants import LOCATION\n",
        "from shared.common.utils import canonical_location, get_utc_now\n",
        "from shared.common.sanity_checks import price_benchmark, validate_property\n",
        "\n",
        "# Alias comuni → chiavi canoniche\n",
        "_CANONICAL_ALIASES = {\n",
        "    \"sqm\": \"size_m2\",\n",
        "    \"size\": \"size_m2\",\n",
        "    \"m2\": \"size_m2\",\n",
        "    \"year\": \"year_built\",\n",
        "    \"built_year\": \"year_built\",\n",
        "    \"balcony\": \"has_balcony\",\n",
        "    \"garden\": \"has_garden\",\n",
        "    \"garage\": \"has_garage\",\n",
        "    \"air_quality\": \"air_quality_index\",\n",
        "    \"noise\": \"noise_level\",\n",
        "    \"valuation\": \"valuation_k\",\n",
        "    \"price_k\": \"valuation_k\",\n",
        "}\n",
        "\n",
        "# Derivate consentite (no leakage)\n",
        "_SAFE_DERIVED = {\"age_years\", \"luxury_score\", \"env_score\"}\n",
        "\n",
        "\n",
        "def _canonicalize_keys(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Mappa alias comuni verso i nomi campo canonici, con normalizzazione soft delle chiavi.\"\"\"\n",
        "    out: Dict[str, Any] = {}\n",
        "    for k, v in record.items():\n",
        "        k_norm = (k or \"\").strip()\n",
        "        k_lc = k_norm.lower()\n",
        "        out[_CANONICAL_ALIASES.get(k_lc, k_lc)] = v\n",
        "    return out\n",
        "\n",
        "\n",
        "def _autofill_safe(record: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Deriva SOLO campi non leaky e indipendenti dal target:\n",
        "    - age_years da year_built\n",
        "    - luxury_score da has_garden/has_balcony/has_garage\n",
        "    - env_score da air_quality_index e noise_level (normalizzati in [0,1])\n",
        "    \"\"\"\n",
        "    r = dict(record)\n",
        "\n",
        "    # age_years\n",
        "    if \"age_years\" not in r and \"year_built\" in r and r.get(\"year_built\") not in (None, \"\"):\n",
        "        try:\n",
        "            r[\"age_years\"] = max(0, get_utc_now().year - int(r[\"year_built\"]))\n",
        "        except Exception:\n",
        "            # se non coerente, lasciamo mancante (lo segnalerà la validazione)\n",
        "            pass\n",
        "\n",
        "    # luxury_score (media semplice di tre boolean/0-1)\n",
        "    if \"luxury_score\" not in r:\n",
        "        g = 1.0 if bool(r.get(\"has_garden\", 0)) else 0.0\n",
        "        b = 1.0 if bool(r.get(\"has_balcony\", 0)) else 0.0\n",
        "        ga = 1.0 if bool(r.get(\"has_garage\", 0)) else 0.0\n",
        "        r[\"luxury_score\"] = (g + b + ga) / 3.0\n",
        "\n",
        "    # env_score in [0,1] (qualità aria ↑, rumore ↓)\n",
        "    if \"env_score\" not in r:\n",
        "        try:\n",
        "            aq = float(r.get(\"air_quality_index\", 0.0))\n",
        "            nz = float(r.get(\"noise_level\", 0.0))\n",
        "            aq_n = float(np.clip(aq / 100.0, 0.0, 1.0))\n",
        "            nz_n = float(np.clip(nz / 100.0, 0.0, 1.0))\n",
        "            r[\"env_score\"] = float(np.clip(aq_n * (1.0 - nz_n), 0.0, 1.0))\n",
        "        except Exception:\n",
        "            r[\"env_score\"] = None\n",
        "\n",
        "    # ⚠️ NON deriviamo:\n",
        "    # - price_per_sqm (leaky dal target)\n",
        "    # - efficienze basate su valuation_k (leakage)\n",
        "    return r\n",
        "\n",
        "\n",
        "def validate_input_record(\n",
        "    record: Dict[str, Any],\n",
        "    *,\n",
        "    strict: bool = True,\n",
        "    drop_extras: bool = True\n",
        ") -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Canonicalizza → deriva campi sicuri → **VALIDA su versione pre-drop** (dominio) → poi filtra per il modello.\n",
        "    \"\"\"\n",
        "    # A) snapshot \"dominio\" per il validator (NON rinomina chiavi)\n",
        "    dom = dict(record)  # copia shallow\n",
        "    # normalizza location per il validator (se presente)\n",
        "    if LOCATION in dom and dom.get(LOCATION):\n",
        "        try:\n",
        "            dom[LOCATION] = canonical_location(dom[LOCATION])\n",
        "        except Exception:\n",
        "            pass\n",
        "    # defaults utili al validator\n",
        "    dom.setdefault(\"asset_type\", \"property\")\n",
        "    dom.setdefault(\"last_verified_ts\", get_utc_now().replace(microsecond=0).isoformat().replace(\"+00:00\",\"Z\"))\n",
        "\n",
        "    # B) versione \"modello\": alias + derivate sicure\n",
        "    base = _canonicalize_keys(record)\n",
        "    base = _autofill_safe(base)\n",
        "    if LOCATION in base and base.get(LOCATION):\n",
        "        try:\n",
        "            base[LOCATION] = canonical_location(base[LOCATION])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # C) VALIDAZIONE su 'dom' (pre-drop, con chiavi originali)\n",
        "    report = validate_property(dom)\n",
        "\n",
        "    if strict and not report.get(\"ok\", True):\n",
        "        raise ValueError(f\"❌ Property validation failed: {report.get('errors') or report}\")\n",
        "\n",
        "    # D) Filtra extra SOLO per l’input al modello\n",
        "    allowed = set(globals().get(\"ALL_EXPECTED\", [])) | _SAFE_DERIVED\n",
        "    extras = [k for k in list(base.keys()) if k not in allowed]\n",
        "    if drop_extras:\n",
        "        for k in extras:\n",
        "            base.pop(k, None)\n",
        "    elif strict and extras:\n",
        "        raise ValueError(f\"❌ Unexpected extra features: {extras}\")\n",
        "\n",
        "    return base, report\n",
        "\n",
        "\n",
        "def detect_anomalies(record: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Wrapper sugli esiti di validate_property:\n",
        "    - True se presenti violazioni/blocchi forti (es. campi fuori dominio, misure impossibili)\n",
        "    - Ritorna anche il report per logging/telemetria.\n",
        "    \"\"\"\n",
        "    _, report = validate_input_record(record, strict=False)\n",
        "    has_blockers = not report.get(\"ok\", True)\n",
        "    return has_blockers, report\n",
        "\n",
        "\n",
        "def _maybe_explain_price(rec: dict) -> dict | None:\n",
        "    \"\"\"Breakdown euristico del prezzo (no ML), utile per trasparenza UI.\"\"\"\n",
        "    try:\n",
        "        return explain_price(rec)  # dict con componenti/moltipl. – già nel tuo /shared\n",
        "    except Exception as e:\n",
        "        # usa logger globale se disponibile nel notebook\n",
        "        try:\n",
        "            logger.info(\"explain_price not available\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "def _price_benchmark_flag(rec: dict, yhat_k: float) -> dict | None:\n",
        "    \"\"\"\n",
        "    Flag 'fuori banda' rispetto alle mediane/location (se disponibili nello shared).\n",
        "    Ritorna un dict tipo: {\"z\":..., \"out_of_band\": bool, \"band\": [low, high], ...}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return price_benchmark(location=rec.get(\"location\"), valuation_k=float(yhat_k))\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.info(\"price_benchmark not available\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0341141f-3525-4d22-92f8-a68edc266946",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Sample Single Property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1d920b40-4628-4766-a1f0-231f3487d26d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[VALIDATION] Asset unknown normalized. Errors=['condition_score_missing', 'risk_score_missing', 'luxury_score_missing', 'env_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['listing_month', 'view', 'age_years', 'orientation', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'asset_id', 'cellar', 'garage', 'concierge', 'condition', 'env_score', 'luxury_score', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'luxury_score_missing', 'env_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 250.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'luxury_score_missing', 'env_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['listing_month', 'view', 'age_years', 'orientation', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'asset_id', 'cellar', 'garage', 'concierge', 'condition', 'env_score', 'luxury_score', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'asset_id': (None, 'unknown'), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'luxury_score_missing', 'env_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "[2025-09-23 02:52:02,433] INFO nb04_infer: Sample property validated\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Sample validated. asset_id=asset_infer_eaa37945 location=None\n"
          ]
        }
      ],
      "source": [
        "from uuid import uuid4\n",
        "from shared.common.constants import ASSET_ID\n",
        "\n",
        "# Esempio di record \"grezzo\" da UI/utente\n",
        "sample_property_raw = {\n",
        "    \"location\": \"Milan\",\n",
        "    \"size_m2\": 500,\n",
        "    \"rooms\": 4,\n",
        "    \"bathrooms\": 2,\n",
        "    \"year_built\": 1999,\n",
        "    \"floor\": 2,\n",
        "    \"building_floors\": 6,\n",
        "    \"has_elevator\": 1,\n",
        "    \"has_garden\": 0,\n",
        "    \"has_balcony\": 1,\n",
        "    \"has_garage\": 1,\n",
        "    \"energy_class\": \"B\",\n",
        "    \"humidity_level\": 50.0,\n",
        "    \"temperature_avg\": 20.5,\n",
        "    \"noise_level\": 40,\n",
        "    \"air_quality_index\": 70,\n",
        "    \"owner_occupied\": 1,\n",
        "    \"public_transport_nearby\": 1,\n",
        "    \"distance_to_center_km\": 2.5,\n",
        "}\n",
        "\n",
        "# 1) Valida e derivi SOLO campi sicuri (age_years, luxury_score, env_score)\n",
        "sample_property, validation_report = validate_input_record(sample_property_raw, strict=True)\n",
        "\n",
        "# 2) Normalizza boolean-like a intero {0,1} (aiuta schema/serving)\n",
        "_bool_like = [\n",
        "    k for k in sample_property.keys()\n",
        "    if k.startswith(\"has_\")\n",
        "] + [\"owner_occupied\", \"public_transport_nearby\"]\n",
        "for k in _bool_like:\n",
        "    if k in sample_property:\n",
        "        sample_property[k] = int(bool(sample_property[k]))\n",
        "\n",
        "# 3) Genera un asset_id se mancante (non influisce sulle feature del modello)\n",
        "if ASSET_ID not in sample_property:\n",
        "    sample_property[ASSET_ID] = f\"asset_infer_{uuid4().hex[:8]}\"\n",
        "\n",
        "logger.info(\n",
        "    \"Sample property validated\",\n",
        "    extra={\n",
        "        \"asset_id\": sample_property.get(ASSET_ID),\n",
        "        \"location\": sample_property.get(\"location\"),\n",
        "        \"ok\": validation_report.get(\"ok\", True),\n",
        "        \"warnings\": validation_report.get(\"warnings\"),\n",
        "        \"errors\": validation_report.get(\"errors\"),\n",
        "    },\n",
        ")\n",
        "print(f\"✅ Sample validated. asset_id={sample_property.get(ASSET_ID)} location={sample_property.get('location')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e625d7-fa88-45b0-90fd-bc6e9dfa8dc0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Load Pipeline & Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "343fc03a-0516-4d0e-b48f-bde2944caddc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-09-23 02:52:02,472] INFO nb04_infer: Expected features resolved\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Artifacts ready — model v2 | features: 26 (cat=8, num=18)\n"
          ]
        }
      ],
      "source": [
        "loaded_version = MODEL_VERSION\n",
        "\n",
        "def _dedup_preserve(seq: List[str]) -> List[str]:\n",
        "    seen: set[str] = set()\n",
        "    out: List[str] = []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            out.append(s)\n",
        "    return out\n",
        "\n",
        "def _read_json(path: Path) -> dict:\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def resolve_expected_features(\n",
        "    model_meta: dict,\n",
        "    manifest_path: Path,\n",
        "    feature_order_path: Optional[Path] = None,\n",
        ") -> Tuple[List[str], List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Priorità:\n",
        "    1) feature_order.json (ordine canone per serving → parità train→serve)\n",
        "    2) manifest: model.feature_list / model.features.{categorical,numeric}\n",
        "    3) meta.json: features_categorical / features_numeric\n",
        "    Ritorna: (categorical, numeric, all_expected_in_order)\n",
        "    \"\"\"\n",
        "    # 1) feature_order.json (se presente)\n",
        "    if feature_order_path and feature_order_path.exists():\n",
        "        try:\n",
        "            order: List[str] = _read_json(feature_order_path)\n",
        "            order = _dedup_preserve([str(c) for c in order])\n",
        "            # Recupera cat/num di supporto da meta (non influiscono sull'ordine)\n",
        "            cat = list(model_meta.get(\"features_categorical\", []) or [])\n",
        "            num = list(model_meta.get(\"features_numeric\", []) or [])\n",
        "            cat = _dedup_preserve([c for c in cat if c in order])\n",
        "            num = _dedup_preserve([c for c in num if c in order and c not in set(cat)])\n",
        "            return cat, num, order\n",
        "        except Exception as e:\n",
        "            logger.warning(\"feature_order.json non leggibile; fallback a manifest/meta\", extra={\"error\": str(e)})\n",
        "\n",
        "    # 2) manifest (cat/num)\n",
        "    cat = list(model_meta.get(\"features_categorical\", []) or [])\n",
        "    num = list(model_meta.get(\"features_numeric\", []) or [])\n",
        "    if manifest_path.exists():\n",
        "        try:\n",
        "            mf = _read_json(manifest_path)\n",
        "            feats = (mf.get(\"model\", {}).get(\"feature_list\") or mf.get(\"model\", {}).get(\"features\"))\n",
        "            if isinstance(feats, dict):\n",
        "                cat = list(feats.get(\"categorical\", cat) or cat)\n",
        "                num = list(feats.get(\"numeric\", num) or num)\n",
        "        except Exception as e:\n",
        "            logger.warning(\"Manifest presente ma non leggibile; fallback a meta.json\", extra={\"error\": str(e)})\n",
        "\n",
        "    # 3) dedup & nessun overlap; ordine: cat poi num (stabile)\n",
        "    cat = _dedup_preserve([str(c) for c in cat])\n",
        "    num = _dedup_preserve([str(c) for c in num if c not in set(cat)])\n",
        "    all_expected = cat + num\n",
        "    return cat, num, all_expected\n",
        "\n",
        "# ---- Risolvi il path di feature_order.json (se disponibile) ----\n",
        "feature_order_candidates: List[Path] = []\n",
        "\n",
        "# se definito in una cella precedente, usalo\n",
        "if \"FEATURE_ORDER_PATH\" in globals() and isinstance(FEATURE_ORDER_PATH, (Path, str)) and FEATURE_ORDER_PATH:\n",
        "    feature_order_candidates.append(Path(FEATURE_ORDER_PATH))\n",
        "\n",
        "# manifest -> paths.feature_order\n",
        "if MANIFEST_PATH.exists():\n",
        "    try:\n",
        "        _mf = _read_json(MANIFEST_PATH)\n",
        "        p = _mf.get(\"paths\", {}).get(\"feature_order\")\n",
        "        if p:\n",
        "            feature_order_candidates.append(Path(p))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# default nella stessa dir del modello\n",
        "feature_order_candidates.append(PIPELINE_PATH.parent / \"feature_order.json\")\n",
        "\n",
        "FEATURE_ORDER_PATH_RESOLVED: Optional[Path] = next((p for p in feature_order_candidates if p and p.exists()), None)\n",
        "\n",
        "categorical_expected, numeric_expected, ALL_EXPECTED = resolve_expected_features(\n",
        "    model_meta=model_meta,\n",
        "    manifest_path=MANIFEST_PATH,\n",
        "    feature_order_path=FEATURE_ORDER_PATH_RESOLVED,\n",
        ")\n",
        "\n",
        "assert len(ALL_EXPECTED) > 0, \"Nessuna feature attesa risolta (controlla meta/manifest/feature_order.json).\"\n",
        "\n",
        "logger.info(\n",
        "    \"Expected features resolved\",\n",
        "    extra={\n",
        "        \"model_version\": loaded_version,\n",
        "        \"n_categorical\": len(categorical_expected),\n",
        "        \"n_numeric\": len(numeric_expected),\n",
        "        \"n_total\": len(ALL_EXPECTED),\n",
        "        \"feature_order_path\": str(FEATURE_ORDER_PATH_RESOLVED) if FEATURE_ORDER_PATH_RESOLVED else None,\n",
        "    },\n",
        ")\n",
        "print(\n",
        "    f\"✅ Artifacts ready — model {loaded_version} | \"\n",
        "    f\"features: {len(ALL_EXPECTED)} (cat={len(categorical_expected)}, num={len(numeric_expected)})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53df569-abec-4acb-93a8-85c2354350ee",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Predict with confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d3d407da-713f-437f-aa37-61d5b426b38f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Any, Tuple, Optional, List\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# sklearn (opzionale: in ambienti \"slim\" può non esserci)\n",
        "try:\n",
        "    from sklearn.pipeline import Pipeline  # type: ignore\n",
        "except Exception:\n",
        "    Pipeline = None  # type: ignore\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Conf levels → z-approx (no SciPy richiesto)\n",
        "# -------------------------------------------------------------------\n",
        "_Z_FOR_CONF = {0.80: 1.282, 0.90: 1.645, 0.95: 1.960, 0.98: 2.326, 0.99: 2.576}\n",
        "def _z_for_conf(conf: float) -> float:\n",
        "    return _Z_FOR_CONF.get(round(conf, 2), 1.960)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Helpers (NO uso di variabili globali: pipeline/manifest/features sono parametri)\n",
        "# -------------------------------------------------------------------\n",
        "def _to_numpy_nan(x):\n",
        "    try:\n",
        "        import pandas as _pd\n",
        "        if x is _pd.NA:\n",
        "            return np.nan\n",
        "    except Exception:\n",
        "        pass\n",
        "    return x\n",
        "\n",
        "def _coerce_nullable_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Converte dtypes pandas 'nullable' in tipi compatibili sklearn.\"\"\"\n",
        "    df = df.copy()\n",
        "    for col in df.columns:\n",
        "        dt = df[col].dtype\n",
        "        dtn = str(dt).lower()\n",
        "        # string/boolean nullable -> object\n",
        "        if \"string\" in dtn or \"boolean\" in dtn:\n",
        "            df[col] = df[col].astype(object)\n",
        "        # interi nullable -> float64\n",
        "        if dtn in (\"int64\", \"int32\", \"int16\") and getattr(dt, \"name\", \"\").startswith(\"Int\"):\n",
        "            # Caso raro: se dt è 'Int64' di pandas, converti a float64\n",
        "            df[col] = df[col].astype(\"float64\")\n",
        "        # fallback: rimpiazza eventuali <NA>\n",
        "        try:\n",
        "            import pandas as _pd\n",
        "            df[col] = df[col].replace({_pd.NA: np.nan})\n",
        "        except Exception:\n",
        "            pass\n",
        "    return df\n",
        "\n",
        "def _clean_missing_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Normalizza i NaN:\n",
        "      - coerce dei dtypes nullable (string/boolean/IntXX) verso object/float\n",
        "      - sostituisce ogni pd.NA con np.nan (evita 'boolean value of NA is ambiguous')\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df = _coerce_nullable_dtypes(df)\n",
        "    try:\n",
        "        import pandas as _pd\n",
        "        df = df.replace({_pd.NA: np.nan})\n",
        "        df = df.applymap(_to_numpy_nan)\n",
        "        df = df.where(_pd.notna(df), np.nan)\n",
        "    except Exception:\n",
        "        df = df.where(pd.notna(df), np.nan)\n",
        "    return df\n",
        "\n",
        "GEO_REQUIRED = (\"city\", \"zone\", \"region\")\n",
        "\n",
        "def _prepare_df(record: Dict[str, Any], expected_features: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Prepara il DF con le feature attese.\n",
        "    - Colonne mancanti riempite con np.nan.\n",
        "    - city/zone/region sempre presenti come stringa vuota \"\" (evita pandas.NA e i crash in SimpleImputer).\n",
        "    - Dtypes numerici safe (niente boolean/integer nullable).\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    # importa helper dtype compatibili con varie versioni di pandas\n",
        "    try:\n",
        "        from pandas.api.types import is_integer_dtype, is_bool_dtype\n",
        "    except Exception:\n",
        "        # fallback ultra-conservativo\n",
        "        def is_integer_dtype(s):  # type: ignore\n",
        "            return str(s.dtype).startswith((\"int\", \"Int\"))\n",
        "        def is_bool_dtype(s):     # type: ignore\n",
        "            return str(s.dtype).startswith((\"bool\", \"Boolean\"))\n",
        "\n",
        "    # 1) riga ordinata sulle sole expected_features\n",
        "    row = {k: record.get(k, np.nan) for k in expected_features}\n",
        "    df = pd.DataFrame([row], columns=expected_features)\n",
        "\n",
        "    # 2) inietta sempre le geo columns come stringa vuota (evita <NA> dopo .str.* in PriorsGuard)\n",
        "    for col in GEO_REQUIRED:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"          # importante: stringa vuota, NON np.nan\n",
        "        else:\n",
        "            if pd.isna(df.at[0, col]):\n",
        "                df.at[0, col] = \"\"\n",
        "\n",
        "    # 3) evita dtypes \"nullable\" che introducono pandas.NA in step sklearn:\n",
        "    #    converti integer/bool in float64 (così i missing restano np.nan)\n",
        "    for c in df.columns:\n",
        "        s = df[c]\n",
        "        if is_integer_dtype(s) or is_bool_dtype(s):\n",
        "            df[c] = s.astype(\"float64\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def _extract_model_and_X(pipeline_obj, df: pd.DataFrame) -> Tuple[Any, Any]:\n",
        "    \"\"\"\n",
        "    Se 'pipeline_obj' è una sklearn Pipeline:\n",
        "      - separa preproc (tutti i passaggi tranne l'ultimo) e modello (ultimo step)\n",
        "      - applica 'transform' al preproc e ritorna (model, X_transformed)\n",
        "    Altrimenti ritorna (pipeline_obj, df) come passthrough.\n",
        "    \"\"\"\n",
        "    if Pipeline is not None and hasattr(pipeline_obj, \"steps\"):\n",
        "        preproc = pipeline_obj[:-1]\n",
        "        X = preproc.transform(_clean_missing_df(df))\n",
        "        model = pipeline_obj.steps[-1][1]\n",
        "        return model, X\n",
        "    else:\n",
        "        return pipeline_obj, _clean_missing_df(df)\n",
        "\n",
        "def _sigma_from_manifest(manifest_path: Optional[Path]) -> Optional[float]:\n",
        "    if not manifest_path or not manifest_path.exists():\n",
        "        return None\n",
        "    try:\n",
        "        mf = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
        "        mroot = mf.get(\"metrics\") or {}\n",
        "        metrics = mroot.get(\"valid\") or mroot.get(\"validation\") or mroot\n",
        "        rmse = metrics.get(\"rmse\") or metrics.get(\"RMSE\")\n",
        "        mae = metrics.get(\"mae\") or metrics.get(\"MAE\")\n",
        "        if isinstance(rmse, (int, float)) and rmse > 0:\n",
        "            return float(rmse)\n",
        "        if isinstance(mae, (int, float)) and mae > 0:\n",
        "            return float(mae) * 1.253314\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.warning(\"Cannot read sigma from manifest\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# API principale\n",
        "# -------------------------------------------------------------------\n",
        "def predict_with_confidence(\n",
        "    record: Dict[str, Any],\n",
        "    *,\n",
        "    pipeline_obj: Any,\n",
        "    expected_features: List[str],\n",
        "    manifest_path: Optional[Path] = None,\n",
        "    n_t_min: int = 3,\n",
        "    confidence: float = 0.95,\n",
        "    verbose: bool = False,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Stima puntuale + intervallo di confidenza:\n",
        "    - Se il modello è una foresta (ha 'estimators_'): usa la varianza tra gli alberi (t≈z).\n",
        "    - Altrimenti: usa σ ≈ RMSE (o MAE→σ) dal training_manifest → z-interval.\n",
        "    \"\"\"\n",
        "    # 1) Prepara X (missing puliti)\n",
        "    df = _prepare_df(record, expected_features)\n",
        "\n",
        "    # 2) Estrai una sola volta preproc e modello, poi predici sullo stesso X\n",
        "    model, X = _extract_model_and_X(pipeline_obj, df)\n",
        "\n",
        "    # 2a) Predizione puntuale\n",
        "    y_raw = model.predict(X) if hasattr(model, \"predict\") else pipeline_obj(df)\n",
        "    y_hat = float(np.ravel(y_raw)[0])\n",
        "\n",
        "    # 3) Varianza tra alberi (se disponibile)\n",
        "    try:\n",
        "        estimators = getattr(model, \"estimators_\", None)\n",
        "        if isinstance(estimators, (list, tuple)) and len(estimators) >= n_t_min:\n",
        "            per_tree = np.array([np.ravel(est.predict(X))[0] for est in estimators], dtype=float)\n",
        "            m = float(per_tree.mean())\n",
        "            s = float(per_tree.std(ddof=1)) if per_tree.size > 1 else 0.0\n",
        "            z = _z_for_conf(confidence)\n",
        "            ci_margin = float(z * s)\n",
        "            lower, upper = float(m - ci_margin), float(m + ci_margin)\n",
        "            method = \"forest_variance\"\n",
        "            n_estimators = len(estimators)\n",
        "        else:\n",
        "            raise RuntimeError(\"No per-tree predictions available\")\n",
        "    except Exception:\n",
        "        # 4) Fallback: σ globale dal manifest o 10% di y_hat\n",
        "        sigma = _sigma_from_manifest(manifest_path)\n",
        "        if sigma is None:\n",
        "            sigma = max(1.0, abs(y_hat) * 0.10)\n",
        "        z = _z_for_conf(confidence)\n",
        "        ci_margin = float(z * float(sigma))\n",
        "        lower, upper = float(y_hat - ci_margin), float(y_hat + ci_margin)\n",
        "        m, s, method = y_hat, float(sigma), \"global_sigma\"\n",
        "        n_estimators = None\n",
        "\n",
        "    if verbose:\n",
        "        try:\n",
        "            logger.info(\"Prediction info\",\n",
        "                        extra={\"y_hat\": y_hat, \"mean_used\": m, \"std_used\": s,\n",
        "                               \"ci_margin\": ci_margin, \"confidence\": confidence, \"method\": method})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return {\n",
        "        \"prediction\": round(m, 2),\n",
        "        \"point_pred\": round(y_hat, 2),\n",
        "        \"uncertainty\": round(s, 2),\n",
        "        \"confidence\": float(confidence),\n",
        "        \"confidence_interval\": (round(lower, 2), round(upper, 2)),\n",
        "        \"ci_margin\": round(ci_margin, 2),\n",
        "        \"method\": method,\n",
        "        \"n_estimators\": n_estimators,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2ddd8d9e-2ac0-4371-be4d-18f3b78a6440",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-09-23 03:26:11,731] INFO nb04_infer: Loaded fitted model\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 250.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "[2025-09-23 03:26:11,734] INFO nb04_infer: Anomaly check: False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded FITTED model v2 | features=26\n",
            "✅ No anomalies detected.\n",
            "✅ No significant feature drift detected.\n"
          ]
        }
      ],
      "source": [
        "# --- ensure model is fitted & resolve artifacts (idempotente) ---\n",
        "from pathlib import Path\n",
        "import os, re, json\n",
        "from typing import Optional, List, Dict, Any\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.exceptions import NotFittedError\n",
        "\n",
        "# Helpers locali ----------------------------------------------------\n",
        "def _list_versions(dirpath: Path) -> List[str]:\n",
        "    vers = []\n",
        "    for p in sorted(dirpath.glob(\"value_regressor_v*.joblib\")):\n",
        "        m = re.search(r\"value_regressor_(v\\d+)\\.joblib$\", p.name)\n",
        "        if m:\n",
        "            try:\n",
        "                vers.append((int(m.group(1)[1:]), m.group(1)))  # (num, 'vN')\n",
        "            except Exception:\n",
        "                vers.append((-1, m.group(1)))\n",
        "    # ordina discendente (più recente prima)\n",
        "    return [v for _, v in sorted(vers, reverse=True)]\n",
        "\n",
        "def _load_pipeline(path: Path):\n",
        "    return joblib.load(path)\n",
        "\n",
        "def _is_fitted_pipeline(pl) -> bool:\n",
        "    try:\n",
        "        if hasattr(pl, \"steps\"):  # sklearn Pipeline\n",
        "            check_is_fitted(pl.steps[-1][1])\n",
        "        else:\n",
        "            check_is_fitted(pl)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _read_json(path: Path) -> dict:\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def _sha256_file(path: Path) -> str:\n",
        "    import hashlib\n",
        "    return hashlib.sha256(path.read_bytes()).hexdigest()\n",
        "\n",
        "def _dedup_preserve(seq: List[str]) -> List[str]:\n",
        "    seen, out = set(), []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s); out.append(s)\n",
        "    return out\n",
        "\n",
        "def _resolve_expected_features(\n",
        "    *, model_meta: dict, manifest_path: Optional[Path], feature_order_path: Optional[Path]\n",
        ") -> List[str]:\n",
        "    # 1) feature_order.json → ordine canone\n",
        "    if feature_order_path and feature_order_path.exists():\n",
        "        try:\n",
        "            order = _read_json(feature_order_path)\n",
        "            return _dedup_preserve([str(c) for c in order])\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                logger.warning(\"feature_order.json non leggibile; fallback a manifest/meta\", extra={\"error\": str(e)})\n",
        "            except Exception:\n",
        "                pass\n",
        "    # 2) manifest: model.feature_list / model.features\n",
        "    cat = list(model_meta.get(\"features_categorical\", []) or [])\n",
        "    num = list(model_meta.get(\"features_numeric\", []) or [])\n",
        "    if manifest_path and manifest_path.exists():\n",
        "        try:\n",
        "            mf = _read_json(manifest_path)\n",
        "            feats = (mf.get(\"model\", {}).get(\"feature_list\") or mf.get(\"model\", {}).get(\"features\"))\n",
        "            if isinstance(feats, dict):\n",
        "                cat = list(feats.get(\"categorical\", cat) or cat)\n",
        "                num = list(feats.get(\"numeric\", num) or num)\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                logger.warning(\"Manifest presente ma non leggibile; fallback a meta.json\", extra={\"error\": str(e)})\n",
        "            except Exception:\n",
        "                pass\n",
        "    # 3) cat poi num (stabile) con dedup e senza overlap\n",
        "    cat = _dedup_preserve([str(c) for c in cat])\n",
        "    num = _dedup_preserve([str(c) for c in num if c not in set(cat)])\n",
        "    return cat + num\n",
        "\n",
        "def resolve_fitted_model(base_dir: Path, preferred: Optional[str]) -> dict:\n",
        "    # 1) prova preferito\n",
        "    if preferred:\n",
        "        p = base_dir / f\"value_regressor_{preferred}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{preferred}_meta.json\"\n",
        "        if p.exists() and m.exists():\n",
        "            pl = _load_pipeline(p)\n",
        "            if _is_fitted_pipeline(pl):\n",
        "                return {\"version\": preferred, \"pipeline\": p, \"meta\": m, \"manifest\": base_dir / \"training_manifest.json\", \"obj\": pl}\n",
        "            try:\n",
        "                logger.warning(f\"Model {preferred} presente ma non fitted, cerco fallback…\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # 2) cerca il primo fitted tra i presenti (vN decrescente)\n",
        "    for ver in _list_versions(base_dir):\n",
        "        p = base_dir / f\"value_regressor_{ver}.joblib\"\n",
        "        m = base_dir / f\"value_regressor_{ver}_meta.json\"\n",
        "        if not (p.exists() and m.exists()):\n",
        "            continue\n",
        "        pl = _load_pipeline(p)\n",
        "        if _is_fitted_pipeline(pl):\n",
        "            return {\"version\": ver, \"pipeline\": p, \"meta\": m, \"manifest\": base_dir / \"training_manifest.json\", \"obj\": pl}\n",
        "\n",
        "    raise FileNotFoundError(f\"Nessun modello fitted trovato in {base_dir}\")\n",
        "\n",
        "# Risoluzione idempotente ------------------------------------------\n",
        "if \"MODEL_DIR\" not in globals():\n",
        "    _candidates = []\n",
        "    env_root = os.getenv(\"MODELS_ROOT\")\n",
        "    if env_root and env_root.strip():\n",
        "        _candidates.append(Path(env_root))\n",
        "    _candidates.append(Path(\"./outputs/modeling\"))\n",
        "    MODELS_ROOT = next((c for c in _candidates if c.exists()), Path(\"./outputs/modeling\"))\n",
        "    ASSET_TYPE = \"property\"\n",
        "    MODEL_DIR = MODELS_ROOT / ASSET_TYPE\n",
        "\n",
        "resolved = (\n",
        "    resolved if \"resolved\" in globals()\n",
        "    else resolve_fitted_model(MODEL_DIR, os.getenv(\"MODEL_VERSION\", \"v2\"))\n",
        ")\n",
        "\n",
        "MODEL_VERSION = resolved[\"version\"]\n",
        "PIPELINE_PATH = resolved[\"pipeline\"]\n",
        "META_PATH = resolved[\"meta\"]\n",
        "MANIFEST_PATH = resolved[\"manifest\"]\n",
        "pipeline = resolved[\"obj\"]\n",
        "\n",
        "# carica meta + verifica integrità hash\n",
        "model_meta = _read_json(META_PATH)\n",
        "expected_hash = model_meta.get(\"model_hash\") or model_meta.get(\"pipeline_sha256\")\n",
        "actual_hash = _sha256_file(PIPELINE_PATH)\n",
        "if expected_hash and expected_hash != actual_hash:\n",
        "    raise ValueError(f\"Bundle manomesso: meta={expected_hash[:8]}… != actual={actual_hash[:8]}…\")\n",
        "\n",
        "# feature_order path dai candidati\n",
        "feature_order_candidates: List[Path] = [\n",
        "    PIPELINE_PATH.parent / \"feature_order.json\",\n",
        "]\n",
        "if MANIFEST_PATH and MANIFEST_PATH.exists():\n",
        "    try:\n",
        "        mf = _read_json(MANIFEST_PATH)\n",
        "        pfo = mf.get(\"paths\", {}).get(\"feature_order\")\n",
        "        if pfo:\n",
        "            feature_order_candidates.insert(0, Path(pfo))\n",
        "    except Exception:\n",
        "        pass\n",
        "FEATURE_ORDER_PATH = next((p for p in feature_order_candidates if p and p.exists()), None)\n",
        "\n",
        "# expected features local alla cella (no dipendenze globali)\n",
        "ALL_EXPECTED = _resolve_expected_features(\n",
        "    model_meta=model_meta,\n",
        "    manifest_path=MANIFEST_PATH if MANIFEST_PATH and MANIFEST_PATH.exists() else None,\n",
        "    feature_order_path=FEATURE_ORDER_PATH,\n",
        ")\n",
        "\n",
        "try:\n",
        "    logger.info(\"Loaded fitted model\", extra={\n",
        "        \"version\": MODEL_VERSION,\n",
        "        \"pipeline\": str(PIPELINE_PATH),\n",
        "        \"feature_order\": str(FEATURE_ORDER_PATH) if FEATURE_ORDER_PATH else None,\n",
        "        \"n_expected_features\": len(ALL_EXPECTED),\n",
        "    })\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(f\"✅ Loaded FITTED model {MODEL_VERSION} | features={len(ALL_EXPECTED)}\")\n",
        "\n",
        "# === Anomaly / Validation report ===\n",
        "has_anomaly, validation_report = detect_anomalies(sample_property)\n",
        "\n",
        "if has_anomaly:\n",
        "    print(\"⚠️ Anomaly detected in input property!\")\n",
        "    try:\n",
        "        logger.info(\"Validation report\", extra={\"report\": validation_report})\n",
        "    except Exception:\n",
        "        pass\n",
        "else:\n",
        "    print(\"✅ No anomalies detected.\")\n",
        "    if validation_report.get(\"warnings\"):\n",
        "        print(f\"ℹ️ Warnings: {validation_report['warnings']}\")\n",
        "\n",
        "try:\n",
        "    logger.info(f\"Anomaly check: {has_anomaly}\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Drift check helpers\n",
        "# ------------------------------------------------------------------\n",
        "def check_feature_drift(record: dict, baseline_stats: dict):\n",
        "    \"\"\"\n",
        "    Verifica drift (|z| > 3) rispetto a 'baseline_stats'.\n",
        "    baseline_stats atteso: {feature: {\"mean\":..., \"std\":...} oppure include \"min\"/\"max\"/\"iqr\"}.\n",
        "    Usa solo feature numeriche presenti sia in 'record' sia in 'baseline_stats'.\n",
        "    Ritorna: (drifted: bool, first_message: Optional[str])\n",
        "    \"\"\"\n",
        "    def _mean_std(v: dict) -> tuple[float, float]:\n",
        "        m = float(v.get(\"mean\", np.nan))\n",
        "        std = v.get(\"std\")\n",
        "        if std is None:\n",
        "            iqr = v.get(\"iqr\")\n",
        "            if iqr is not None:\n",
        "                s = float(iqr) / 1.349  # approx σ from IQR\n",
        "            else:\n",
        "                mn, mx = v.get(\"min\"), v.get(\"max\")\n",
        "                s = float(mx - mn) / 4.0 if (mn is not None and mx is not None) else np.nan\n",
        "        else:\n",
        "            s = float(std)\n",
        "        return m, s\n",
        "\n",
        "    drifted_any = False\n",
        "    first_msg = None\n",
        "\n",
        "    for feat, stats in baseline_stats.items():\n",
        "        if feat not in record:\n",
        "            continue\n",
        "        val = record.get(feat)\n",
        "        if val is None or not isinstance(val, (int, float, np.number)):\n",
        "            continue\n",
        "        m, s = _mean_std(stats)\n",
        "        if not np.isfinite(m) or not np.isfinite(s) or s == 0:\n",
        "            continue\n",
        "        z = abs((float(val) - m) / s)\n",
        "        if z > 3.0:\n",
        "            msg = f\"⚠️ Feature drift on '{feat}': z={z:.2f} (val={val}, mean={m:.2f}, std≈{s:.2f})\"\n",
        "            try:\n",
        "                logger.warning(msg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            drifted_any = True\n",
        "            if first_msg is None:\n",
        "                first_msg = msg\n",
        "    return drifted_any, first_msg\n",
        "\n",
        "# Costruisci baseline stats da meta (preferisci raw → engineered)\n",
        "source = (\n",
        "    model_meta.get(\"raw_feature_stats\")\n",
        "    or model_meta.get(\"engineered_feature_stats\")\n",
        "    or {}\n",
        ")\n",
        "\n",
        "# Normalizza in forma {feat: {\"mean\":..., \"std\":..., \"min\":..., \"max\":..., \"iqr\":...}}\n",
        "baseline_stats: Dict[str, Dict[str, Any]] = {}\n",
        "for k, v in source.items():\n",
        "    if isinstance(v, dict):\n",
        "        entry = {}\n",
        "        for key in (\"mean\", \"std\", \"min\", \"max\", \"iqr\"):\n",
        "            if key in v:\n",
        "                entry[key] = v[key]\n",
        "        if \"mean\" in entry:\n",
        "            baseline_stats[k] = entry\n",
        "    else:\n",
        "        # legacy: tuple/list con (mean, std?)\n",
        "        try:\n",
        "            mean = float(v[0])\n",
        "            std  = float(v[1]) if len(v) > 1 else None\n",
        "            entry = {\"mean\": mean}\n",
        "            if std is not None:\n",
        "                entry[\"std\"] = std\n",
        "            baseline_stats[k] = entry\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# 1) Prova drift su feature raw (intersezione con record)\n",
        "overlap = set(baseline_stats.keys()) & set(sample_property.keys())\n",
        "drift_flag = False\n",
        "drift_msg = None\n",
        "if overlap:\n",
        "    drift_flag, drift_msg = check_feature_drift(sample_property, baseline_stats)\n",
        "else:\n",
        "    # 2) Tentativo “engineered”: usa il preproc della pipeline per trasformare il record\n",
        "    try:\n",
        "        preproc = pipeline[:-1]  # tutto tranne l'ultimo step (modello)\n",
        "        df_row = pd.DataFrame([{k: sample_property.get(k, np.nan) for k in ALL_EXPECTED}], columns=ALL_EXPECTED)\n",
        "        df_row = df_row.where(pd.notna(df_row), np.nan)  # pd.NA -> np.nan\n",
        "        if hasattr(preproc, \"get_feature_names_out\"):\n",
        "            names = list(preproc.get_feature_names_out())\n",
        "        else:\n",
        "            names = [f\"f{i}\" for i in range(getattr(preproc, \"n_features_in_\", 0) or len(ALL_EXPECTED))]\n",
        "        X = preproc.transform(df_row)\n",
        "        vals = np.asarray(X).ravel().tolist()\n",
        "        engineered_record = {n: v for n, v in zip(names, vals)}\n",
        "        overlap2 = set(baseline_stats.keys()) & set(engineered_record.keys())\n",
        "        if overlap2:\n",
        "            drift_flag, drift_msg = check_feature_drift(engineered_record, baseline_stats)\n",
        "        else:\n",
        "            try:\n",
        "                logger.info(\"No overlapping engineered features for drift check.\")\n",
        "            except Exception:\n",
        "                pass\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.debug(\"Engineered drift check not available\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "print(drift_msg if drift_flag else \"✅ No significant feature drift detected.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a87ecb6-8531-4cba-a6dc-1d28d2c13084",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Output Schema Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1379e002-a49d-4baa-8bb4-bcba298e5744",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Output record built.\n"
          ]
        }
      ],
      "source": [
        "# === Output schema builder (refactor, aligned) — SAFE GUARDS ===\n",
        "from __future__ import annotations\n",
        "from typing import Dict, Any, Optional\n",
        "from datetime import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from shared.common.utils import get_utc_now\n",
        "from shared.common.constants import SCHEMA_VERSION\n",
        "\n",
        "# (nel dubbio, import del constant)\n",
        "try:\n",
        "    ASSET_ID\n",
        "except NameError:\n",
        "    from shared.common.constants import ASSET_ID\n",
        "\n",
        "def _utc_now_z() -> str:\n",
        "    \"\"\"UTC ISO-8601 senza microsecondi, suffisso 'Z'.\"\"\"\n",
        "    return get_utc_now().replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "def _model_health_dict() -> Dict[str, Any]:\n",
        "    \"\"\"Raccoglie info basilari sugli artefatti del modello.\"\"\"\n",
        "    if PIPELINE_PATH.exists():\n",
        "        size_mb = round(PIPELINE_PATH.stat().st_size / (1024 * 1024), 2)\n",
        "        last_mod = datetime.utcfromtimestamp(PIPELINE_PATH.stat().st_mtime).replace(microsecond=0).isoformat() + \"Z\"\n",
        "        status = \"ok\"\n",
        "    else:\n",
        "        size_mb = 0.0\n",
        "        last_mod = None\n",
        "        status = \"missing\"\n",
        "\n",
        "    # Preferisci metriche da manifest, poi da meta.json\n",
        "    mf_metrics = {}\n",
        "    try:\n",
        "        if MANIFEST_PATH and MANIFEST_PATH.exists():\n",
        "            mf = json.loads(MANIFEST_PATH.read_text(encoding=\"utf-8\"))\n",
        "            mroot = mf.get(\"metrics\") or {}\n",
        "            mf_metrics = mroot.get(\"validation\") or mroot.get(\"valid\") or {}\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.info(\"Manifest not readable for metrics\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    meta_metrics = model_meta.get(\"metrics\", {}) or {}\n",
        "    metrics = mf_metrics or meta_metrics\n",
        "\n",
        "    return {\n",
        "        \"status\": status,\n",
        "        \"model_path\": str(PIPELINE_PATH),\n",
        "        \"size_mb\": size_mb,\n",
        "        \"last_modified\": last_mod,\n",
        "        \"metadata_valid\": META_PATH.exists(),\n",
        "        \"metrics\": metrics,\n",
        "    }\n",
        "\n",
        "def build_output_record(\n",
        "    record: Dict[str, Any],\n",
        "    *,\n",
        "    asset_type: str,\n",
        "    confidence_output: Dict[str, Any],\n",
        "    latency_ms: float,\n",
        "    has_anomaly: bool,\n",
        "    validation_report: Dict[str, Any],\n",
        "    drift_flag: bool,\n",
        "    drift_msg: Optional[str],\n",
        "    extra_metrics: Optional[Dict[str, Any]] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Costruisce il payload finale, pronto per log/publish.\"\"\"\n",
        "    # Info modello\n",
        "    try:\n",
        "        model_name = type(getattr(pipeline, \"steps\", [[None, pipeline]])[-1][1]).__name__\n",
        "    except Exception:\n",
        "        model_name = model_meta.get(\"model_class\")\n",
        "\n",
        "    ci_low, ci_high = confidence_output[\"confidence_interval\"]\n",
        "\n",
        "    out: Dict[str, Any] = {\n",
        "        \"schema_version\": SCHEMA_VERSION,  # \"2.0\"\n",
        "        \"asset_id\": record.get(ASSET_ID, f\"asset_manual_0001\"),\n",
        "        \"asset_type\": asset_type,\n",
        "        \"timestamp\": _utc_now_z(),\n",
        "        \"metrics\": {\n",
        "            \"valuation_k\": round(float(confidence_output[\"prediction\"]), 3),\n",
        "            \"point_pred_k\": round(float(confidence_output.get(\"point_pred\", confidence_output[\"prediction\"])), 3),\n",
        "            \"uncertainty_k\": round(float(confidence_output[\"uncertainty\"]), 3),\n",
        "            \"confidence\": float(confidence_output.get(\"confidence\", 0.95)),\n",
        "            \"confidence_low_k\": round(float(ci_low), 3),\n",
        "            \"confidence_high_k\": round(float(ci_high), 3),\n",
        "            \"ci_margin_k\": round(float(confidence_output[\"ci_margin\"]), 3),\n",
        "            \"latency_ms\": float(latency_ms),\n",
        "        },\n",
        "        \"flags\": {\n",
        "            \"anomaly\": bool(has_anomaly),\n",
        "            \"drift_detected\": bool(drift_flag),\n",
        "            \"needs_review\": bool(has_anomaly or drift_flag),\n",
        "        },\n",
        "        \"model_meta\": {\n",
        "            \"value_model_version\": MODEL_VERSION,\n",
        "            \"value_model_name\": model_name,\n",
        "            \"n_features_total\": len(ALL_EXPECTED),\n",
        "            \"n_features_categorical\": len(categorical_expected),\n",
        "            \"n_features_numeric\": len(numeric_expected),\n",
        "        },\n",
        "        \"model_health\": _model_health_dict(),\n",
        "        \"validation\": {\n",
        "            \"ok\": bool(validation_report.get(\"ok\", True)),\n",
        "            \"warnings\": validation_report.get(\"warnings\"),\n",
        "            \"errors\": validation_report.get(\"errors\"),\n",
        "        },\n",
        "        \"drift\": {\n",
        "            \"message\": drift_msg,\n",
        "        },\n",
        "        # placeholder compatibili col resto dello stack\n",
        "        \"offchain_refs\": {\"detail_report_hash\": None, \"sensor_batch_hash\": None},\n",
        "        \"cache_hit\": False,\n",
        "        \"schema_validation_error\": \"\",\n",
        "        \"blockchain_txid\": \"\",\n",
        "        \"asa_id\": \"\",\n",
        "        \"publish\": {\"status\": \"skipped\"},\n",
        "    }\n",
        "\n",
        "    if \"method\" in confidence_output:\n",
        "        out[\"metrics\"][\"ci_method\"] = confidence_output[\"method\"]\n",
        "    if confidence_output.get(\"n_estimators\") is not None:\n",
        "        out[\"metrics\"][\"n_estimators\"] = int(confidence_output[\"n_estimators\"])\n",
        "\n",
        "    if extra_metrics:\n",
        "        for k, v in extra_metrics.items():\n",
        "            try:\n",
        "                out[\"metrics\"][k] = round(float(v), 3)\n",
        "            except Exception:\n",
        "                try:\n",
        "                    logger.warning(\"Skipping non-numeric extra metric\", extra={\"key\": k, \"value\": v})\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    return out\n",
        "\n",
        "# ------------------------ GUARD RUNTIME VARIABLES ------------------------\n",
        "# 1) Predizione + CI + latenza (adatta alla nuova firma di predict_with_confidence)\n",
        "if \"confidence_output\" not in locals() or \"latency_ms\" not in locals():\n",
        "    t0 = time.perf_counter()\n",
        "    confidence_output = predict_with_confidence(\n",
        "        sample_property,\n",
        "        pipeline_obj=pipeline,\n",
        "        expected_features=ALL_EXPECTED,\n",
        "        manifest_path=MANIFEST_PATH,\n",
        "        confidence=0.95,\n",
        "        verbose=False,\n",
        "    )\n",
        "    latency_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "\n",
        "# 2) Validation/anomaly (se mancano)\n",
        "if \"validation_report\" not in locals() or \"has_anomaly\" not in locals():\n",
        "    # usa la nostra validate_input_record (strict=False per non bloccare)\n",
        "    _, validation_report = validate_input_record(sample_property, strict=False)\n",
        "    has_anomaly = not validation_report.get(\"ok\", True)\n",
        "\n",
        "# 3) Drift (se mancano): prova raw → engineered\n",
        "if \"drift_flag\" not in locals() or \"drift_msg\" not in locals():\n",
        "    # baseline da meta (raw → engineered)\n",
        "    source = (\n",
        "        model_meta.get(\"raw_feature_stats\")\n",
        "        or model_meta.get(\"engineered_feature_stats\")\n",
        "        or {}\n",
        "    )\n",
        "    baseline_stats = {}\n",
        "    for k, v in source.items():\n",
        "        if isinstance(v, dict) and \"mean\" in v:\n",
        "            entry = {key: v[key] for key in (\"mean\", \"std\", \"min\", \"max\", \"iqr\") if key in v}\n",
        "            baseline_stats[k] = entry\n",
        "    drift_flag, drift_msg = check_feature_drift(sample_property, baseline_stats)\n",
        "    if not drift_flag:\n",
        "        # engineered fallback\n",
        "        try:\n",
        "            preproc = pipeline[:-1]\n",
        "            df_tmp = pd.DataFrame([{k: sample_property.get(k, np.nan) for k in ALL_EXPECTED}], columns=ALL_EXPECTED)\n",
        "            df_tmp = df_tmp.where(pd.notna(df_tmp), np.nan)  # pd.NA -> np.nan\n",
        "            if hasattr(preproc, \"get_feature_names_out\"):\n",
        "                names = list(preproc.get_feature_names_out())\n",
        "            else:\n",
        "                names = [f\"f{i}\" for i in range(getattr(preproc, \"n_features_in_\", 0) or len(ALL_EXPECTED))]\n",
        "            X = preproc.transform(df_tmp)\n",
        "            vals = np.asarray(X).ravel().tolist()\n",
        "            engineered = {n: v for n, v in zip(names, vals)}\n",
        "            drift_flag, drift_msg = check_feature_drift(engineered, baseline_stats)\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                logger.debug(\"Engineered drift check not available\", extra={\"error\": str(e)})\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "# ------------------------ BUILD OUTPUT ------------------------\n",
        "single_output = build_output_record(\n",
        "    sample_property,\n",
        "    asset_type=ASSET_TYPE,\n",
        "    confidence_output=confidence_output,\n",
        "    latency_ms=latency_ms,\n",
        "    has_anomaly=has_anomaly,\n",
        "    validation_report=validation_report,\n",
        "    drift_flag=drift_flag,\n",
        "    drift_msg=drift_msg,\n",
        ")\n",
        "print(\"✅ Output record built.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0ffd39",
      "metadata": {},
      "source": [
        "### Pre-chain compaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "675241e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note size=281 bytes | sha256=bd083220182189d3…\n"
          ]
        }
      ],
      "source": [
        "from shared.common.constants import NOTE_MAX_BYTES\n",
        "from shared.common.utils import canonical_json_dumps, sha256_hex\n",
        "\n",
        "def build_compact_note(out: dict) -> dict:\n",
        "    # tieni SOLO quanto necessario on-chain (hash-first approach)\n",
        "    note = {\n",
        "        \"schema_version\": \"v2\",\n",
        "        \"asset_id\": out[\"asset_id\"],\n",
        "        \"asset_type\": out[\"asset_type\"],\n",
        "        \"timestamp\": out[\"timestamp\"],\n",
        "        \"model\": {\n",
        "            \"version\": out[\"model_meta\"][\"value_model_version\"],\n",
        "            \"hash\": model_meta.get(\"pipeline_sha256\") or model_meta.get(\"model_hash\"),\n",
        "        },\n",
        "        \"metrics\": {\n",
        "            \"valuation_k\": out[\"metrics\"][\"valuation_k\"],\n",
        "            \"confidence\": out[\"metrics\"][\"confidence\"],\n",
        "            \"ci\": [out[\"metrics\"][\"confidence_low_k\"], out[\"metrics\"][\"confidence_high_k\"]],\n",
        "        },\n",
        "        # opzionale: input_hash, trace_id se disponibili\n",
        "    }\n",
        "    return note\n",
        "\n",
        "note = build_compact_note(single_output)\n",
        "note_bytes = canonical_json_dumps(note).encode(\"utf-8\")\n",
        "note_size = len(note_bytes)\n",
        "note_sha256 = sha256_hex(note_bytes)\n",
        "\n",
        "single_output.setdefault(\"publish\", {}).update({\n",
        "    \"status\": \"skipped\",\n",
        "    \"note_size\": note_size,\n",
        "    \"note_sha256\": note_sha256,\n",
        "    \"is_compacted\": True,\n",
        "    \"fallback_url_used\": False,\n",
        "})\n",
        "\n",
        "assert note_size <= NOTE_MAX_BYTES, f\"Nota troppo grande: {note_size} > {NOTE_MAX_BYTES}\"\n",
        "print(f\"Note size={note_size} bytes | sha256={note_sha256[:16]}…\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6fac87-59c9-4c72-8338-3258c69ce606",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Batch Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "fee068f8-37fe-4d6e-9e08-1a27b4ecb5e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 250.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[2025-09-23 03:26:15,801] INFO nb04_infer: Engineered drift check failed\n",
            "[VALIDATION] Asset None normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 60.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[2025-09-23 03:26:15,969] INFO nb04_infer: Engineered drift check failed\n",
            "[VALIDATION] Asset None normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 35.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[2025-09-23 03:26:16,130] INFO nb04_infer: Engineered drift check failed\n",
            "[VALIDATION] Asset None normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 75.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[2025-09-23 03:26:16,290] INFO nb04_infer: Engineered drift check failed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>valuation_k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asset_batch_001</td>\n",
              "      <td>6.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>asset_batch_002</td>\n",
              "      <td>6.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>asset_batch_003</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asset_batch_004</td>\n",
              "      <td>6.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          asset_id  valuation_k\n",
              "0  asset_batch_001         6.38\n",
              "1  asset_batch_002         6.02\n",
              "2  asset_batch_003         5.94\n",
              "3  asset_batch_004         6.24"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Batch Inference (refactor, aligned) ===\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Definisci alcuni sample variati a partire dal validated sample\n",
        "batch_samples = [\n",
        "    deepcopy(sample_property),\n",
        "    {**sample_property, \"asset_id\": None, \"location\": \"Rome\",     \"size_m2\": 120, \"energy_class\": \"C\"},\n",
        "    {**sample_property, \"asset_id\": None, \"location\": \"Florence\", \"size_m2\":  70, \"has_garden\": 1, \"energy_class\": \"A\"},\n",
        "    {**sample_property, \"asset_id\": None, \"location\": \"Turin\",    \"size_m2\": 150, \"energy_class\": \"D\"},\n",
        "]\n",
        "\n",
        "def _drift_for_record(rec: dict) -> tuple[bool, str | None]:\n",
        "    \"\"\"Prova drift su raw features; se non c'è overlap, tenta engineered tramite preproc.\"\"\"\n",
        "    # 1) Raw overlap\n",
        "    overlap = set(baseline_stats.keys()) & set(rec.keys())\n",
        "    if overlap:\n",
        "        return check_feature_drift(rec, baseline_stats)\n",
        "    # 2) Engineered fallback\n",
        "    try:\n",
        "        preproc = pipeline[:-1]  # tutto tranne il modello\n",
        "        if hasattr(preproc, \"get_feature_names_out\"):\n",
        "            names = list(preproc.get_feature_names_out())\n",
        "        else:\n",
        "            names = None\n",
        "        X = preproc.transform(pd.DataFrame([{k: rec.get(k, np.nan) for k in ALL_EXPECTED}], columns=ALL_EXPECTED))\n",
        "        vals = np.asarray(X).ravel().tolist()\n",
        "        engineered = {n: v for n, v in zip(names or range(len(vals)), vals)}\n",
        "        overlap2 = set(baseline_stats.keys()) & set(engineered.keys())\n",
        "        if overlap2:\n",
        "            return check_feature_drift(engineered, baseline_stats)\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.info(\"Engineered drift check failed\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "    return False, None\n",
        "\n",
        "batch_outputs = []\n",
        "for i, raw in enumerate(batch_samples, start=1):\n",
        "    # 1) Validate + canonicalize (riusa report per anomaly)\n",
        "    rec, vreport = validate_input_record(raw, strict=True)\n",
        "    if ASSET_ID not in rec or not rec.get(ASSET_ID):\n",
        "        rec[ASSET_ID] = f\"asset_batch_{i:03}\"\n",
        "\n",
        "    # 2) Predict + CI + timing reale (nuova firma)\n",
        "    t0 = time.perf_counter()\n",
        "    conf = predict_with_confidence(\n",
        "        rec,\n",
        "        pipeline_obj=pipeline,\n",
        "        expected_features=ALL_EXPECTED,\n",
        "        manifest_path=MANIFEST_PATH,\n",
        "        confidence=0.95,\n",
        "        verbose=False,\n",
        "    )\n",
        "    latency_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "\n",
        "    # 3) Drift & anomaly flags\n",
        "    drift_flag, drift_msg = _drift_for_record(rec)\n",
        "    has_anomaly = not vreport.get(\"ok\", True)\n",
        "\n",
        "    # 4) Build output record\n",
        "    out = build_output_record(\n",
        "        rec,\n",
        "        asset_type=ASSET_TYPE,\n",
        "        confidence_output=conf,\n",
        "        latency_ms=latency_ms,\n",
        "        has_anomaly=has_anomaly,\n",
        "        validation_report=vreport,\n",
        "        drift_flag=drift_flag,\n",
        "        drift_msg=drift_msg,\n",
        "    )\n",
        "    batch_outputs.append(out)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
        "\n",
        "# Riepilogo compatto\n",
        "pd.DataFrame(\n",
        "    [{\"asset_id\": o[\"asset_id\"], \"valuation_k\": o[\"metrics\"][\"valuation_k\"]} for o in batch_outputs]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b30533-6431-4327-8c9a-b781ecd1601f",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Logging JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "cb4b3446-a1ba-4b53-9cd2-83ae069e8b1f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Appended 5 predictions to outputs\\logs\\predictions_log.jsonl\n",
            "Appended monitoring for 5 records to outputs\\logs\\monitoring_log.jsonl\n"
          ]
        }
      ],
      "source": [
        "# === JSONL Logging (atomic append) ===\n",
        "from datetime import datetime\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "from shared.common.utils import canonical_json_dumps, get_utc_now\n",
        "\n",
        "MONITOR_LOG_PATH = Path(\"./outputs/logs/monitoring_log.jsonl\")\n",
        "MONITOR_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def append_jsonl(record: dict, path: Path) -> None:\n",
        "    \"\"\"Append atomico in JSONL, con timestamp UTC 'Z' e JSON canonico/compatto.\"\"\"\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    payload = {**record, \"_logged_at\": get_utc_now().replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")}\n",
        "    line = canonical_json_dumps(payload)\n",
        "    fd = os.open(str(path), os.O_WRONLY | os.O_CREAT | os.O_APPEND)\n",
        "    try:\n",
        "        with os.fdopen(fd, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(line + \"\\n\")\n",
        "            f.flush()\n",
        "            os.fsync(f.fileno())\n",
        "    except Exception:\n",
        "        # in caso di errore, chiudi comunque il descrittore\n",
        "        try:\n",
        "            os.close(fd)\n",
        "        except Exception:\n",
        "            pass\n",
        "        raise\n",
        "\n",
        "# Predictions log\n",
        "append_jsonl(single_output, LOG_PATH)\n",
        "for o in batch_outputs:\n",
        "    append_jsonl(o, LOG_PATH)\n",
        "print(f\"Appended {1 + len(batch_outputs)} predictions to {LOG_PATH}\")\n",
        "\n",
        "# Monitoring log (deriva dai record già costruiti: nessuna stima duplicata)\n",
        "def _to_monitoring(entry: dict) -> dict:\n",
        "    m = entry.get(\"metrics\", {}) or {}\n",
        "    mm = entry.get(\"model_meta\", {}) or {}\n",
        "    return {\n",
        "        \"asset_id\": entry.get(\"asset_id\"),\n",
        "        \"model_version\": mm.get(\"value_model_version\", MODEL_VERSION),\n",
        "        \"model_class\": mm.get(\"value_model_name\"),\n",
        "        \"latency_ms\": m.get(\"latency_ms\"),\n",
        "        \"valuation_k\": m.get(\"valuation_k\") or m.get(\"valuation_base_k\"),\n",
        "        \"uncertainty_k\": m.get(\"uncertainty_k\") or m.get(\"uncertainty\"),\n",
        "        \"confidence_low_k\": m.get(\"confidence_low_k\"),\n",
        "        \"confidence_high_k\": m.get(\"confidence_high_k\"),\n",
        "        \"ci_method\": m.get(\"ci_method\"),\n",
        "        \"n_estimators\": m.get(\"n_estimators\"),\n",
        "        \"anomaly\": entry.get(\"flags\", {}).get(\"anomaly\"),\n",
        "        \"drift_detected\": entry.get(\"flags\", {}).get(\"drift_detected\"),\n",
        "    }\n",
        "\n",
        "append_jsonl(_to_monitoring(single_output), MONITOR_LOG_PATH)\n",
        "for o in batch_outputs:\n",
        "    append_jsonl(_to_monitoring(o), MONITOR_LOG_PATH)\n",
        "\n",
        "print(f\"Appended monitoring for {1 + len(batch_outputs)} records to {MONITOR_LOG_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc82054-05e6-4bc5-99a4-46d015820d74",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Single Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1b190e70-f17f-4b47-beb3-0631ac1a6b73",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 250.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[2025-09-23 03:26:23,590] INFO nb04_infer: Engineered drift check failed\n",
            "[2025-09-23 03:26:23,597] INFO nb04_infer: explain_price not available\n",
            "[2025-09-23 03:26:23,617] INFO nb04_infer: price_benchmark not available\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'schema_version': 'v2',\n",
              " 'asset_id': 'asset_function_test',\n",
              " 'asset_type': 'property',\n",
              " 'timestamp': '2025-09-23T01:26:23Z',\n",
              " 'metrics': {'valuation_k': 6.38,\n",
              "  'point_pred_k': 6.38,\n",
              "  'uncertainty_k': 1.0,\n",
              "  'confidence': 0.95,\n",
              "  'confidence_low_k': 4.42,\n",
              "  'confidence_high_k': 8.34,\n",
              "  'ci_margin_k': 1.96,\n",
              "  'latency_ms': 245.04,\n",
              "  'ci_method': 'global_sigma'},\n",
              " 'flags': {'anomaly': False, 'drift_detected': False, 'needs_review': False},\n",
              " 'model_meta': {'value_model_version': 'v2',\n",
              "  'value_model_name': 'Pipeline',\n",
              "  'n_features_total': 26,\n",
              "  'n_features_categorical': 8,\n",
              "  'n_features_numeric': 18},\n",
              " 'model_health': {'status': 'ok',\n",
              "  'model_path': 'outputs\\\\modeling\\\\property\\\\value_regressor_v2.joblib',\n",
              "  'size_mb': 158.25,\n",
              "  'last_modified': '2025-09-23T00:05:48Z',\n",
              "  'metadata_valid': True,\n",
              "  'metrics': {}},\n",
              " 'validation': {'ok': True, 'warnings': None, 'errors': None},\n",
              " 'drift': {'message': None},\n",
              " 'offchain_refs': {'detail_report_hash': None, 'sensor_batch_hash': None},\n",
              " 'cache_hit': False,\n",
              " 'schema_validation_error': '',\n",
              " 'blockchain_txid': '',\n",
              " 'asa_id': '',\n",
              " 'publish': {'status': 'skipped'}}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Utility: Single Prediction Function (refactor, aligned) ===\n",
        "from typing import Dict, Any, Optional\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _ensure_baseline_stats() -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Normalizza le baseline stats da model_meta (raw → engineered).\"\"\"\n",
        "    source = (\n",
        "        model_meta.get(\"raw_feature_stats\")\n",
        "        or model_meta.get(\"engineered_feature_stats\")\n",
        "        or {}\n",
        "    )\n",
        "    baseline: Dict[str, Dict[str, Any]] = {}\n",
        "    for k, v in source.items():\n",
        "        if isinstance(v, dict) and \"mean\" in v:\n",
        "            entry = {key: v[key] for key in (\"mean\", \"std\", \"min\", \"max\", \"iqr\") if key in v}\n",
        "            baseline[k] = entry\n",
        "        elif isinstance(v, (list, tuple)) and len(v) >= 1:\n",
        "            try:\n",
        "                entry = {\"mean\": float(v[0])}\n",
        "                if len(v) > 1:\n",
        "                    entry[\"std\"] = float(v[1])\n",
        "                baseline[k] = entry\n",
        "            except Exception:\n",
        "                pass\n",
        "    return baseline\n",
        "\n",
        "def _drift_for_record(rec: dict, baseline_stats: dict) -> tuple[bool, Optional[str]]:\n",
        "    # 1) Raw overlap\n",
        "    overlap = set(baseline_stats.keys()) & set(rec.keys())\n",
        "    if overlap:\n",
        "        return check_feature_drift(rec, baseline_stats)\n",
        "    # 2) Engineered fallback\n",
        "    try:\n",
        "        preproc = pipeline[:-1]  # tutto tranne il modello\n",
        "        if hasattr(preproc, \"get_feature_names_out\"):\n",
        "            names = list(preproc.get_feature_names_out())\n",
        "        else:\n",
        "            names = None\n",
        "        X = preproc.transform(pd.DataFrame([{k: rec.get(k, np.nan) for k in ALL_EXPECTED}], columns=ALL_EXPECTED))\n",
        "        vals = np.asarray(X).ravel().tolist()\n",
        "        engineered = {n: v for n, v in zip(names or range(len(vals)), vals)}\n",
        "        overlap2 = set(baseline_stats.keys()) & set(engineered.keys())\n",
        "        if overlap2:\n",
        "            return check_feature_drift(engineered, baseline_stats)\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.info(\"Engineered drift check failed\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "    return False, None\n",
        "\n",
        "def predict_asset(record: Dict[str, Any], asset_id: Optional[str] = None, asset_type: str = ASSET_TYPE) -> Dict[str, Any]:\n",
        "    # 1) Validazione + canonicalizzazione + derivate sicure\n",
        "    rec, vreport = validate_input_record(record, strict=True)\n",
        "    if not rec.get(ASSET_ID):\n",
        "        rec[ASSET_ID] = asset_id or f\"asset_single_{np.random.randint(1_000_000):06d}\"\n",
        "\n",
        "    # 2) Predizione + CI + latenza reale (nuova firma)\n",
        "    t0 = time.perf_counter()\n",
        "    conf = predict_with_confidence(\n",
        "        rec,\n",
        "        pipeline_obj=pipeline,\n",
        "        expected_features=ALL_EXPECTED,\n",
        "        manifest_path=MANIFEST_PATH,\n",
        "        confidence=0.95,\n",
        "        verbose=False,\n",
        "    )\n",
        "    latency_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "\n",
        "    # 3) Drift & anomaly\n",
        "    baseline = _ensure_baseline_stats()\n",
        "    drift_flag, drift_msg = _drift_for_record(rec, baseline)\n",
        "    has_anomaly = not vreport.get(\"ok\", True)\n",
        "\n",
        "    # 4) Output record coerente\n",
        "    out = build_output_record(\n",
        "        rec,\n",
        "        asset_type=asset_type,\n",
        "        confidence_output=conf,\n",
        "        latency_ms=latency_ms,\n",
        "        has_anomaly=has_anomaly,\n",
        "        validation_report=vreport,\n",
        "        drift_flag=drift_flag,\n",
        "        drift_msg=drift_msg,\n",
        "    )\n",
        "\n",
        "    # --- Pricing breakdown (euristico) ---\n",
        "    price_expl = _maybe_explain_price(record)\n",
        "    if price_expl:\n",
        "        out.setdefault(\"explanations\", {})[\"pricing_breakdown\"] = price_expl\n",
        "\n",
        "    # --- Sanity check di prezzo (benchmark per location) ---\n",
        "    yhat_k = float(conf[\"prediction\"])\n",
        "    pb = _price_benchmark_flag(record, yhat_k)\n",
        "    if pb:\n",
        "        # salva il report nel payload\n",
        "        out.setdefault(\"sanity\", {})[\"price_benchmark\"] = pb\n",
        "        # se esiste un flag 'out_of_band', riflettilo nei flags globali\n",
        "        out[\"flags\"][\"price_out_of_band\"] = bool(pb.get(\"out_of_band\", False))\n",
        "        # opzionale: includi anche questo nel needs_review\n",
        "        out[\"flags\"][\"needs_review\"] = bool(out[\"flags\"][\"needs_review\"] or pb.get(\"out_of_band\", False))\n",
        "\n",
        "    return out\n",
        "\n",
        "# Test rapido\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
        "test_output = predict_asset(sample_property, asset_id=\"asset_function_test\")\n",
        "test_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b507a90c-a003-40e6-a97c-d4763895ba1c",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Sensitivity Check (vary size_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e1622a58-f3cd-47b3-8e5b-efe2cc2eadcd",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 30.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 45.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 65.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 85.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "[VALIDATION] Asset asset_infer_eaa37945 normalized. Errors=['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"] Flags=['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'] Changes={'valuation_k': (None, 105.0), 'validation_errors': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_k_too_low_or_missing', 'price_per_sqm_non_positive_or_missing', \"missing_keys:['temperature_avg', 'listing_month', 'air_quality_index', 'view', 'distance_to_center_km', 'orientation', 'humidity_level', 'noise_level', 'owner_occupied', 'urban_type', 'risk_score', 'parking_spot', 'condition_score', 'zone', 'cellar', 'location', 'garage', 'concierge', 'condition', 'region', 'attic', 'heating']\"]), 'price_per_sqm': (None, 500.0), 'is_top_floor': (None, 0), 'is_ground_floor': (None, 0), 'validation_flags': (None, ['condition_score_missing', 'risk_score_missing', 'valuation_override', 'price_per_sqm_recomputed', 'schema_incomplete'])}\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.at[0, col] = \"\"\n",
            "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_15652\\1350153677.py:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(_to_numpy_nan)\n",
            "d:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size_m2</th>\n",
              "      <th>prediction_k</th>\n",
              "      <th>ci_low_k</th>\n",
              "      <th>ci_high_k</th>\n",
              "      <th>ci_margin_k</th>\n",
              "      <th>uncertainty_k</th>\n",
              "      <th>delta_vs_base_k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>5.82</td>\n",
              "      <td>3.86</td>\n",
              "      <td>7.78</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90</td>\n",
              "      <td>5.93</td>\n",
              "      <td>3.97</td>\n",
              "      <td>7.89</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>130</td>\n",
              "      <td>6.15</td>\n",
              "      <td>4.19</td>\n",
              "      <td>8.11</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170</td>\n",
              "      <td>6.35</td>\n",
              "      <td>4.39</td>\n",
              "      <td>8.31</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>210</td>\n",
              "      <td>6.38</td>\n",
              "      <td>4.42</td>\n",
              "      <td>8.34</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   size_m2  prediction_k  ci_low_k  ci_high_k  ci_margin_k  uncertainty_k  \\\n",
              "0       60          5.82      3.86       7.78         1.96            1.0   \n",
              "1       90          5.93      3.97       7.89         1.96            1.0   \n",
              "2      130          6.15      4.19       8.11         1.96            1.0   \n",
              "3      170          6.35      4.39       8.31         1.96            1.0   \n",
              "4      210          6.38      4.42       8.34         1.96            1.0   \n",
              "\n",
              "   delta_vs_base_k  \n",
              "0            -0.56  \n",
              "1            -0.45  \n",
              "2            -0.23  \n",
              "3            -0.03  \n",
              "4             0.00  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Sensitivity check: 'size_m2' (refactor, aligned) ===\n",
        "sizes = [60, 90, 130, 170, 210]\n",
        "rows = []\n",
        "\n",
        "# baseline (size attuale del sample)\n",
        "base_conf = predict_with_confidence(\n",
        "    sample_property,\n",
        "    pipeline_obj=pipeline,\n",
        "    expected_features=ALL_EXPECTED,\n",
        "    manifest_path=MANIFEST_PATH,\n",
        "    confidence=0.95,\n",
        "    verbose=False,\n",
        ")\n",
        "base_pred = float(base_conf[\"prediction\"])\n",
        "\n",
        "for s in sizes:\n",
        "    rec_raw = {**sample_property, \"size_m2\": s}\n",
        "    try:\n",
        "        rec, _vreport = validate_input_record(rec_raw, strict=True)\n",
        "        conf = predict_with_confidence(\n",
        "            rec,\n",
        "            pipeline_obj=pipeline,\n",
        "            expected_features=ALL_EXPECTED,\n",
        "            manifest_path=MANIFEST_PATH,\n",
        "            confidence=0.95,\n",
        "            verbose=False,\n",
        "        )\n",
        "        ci_low, ci_high = conf[\"confidence_interval\"]\n",
        "        rows.append({\n",
        "            \"size_m2\": s,\n",
        "            \"prediction_k\": round(float(conf[\"prediction\"]), 3),\n",
        "            \"ci_low_k\": round(float(ci_low), 3),\n",
        "            \"ci_high_k\": round(float(ci_high), 3),\n",
        "            \"ci_margin_k\": round(float(conf[\"ci_margin\"]), 3),\n",
        "            \"uncertainty_k\": round(float(conf[\"uncertainty\"]), 3),\n",
        "            \"delta_vs_base_k\": round(float(conf[\"prediction\"]) - base_pred, 3),\n",
        "        })\n",
        "    except Exception as e:\n",
        "        rows.append({\"size_m2\": s, \"prediction_k\": None, \"error\": str(e)})\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
        "pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84f9f3e-aaad-4843-a735-1c388f17da55",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Compare With API Prediction Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "40996a99-ed49-473f-8ddb-74d5d36f932d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[API] ❌ 500 | {\"detail\":\"Inference error: boolean value of NA is ambiguous\"}\n"
          ]
        }
      ],
      "source": [
        "# === Compare with API prediction consistency (refactor, robust) ===\n",
        "import os\n",
        "import requests\n",
        "\n",
        "if COMPARE_WITH_API:\n",
        "    def _pick_pred_metrics(payload: dict):\n",
        "        \"\"\"Estrae predizione e CI dall'output API (tollerante a v1/v2/flat).\"\"\"\n",
        "        if not isinstance(payload, dict):\n",
        "            return None, None, None, None\n",
        "        m = payload.get(\"metrics\", {}) if isinstance(payload.get(\"metrics\"), dict) else {}\n",
        "        # fallback flat\n",
        "        pred = (\n",
        "            m.get(\"valuation_k\")\n",
        "            or m.get(\"valuation_base_k\")\n",
        "            or m.get(\"valuation\")\n",
        "            or payload.get(\"valuation_k\")\n",
        "            or payload.get(\"prediction\")\n",
        "        )\n",
        "        ci_low = m.get(\"confidence_low_k\") or payload.get(\"confidence_low_k\")\n",
        "        ci_high = m.get(\"confidence_high_k\") or payload.get(\"confidence_high_k\")\n",
        "        unc = m.get(\"uncertainty_k\") or m.get(\"uncertainty\") or payload.get(\"uncertainty_k\")\n",
        "        return pred, ci_low, ci_high, unc\n",
        "\n",
        "    def _model_version(payload: dict):\n",
        "        mm = (payload or {}).get(\"model_meta\", {}) if isinstance(payload, dict) else {}\n",
        "        return mm.get(\"value_model_version\") or mm.get(\"model_version\")\n",
        "\n",
        "    try:\n",
        "        # Usa il record già validato per coerenza\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        token = os.getenv(\"AXM_TOKEN\")\n",
        "        if token:\n",
        "            headers[\"Authorization\"] = f\"Bearer {token}\"\n",
        "        url = f\"{API_BASE}/predict/{ASSET_TYPE}\"\n",
        "\n",
        "        resp = requests.post(url, json=sample_property, headers=headers, timeout=8)\n",
        "        if resp.status_code == 200:\n",
        "            api_json = resp.json()\n",
        "            api_pred, api_low, api_high, api_unc = _pick_pred_metrics(api_json)\n",
        "\n",
        "            if api_pred is None:\n",
        "                print(f\"[API] ❌ Response OK ma 'metrics.valuation_*' mancante: {api_json}\")\n",
        "            else:\n",
        "                local_pred = float(single_output[\"metrics\"][\"valuation_k\"])\n",
        "                local_low  = float(single_output[\"metrics\"][\"confidence_low_k\"])\n",
        "                local_high = float(single_output[\"metrics\"][\"confidence_high_k\"])\n",
        "\n",
        "                delta = float(abs(float(api_pred) - local_pred))\n",
        "                pct = (delta / max(1e-9, abs(local_pred))) * 100.0\n",
        "\n",
        "                # Check overlap CI (quando disponibile)\n",
        "                ci_overlap = None\n",
        "                if api_low is not None and api_high is not None:\n",
        "                    try:\n",
        "                        api_low_f, api_high_f = float(api_low), float(api_high)\n",
        "                        ci_overlap = not (api_high_f < local_low or api_low_f > local_high)\n",
        "                    except Exception:\n",
        "                        ci_overlap = None\n",
        "\n",
        "                av = _model_version(api_json)\n",
        "                lv = MODEL_VERSION\n",
        "                ver_note = \"\" if av is None or av == lv else f\" | ⚠️ model_version API={av} vs LOCAL={lv}\"\n",
        "\n",
        "                msg = (\n",
        "                    f\"[API] Pred={float(api_pred):.3f} k€ | Local={local_pred:.3f} k€ | Δ={delta:.4f} ({pct:.2f}%)\"\n",
        "                    f\" | CI overlap: {ci_overlap if ci_overlap is not None else 'n/a'}{ver_note}\"\n",
        "                )\n",
        "                print(msg)\n",
        "        else:\n",
        "            print(f\"[API] ❌ {resp.status_code} | {resp.text[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[API] ⚠️ Compare skipped due to exception: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb46f5d-8713-442d-a46b-3da6b3f70278",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Hash Pipeline File (Audit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "703b2c48-e21a-441c-a574-e266a542cbb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model SHA256: 9bd5abe6c69ebbffed532e21e70b9b1181da20ec89e2d7be9d46f1a35d830a52 (first16=9bd5abe6c69ebbff)\n",
            "Meta   expects: 9bd5abe6c69ebbffed532e21e70b9b1181da20ec89e2d7be9d46f1a35d830a52 (match: True)\n",
            "Manifest expects: 9bd5abe6c69ebbffed532e21e70b9b1181da20ec89e2d7be9d46f1a35d830a52 (match: True)\n"
          ]
        }
      ],
      "source": [
        "# === Audit: hash artifacts & compare with manifest/meta ===\n",
        "import hashlib\n",
        "import json\n",
        "\n",
        "def file_sha256(path: Path, chunk_size: int = 1 << 20) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with path.open(\"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def manifest_expected_hash(manifest_path: Path) -> str | None:\n",
        "    \"\"\"\n",
        "    Tenta più posizioni comuni per l'hash del pipeline:\n",
        "    - paths.pipeline_sha256 (nostra convenzione)\n",
        "    - model_meta.model_hash (nostra convenzione)\n",
        "    - artifacts.pipeline_sha256 / artifacts.model_sha256 (legacy)\n",
        "    - model.sha256 (legacy)\n",
        "    - pipeline_sha256 (flat)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not manifest_path.exists():\n",
        "            return None\n",
        "        mf = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
        "        return (\n",
        "            (mf.get(\"paths\") or {}).get(\"pipeline_sha256\")\n",
        "            or (mf.get(\"model_meta\") or {}).get(\"model_hash\")\n",
        "            or (mf.get(\"artifacts\") or {}).get(\"pipeline_sha256\")\n",
        "            or (mf.get(\"artifacts\") or {}).get(\"model_sha256\")\n",
        "            or (mf.get(\"model\") or {}).get(\"sha256\")\n",
        "            or mf.get(\"pipeline_sha256\")\n",
        "        )\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            logger.info(\"Manifest present but unreadable for hash\", extra={\"error\": str(e)})\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "# Calcoli\n",
        "model_sha = file_sha256(PIPELINE_PATH)\n",
        "expected_sha_manifest = manifest_expected_hash(MANIFEST_PATH)\n",
        "\n",
        "# Hash atteso dal meta (valore, non hash del file meta!)\n",
        "expected_sha_meta = (model_meta.get(\"model_hash\") or model_meta.get(\"pipeline_sha256\"))\n",
        "\n",
        "print(f\"Model SHA256: {model_sha} (first16={model_sha[:16]})\")\n",
        "if expected_sha_meta:\n",
        "    print(f\"Meta   expects: {expected_sha_meta} (match: {expected_sha_meta == model_sha})\")\n",
        "\n",
        "if expected_sha_manifest:\n",
        "    ok = (expected_sha_manifest == model_sha)\n",
        "    print(f\"Manifest expects: {expected_sha_manifest} (match: {ok})\")\n",
        "    if not ok:\n",
        "        try:\n",
        "            logger.warning(\n",
        "                \"Pipeline hash mismatch with manifest\",\n",
        "                extra={\"expected\": expected_sha_manifest, \"actual\": model_sha},\n",
        "            )\n",
        "        except Exception:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19638225-dee1-4d0c-8602-35c3968fc527",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Schema Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "96b238ff-5955-404f-9cfd-98330fe62475",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔎 Using schema: output_schema_v2.json\n",
            "✅ Strict schema validation passed (single_output).\n",
            "ℹ️ Example file not found: ..\\schemas\\output_example.json\n",
            "✅ Batch outputs: all 4 records pass schema validation.\n"
          ]
        }
      ],
      "source": [
        "# === Strict schema validation (version-aware) ===\n",
        "import json\n",
        "from pathlib import Path\n",
        "from jsonschema import validate, ValidationError\n",
        "from jsonschema import Draft7Validator\n",
        "from shared.common.utils import NumpyJSONEncoder\n",
        "from shared.common.constants import SCHEMA_VERSION as _DEF_SCHEMA_VER\n",
        "\n",
        "try:\n",
        "    # se disponibile, usa un validator più recente\n",
        "    from jsonschema import Draft202012Validator as BetterValidator\n",
        "    Validator = BetterValidator\n",
        "except Exception:\n",
        "    Validator = Draft7Validator\n",
        "\n",
        "SCHEMAS_DIR = Path(\"../schemas\")\n",
        "example_path = SCHEMAS_DIR / \"output_example.json\"\n",
        "\n",
        "def _norm_schema_tag(ver: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalizza la versione di schema dagli output:\n",
        "    accetta '2', '2.0', 'v2' -> 'v2'; altrimenti torna il tag in lower.\n",
        "    \"\"\"\n",
        "    v = (ver or \"\").strip().lower()\n",
        "    if v in {\"2\", \"2.0\", \"02\", \"v2\"}:\n",
        "        return \"v2\"\n",
        "    if v.startswith(\"v\"):\n",
        "        return v\n",
        "    return v\n",
        "\n",
        "# 1) Scegli lo schema in base all'output; fallback al default (v2) poi v1\n",
        "schema_tag = _norm_schema_tag(str(single_output.get(\"schema_version\", _DEF_SCHEMA_VER)))\n",
        "schema_def_path = SCHEMAS_DIR / f\"output_schema_{schema_tag}.json\"\n",
        "if not schema_def_path.exists():\n",
        "    # fallback al default dichiarato nel progetto (es. \"2.0\" -> v2)\n",
        "    schema_def_path = SCHEMAS_DIR / f\"output_schema_{_norm_schema_tag(_DEF_SCHEMA_VER)}.json\"\n",
        "if not schema_def_path.exists():\n",
        "    # fallback legacy a v1, se proprio\n",
        "    schema_def_path = SCHEMAS_DIR / \"output_schema_v1.json\"\n",
        "\n",
        "# 2) Carica schema\n",
        "if not schema_def_path.exists():\n",
        "    print(f\"❌ Schema file not found: {schema_def_path}\")\n",
        "    schema_def = None\n",
        "else:\n",
        "    with schema_def_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        schema_def = json.load(f)\n",
        "    print(f\"🔎 Using schema: {schema_def_path.name}\")\n",
        "\n",
        "# 3) Helper per JSON-compat (np types) e errori leggibili\n",
        "def _to_jsonable(obj: dict) -> dict:\n",
        "    # serializza con NumpyJSONEncoder e ricarica come dict puro\n",
        "    return json.loads(json.dumps(obj, cls=NumpyJSONEncoder, ensure_ascii=False))\n",
        "\n",
        "def _format_error(e: ValidationError) -> str:\n",
        "    path = \".\".join(str(p) for p in e.path) or \"<root>\"\n",
        "    spath = \" → \".join(str(p) for p in e.schema_path)\n",
        "    return f\"at '{path}': {e.message}  [schema: {spath}]\"\n",
        "\n",
        "# 4) Valida il single_output\n",
        "if schema_def:\n",
        "    try:\n",
        "        validate(instance=_to_jsonable(single_output), schema=schema_def)\n",
        "        print(\"✅ Strict schema validation passed (single_output).\")\n",
        "    except ValidationError as e:\n",
        "        print(\"❌ Strict schema validation failed (single_output):\", _format_error(e))\n",
        "\n",
        "# 5) Confronto struttura PROFONDO con l'esempio (se presente)\n",
        "def _deep_keys(d, prefix=\"\"):\n",
        "    keys = set()\n",
        "    if isinstance(d, dict):\n",
        "        for k, v in d.items():\n",
        "            newp = f\"{prefix}.{k}\" if prefix else k\n",
        "            keys.add(newp)\n",
        "            keys |= _deep_keys(v, newp)\n",
        "    elif isinstance(d, list):\n",
        "        if d:\n",
        "            keys |= _deep_keys(d[0], prefix + \"[]\")\n",
        "        else:\n",
        "            keys.add(prefix + \"[]\")\n",
        "    return keys\n",
        "\n",
        "if example_path.exists():\n",
        "    with example_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        example = json.load(f)\n",
        "    ex_keys = _deep_keys(example)\n",
        "    out_keys = _deep_keys(single_output)\n",
        "    only_in_output = sorted(out_keys - ex_keys)\n",
        "    only_in_example = sorted(ex_keys - out_keys)\n",
        "    if not only_in_output and not only_in_example:\n",
        "        print(\"✅ single_output matches example structure (deep).\")\n",
        "    else:\n",
        "        if only_in_output:\n",
        "            print(\"⚠️ Extra keys vs example (deep):\", only_in_output[:10], (\"…+\" if len(only_in_output) > 10 else \"\"))\n",
        "        if only_in_example:\n",
        "            print(\"⚠️ Missing keys vs example (deep):\", only_in_example[:10], (\"…+\" if len(only_in_example) > 10 else \"\"))\n",
        "else:\n",
        "    print(f\"ℹ️ Example file not found: {example_path}\")\n",
        "\n",
        "# 6) Valida anche i batch outputs (se presenti)\n",
        "if schema_def and isinstance(globals().get(\"batch_outputs\"), list) and batch_outputs:\n",
        "    validator = Validator(schema_def)\n",
        "    errors = []\n",
        "    for idx, rec in enumerate(batch_outputs, start=1):\n",
        "        for err in validator.iter_errors(_to_jsonable(rec)):\n",
        "            errors.append((idx, err))\n",
        "    if not errors:\n",
        "        print(f\"✅ Batch outputs: all {len(batch_outputs)} records pass schema validation.\")\n",
        "    else:\n",
        "        print(f\"❌ Batch outputs: {len(errors)} schema errors found on {len(set(i for i, _ in errors))} records.\")\n",
        "        for i, err in errors[:5]:\n",
        "            print(f\"   • [#{i}] {_format_error(err)}\")\n",
        "        if len(errors) > 5:\n",
        "            print(f\"   … and {len(errors)-5} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a68ca6d-044b-49dd-b9c3-9e4d4ee1a98b",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Test API via curl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7d328f82-13ac-4435-aed0-6265985a67f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ℹ️ Using in-notebook sample; cannot load sample_property.json: [Errno 2] No such file or directory: '..\\\\data\\\\sample_property.json'\n",
            "❌ API Call Failed: 500\n",
            "{\"detail\":\"Inference error: boolean value of NA is ambiguous\"}\n"
          ]
        }
      ],
      "source": [
        "# === Test API via requests (configurable, robust) ===\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from uuid import uuid4\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "from shared.common.utils import canonical_json_dumps, NumpyJSONEncoder\n",
        "\n",
        "# Carica payload da file (fallback: sample_property validato)\n",
        "sample_path = Path(\"../data/sample_property.json\")\n",
        "try:\n",
        "    sample_payload = json.loads(sample_path.read_text(encoding=\"utf-8\"))\n",
        "except Exception as e:\n",
        "    print(f\"ℹ️ Using in-notebook sample; cannot load {sample_path.name}: {e}\")\n",
        "    sample_payload = None\n",
        "\n",
        "payload = sample_payload or sample_property\n",
        "\n",
        "# Parametri API\n",
        "PUBLISH = os.getenv(\"PUBLISH\", \"false\").lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
        "url = f\"{API_BASE}/predict/{ASSET_TYPE}\"\n",
        "params = {\"publish\": \"true\"} if PUBLISH else {}\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "token = os.getenv(\"AXM_TOKEN\")\n",
        "if token:\n",
        "    headers[\"Authorization\"] = f\"Bearer {token}\"\n",
        "# opzionale: idempotenza lato server\n",
        "headers[\"X-Idempotency-Key\"] = uuid4().hex\n",
        "\n",
        "# Prepara payload JSON-safe (senza NaN/np types)\n",
        "payload_json = json.loads(json.dumps(payload, cls=NumpyJSONEncoder, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    t0 = time.perf_counter()\n",
        "    resp = requests.post(url, params=params, json=payload_json, headers=headers, timeout=12)\n",
        "    latency_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
        "\n",
        "    if resp.ok:\n",
        "        api_json = resp.json()\n",
        "\n",
        "        # Helper: estrai metrica (v1/v2 compat)\n",
        "        def _pick_pred_metrics(payload: dict):\n",
        "            m = (payload or {}).get(\"metrics\", {}) if isinstance(payload, dict) else {}\n",
        "            pred = m.get(\"valuation_k\") or m.get(\"valuation_base_k\") or m.get(\"valuation\") or payload.get(\"prediction\")\n",
        "            ci_low = m.get(\"confidence_low_k\") or payload.get(\"confidence_low_k\")\n",
        "            ci_high = m.get(\"confidence_high_k\") or payload.get(\"confidence_high_k\")\n",
        "            unc = m.get(\"uncertainty_k\") or m.get(\"uncertainty\")\n",
        "            return pred, ci_low, ci_high, unc\n",
        "\n",
        "        api_pred, api_low, api_high, api_unc = _pick_pred_metrics(api_json)\n",
        "\n",
        "        if api_pred is None:\n",
        "            print(\"❌ API OK but missing 'metrics.valuation_*' in response\")\n",
        "            print(json.dumps(api_json, indent=2)[:800])\n",
        "        else:\n",
        "            local_pred = float(single_output[\"metrics\"][\"valuation_k\"])\n",
        "            local_low  = float(single_output[\"metrics\"][\"confidence_low_k\"])\n",
        "            local_high = float(single_output[\"metrics\"][\"confidence_high_k\"])\n",
        "\n",
        "            delta = abs(float(api_pred) - local_pred)\n",
        "            pct = (delta / max(1e-9, abs(local_pred))) * 100.0\n",
        "\n",
        "            ci_overlap = None\n",
        "            if api_low is not None and api_high is not None:\n",
        "                try:\n",
        "                    ci_overlap = not (float(api_high) < local_low or float(api_low) > local_high)\n",
        "                except Exception:\n",
        "                    ci_overlap = None\n",
        "\n",
        "            print(\n",
        "                f\"✅ API Call Success in {latency_ms} ms | \"\n",
        "                f\"API={float(api_pred):.3f} k€ (unc={api_unc}) | \"\n",
        "                f\"LOCAL={local_pred:.3f} k€ | Δ={delta:.4f} ({pct:.2f}%) | \"\n",
        "                f\"CI overlap: {ci_overlap if ci_overlap is not None else 'n/a'}\"\n",
        "            )\n",
        "    else:\n",
        "        print(f\"❌ API Call Failed: {resp.status_code}\")\n",
        "        print(resp.text[:800])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Exception during API request: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-oracle",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
