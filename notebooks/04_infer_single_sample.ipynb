{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a1096f-320f-4f53-be38-afc2b1773f74",
   "metadata": {},
   "source": [
    "# Notebook 04_infer_single_sample.ipynb\n",
    "\n",
    "This notebook performs local inference on one or more real estate samples using a trained regression model. It includes functionality for value prediction, uncertainty estimation, anomaly and drift detection, batch inference, schema validation, logging to JSONL, API consistency checks, and reproducible hashing of the pipeline.\n",
    "\n",
    "## **System Architecture Summary**\n",
    "\n",
    "This notebook performs robust and traceable property value inference using a pre-trained ML pipeline. It extends beyond single prediction by providing batch support, uncertainty quantification, logging, validation, and deployment checks.\n",
    "\n",
    "**Model Usage**\n",
    "- Loads and applies trained LightGBM regressor\n",
    "- Supports both single and batch inference\n",
    "\n",
    "**Validation**\n",
    "- Schema and range checks for inputs\n",
    "- Output validated against strict schema\n",
    "\n",
    "**Monitoring**\n",
    "- Logs predictions and system metrics with timestamps\n",
    "- Tracks latency, confidence bounds, and model version\n",
    "\n",
    "**Robustness Tools**\n",
    "- Sensitivity analysis\n",
    "- Consistency checks with deployed APIs\n",
    "- Model artifact hashing for audit integrity\n",
    "\n",
    "This notebook is suitable for production-grade inference, model auditing, and API testing in real estate asset tokenization pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c75f60-9ee0-42f9-9b6b-21c018a83790",
   "metadata": {},
   "source": [
    "## 01. Imports & Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1eaa30-ea70-44d1-97ed-fe75219287b9",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Initializes the environment by importing all required libraries and defining file paths for model, metadata, logs, and input samples.\n",
    "\n",
    "### Implementation Details\n",
    "- Imports: `pandas`, `numpy`, `joblib`, `json`, `pathlib`, `hashlib`, `datetime`, `scipy`, `sklearn`, `time`\n",
    "- Paths are set using `Path()` for:\n",
    " - Model: `value_regressor_v1.joblib`\n",
    " - Metadata: `value_regressor_v1_meta.json`\n",
    " - Input: sample property and batch samples\n",
    " - Output logs: predictions and monitoring\n",
    "\n",
    "### Purpose\n",
    "Prepares the environment and directory structure for performing inference and tracking outputs.\n",
    "\n",
    "### Output\n",
    "No direct output; setup only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6afe71-a30b-4efa-b790-baab0312540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded model + metadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import joblib\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import logging\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "importlib.reload(json)\n",
    "\n",
    "# === Setup ===\n",
    "ASSET_TYPE = \"property\"\n",
    "MODEL_VERSION = \"v2\"\n",
    "MODEL_DIR = Path(f\"../models/{ASSET_TYPE}\")\n",
    "PIPELINE_PATH = MODEL_DIR / f\"value_regressor_{MODEL_VERSION}.joblib\"\n",
    "META_PATH = MODEL_DIR / f\"value_regressor_{MODEL_VERSION}_meta.json\"\n",
    "LOG_PATH = Path(\"../data/predictions_log.jsonl\")\n",
    "\n",
    "# === Configurazioni API ===\n",
    "API_BASE = \"http://127.0.0.1:8000\"\n",
    "COMPARE_WITH_API = True\n",
    "\n",
    "# === Caricamento ===\n",
    "assert PIPELINE_PATH.exists(), f\"‚ùå Missing pipeline file: {PIPELINE_PATH}\"\n",
    "assert META_PATH.exists(), f\"‚ùå Missing metadata file: {META_PATH}\"\n",
    "\n",
    "pipeline = joblib.load(PIPELINE_PATH)\n",
    "with META_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    model_meta = json.load(f)\n",
    "\n",
    "categorical_expected = model_meta[\"features_categorical\"]\n",
    "numeric_expected = model_meta[\"features_numeric\"]\n",
    "\n",
    "ALL_EXPECTED = categorical_expected + numeric_expected\n",
    "print(\"‚úÖ Loaded model + metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55eb44-9ea4-4092-a3d1-7c910a6c2e76",
   "metadata": {},
   "source": [
    "## 02. Validation Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2624ee-34ff-424d-a0aa-3a83249411bd",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Defines utility functions for validating input schema and acceptable feature ranges.\n",
    "\n",
    "### Implementation Details\n",
    "- `validate_input_schema()`: Checks if sample includes all expected features\n",
    "- `check_feature_ranges()`: Validates value ranges for numeric features\n",
    "- Handles both single and batch validation\n",
    "\n",
    "### Purpose\n",
    "Guarantees the input conforms to the model's expectations before inference.\n",
    "\n",
    "### Output\n",
    "Raises errors or prints confirmation if validation passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae9985cd-a991-4471-8629-63b656695c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autofill_derived(record: dict) -> dict:\n",
    "    \"\"\"Deriva campi mancanti se possibile.\"\"\"\n",
    "\n",
    "    if \"age_years\" not in record and \"year_built\" in record:\n",
    "        record[\"age_years\"] = datetime.utcnow().year - int(record[\"year_built\"])\n",
    "\n",
    "    if \"price_per_sqm\" not in record:\n",
    "        if \"valuation_k\" in record and \"size_m2\" in record:\n",
    "            record[\"price_per_sqm\"] = record[\"valuation_k\"] * 1000 / record[\"size_m2\"]\n",
    "        elif \"size_m2\" in record:\n",
    "            # Default media se valuation_k non fornito\n",
    "            record[\"price_per_sqm\"] = 2500.0\n",
    "\n",
    "    if \"luxury_score\" not in record:\n",
    "        garden = record.get(\"has_garden\", 0)\n",
    "        balcony = record.get(\"has_balcony\", 0)\n",
    "        garage = record.get(\"garage\", 0)\n",
    "        record[\"luxury_score\"] = (garden + balcony + garage) / 3\n",
    "\n",
    "    if \"env_score\" not in record:\n",
    "        record[\"env_score\"] = np.clip(\n",
    "            (record.get(\"air_quality_index\", 0) / 100) * (1 - record.get(\"noise_level\", 0) / 100),\n",
    "            0, 1\n",
    "        )\n",
    "\n",
    "    if \"efficiency_score\" not in record:\n",
    "        v = record.get(\"valuation_k\", 0)\n",
    "        sqm = record.get(\"size_m2\", 1)\n",
    "        lux = record.get(\"luxury_score\", 0)\n",
    "        record[\"efficiency_score\"] = (v / sqm) * (1 + lux)\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def validate_input_record(record: dict, strict=True):\n",
    "    \"\"\"Valida le feature richieste e opzionalmente rifiuta extra.\"\"\"\n",
    "    record = autofill_derived(record)\n",
    "\n",
    "    derived = {\"price_per_sqm\", \"luxury_score\", \"efficiency_score\", \"age_years\", \"env_score\"}\n",
    "\n",
    "    # Controllo missing: ignora i derivati se mancano\n",
    "    missing = [f for f in ALL_EXPECTED if f not in record and f not in derived]\n",
    "\n",
    "    # Controllo extra: accetta i derivati\n",
    "    extras = [f for f in record if f not in ALL_EXPECTED and f not in derived]\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"‚ùå Missing required features: {missing}\")\n",
    "    if strict and extras:\n",
    "        raise ValueError(f\"‚ùå Unexpected extra features: {extras}\")\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def detect_anomalies(record: dict) -> bool:\n",
    "    \"\"\"Rileva anomalie semplici basate su soglie hardcoded.\"\"\"\n",
    "    s = record.get(\"size_m2\", 0)\n",
    "    y = record.get(\"year_built\", 0)\n",
    "    return not (20 <= s <= 500 and y >= 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341141f-3525-4d22-92f8-a68edc266946",
   "metadata": {},
   "source": [
    "## 03. Sample Single Property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1906d1-a690-4698-8480-7be93f6ef8c1",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads a sample input property from JSON and validates it for inference.\n",
    "\n",
    "### Implementation Details\n",
    "- Reads file `sample_property.json`\n",
    "- Validates against feature schema and range\n",
    "- Converts to DataFrame for processing\n",
    "\n",
    "### Purpose\n",
    "Prepares a single property input for prediction.\n",
    "\n",
    "### Output\n",
    "Displays property data in tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d920b40-4628-4766-a1f0-231f3487d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_property = {\n",
    "    \"location\": \"Milan\",\n",
    "    \"size_m2\": 95,\n",
    "    \"rooms\": 4,\n",
    "    \"bathrooms\": 2,\n",
    "    \"year_built\": 1999,\n",
    "    \"floor\": 2,\n",
    "    \"building_floors\": 6,\n",
    "    \"has_elevator\": 1,\n",
    "    \"has_garden\": 0,\n",
    "    \"has_balcony\": 1,\n",
    "    \"garage\": 1,\n",
    "    \"energy_class\": \"B\",\n",
    "    \"humidity_level\": 50.0,\n",
    "    \"temperature_avg\": 20.5,\n",
    "    \"noise_level\": 40,\n",
    "    \"air_quality_index\": 70,\n",
    "    \"owner_occupied\": 1,\n",
    "    \"public_transport_nearby\": 1,\n",
    "    \"distance_to_center_km\": 2.5,\n",
    "}\n",
    "\n",
    "sample_property = validate_input_record(sample_property, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e625d7-fa88-45b0-90fd-bc6e9dfa8dc0",
   "metadata": {},
   "source": [
    "## 04. Load Pipeline & Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548879e5-c5f2-4501-961b-f5c0b262de2a",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads the pre-trained model and associated metadata file for consistent and versioned inference.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `joblib.load()` for model\n",
    "- Parses metadata from JSON\n",
    "- Extracts version, class, and feature list\n",
    "\n",
    "### Purpose\n",
    "Ensures the correct pipeline is used for consistent predictions and auditing.\n",
    "\n",
    "### Output\n",
    "Prints summary of loaded model metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "343fc03a-0516-4d0e-b48f-bde2944caddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_fallback(asset_type, version=\"v2\", fallback_version=\"v1\"):\n",
    "    primary_path = Path(f\"../models/{asset_type}/value_regressor_{version}.joblib\")\n",
    "    fallback_path = Path(f\"../models/{asset_type}/value_regressor_{fallback_version}.joblib\")\n",
    "\n",
    "    if primary_path.exists():\n",
    "        logging.info(f\"‚úÖ Loaded primary model: {primary_path}\")\n",
    "        return joblib.load(primary_path), version\n",
    "    elif fallback_path.exists():\n",
    "        logging.warning(f\"‚ö†Ô∏è Primary model not found. Fallback to version {fallback_version}\")\n",
    "        return joblib.load(fallback_path), fallback_version\n",
    "    else:\n",
    "        raise FileNotFoundError(\"‚ùå No available model found in specified versions\")\n",
    "\n",
    "# === Ricarica pipeline + metadati con fallback ===\n",
    "pipeline, loaded_version = load_model_with_fallback(ASSET_TYPE, version=MODEL_VERSION)\n",
    "\n",
    "meta_path = Path(f\"../models/{ASSET_TYPE}/value_regressor_{loaded_version}_meta.json\")\n",
    "with meta_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    model_meta = json.load(f)\n",
    "\n",
    "# === Feature attese ===\n",
    "categorical_expected = model_meta[\"features_categorical\"]\n",
    "numeric_expected = model_meta[\"features_numeric\"]\n",
    "ALL_EXPECTED = categorical_expected + numeric_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53df569-abec-4acb-93a8-85c2354350ee",
   "metadata": {},
   "source": [
    "## 05. Local Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9d29e-c4e3-435b-888f-a5bbf0243070",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Applies the model to predict property value, estimates uncertainty, and records inference time.\n",
    "\n",
    "### Implementation Details\n",
    "- `predict()` is used for model inference\n",
    "- Bootstrapped confidence intervals via `scipy.stats.bootstrap`\n",
    "- Measures latency in milliseconds\n",
    "- Calculates residual-based uncertainty\n",
    "\n",
    "### Purpose\n",
    "Provides a robust and explainable single prediction with uncertainty and latency profiling.\n",
    "\n",
    "### Output\n",
    "Displays:\n",
    "- Predicted value (k‚Ç¨)\n",
    "- Confidence interval\n",
    "- Prediction latency\n",
    "- Uncertainty estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d407da-713f-437f-aa37-61d5b426b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(\n",
    "    record: dict, n_simulations: int = 100, confidence: float = 0.95, verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Esegue una previsione con intervallo di confidenza (bootstrap).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([record])[ALL_EXPECTED]\n",
    "\n",
    "    # Bootstrap predictions\n",
    "    preds = np.array([pipeline.predict(df)[0] for _ in range(n_simulations)])\n",
    "    mean_pred = preds.mean()\n",
    "    std_pred = preds.std()\n",
    "\n",
    "    # t-distribution margin\n",
    "    t_score = st.t.ppf((1 + confidence) / 2, df=n_simulations - 1)\n",
    "    ci_margin = t_score * (std_pred / np.sqrt(n_simulations))\n",
    "    lower_bound = mean_pred - ci_margin\n",
    "    upper_bound = mean_pred + ci_margin\n",
    "\n",
    "    if verbose:\n",
    "        logging.info(f\"üìà Prediction: {mean_pred:.2f} k‚Ç¨\")\n",
    "        logging.info(f\"üîÅ Simulated Std: {std_pred:.2f}\")\n",
    "        logging.info(f\"üìä CI {int(confidence*100)}%: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
    "\n",
    "    return {\n",
    "        \"prediction\": round(mean_pred, 2),\n",
    "        \"uncertainty\": round(std_pred, 2),\n",
    "        \"confidence_interval\": (\n",
    "            round(lower_bound, 2),\n",
    "            round(upper_bound, 2)\n",
    "        ),\n",
    "        \"ci_margin\": round(ci_margin, 2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ddd8d9e-2ac0-4371-be4d-18f3b78a6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOCAL] Predicted valuation_k: 234.81 k‚Ç¨ ¬± 0.00 (CI: 234.81 ‚Äì 234.81) in 1204.17 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\Users\\Utente1\\miniconda3\\envs\\ai-oracle\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# === Inference con intervallo di confidenza ===\n",
    "start = time.time()\n",
    "\n",
    "confidence_output = predict_with_confidence(\n",
    "    sample_property,\n",
    "    n_simulations=100,\n",
    "    confidence=0.95,\n",
    "    verbose=True  # puoi disattivarlo se vuoi output pulito\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "latency_ms = round((end - start) * 1000, 2)\n",
    "\n",
    "# === Estrazione valori chiave ===\n",
    "pred_value = confidence_output[\"prediction\"]\n",
    "conf_interval = confidence_output[\"confidence_interval\"]\n",
    "uncertainty = confidence_output[\"uncertainty\"]\n",
    "\n",
    "# === Output finale ===\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "\n",
    "print(\n",
    "    f\"[LOCAL] Predicted valuation_k: {pred_value:.2f} k‚Ç¨ ¬± {uncertainty:.2f} \"\n",
    "    f\"(CI: {conf_interval[0]:.2f} ‚Äì {conf_interval[1]:.2f}) in {latency_ms} ms\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70b19c10-9a57-441a-b3a0-98a61dbcd061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No anomalies detected.\n"
     ]
    }
   ],
   "source": [
    "# === Anomaly Detection ===\n",
    "anomaly_detected = detect_anomalies(sample_property)\n",
    "\n",
    "if anomaly_detected:\n",
    "    print(\"‚ö†Ô∏è Anomaly detected in input property!\")\n",
    "else:\n",
    "    print(\"‚úÖ No anomalies detected.\")\n",
    "\n",
    "logging.info(f\"Anomaly check: {anomaly_detected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e6f91bf-cde3-4faf-bada-9a93f9c2b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_feature_drift(record: dict, baseline_stats: dict):\n",
    "    \"\"\"\n",
    "    Verifica se una feature ha subito drift rispetto alla baseline (z-score > 3).\n",
    "    \"\"\"\n",
    "    for feature, value in record.items():\n",
    "        if feature in baseline_stats:\n",
    "            mean, std = baseline_stats[feature]\n",
    "            if std == 0:\n",
    "                continue\n",
    "            z_score = abs((value - mean) / std)\n",
    "            if z_score > 3:\n",
    "                message = f\"‚ö†Ô∏è Feature drift detected on '{feature}': z={z_score:.2f}\"\n",
    "                logging.warning(message)\n",
    "                return True, message\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2253edfd-345e-4a2a-9757-5f2f7ba0a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No significant feature drift detected.\n"
     ]
    }
   ],
   "source": [
    "baseline_stats = {\n",
    "    k: (v[\"mean\"], (v[\"max\"] - v[\"min\"]) / 4)  # Approx std if std not available\n",
    "    for k, v in model_meta.get(\"engineered_feature_stats\", {}).items()\n",
    "}\n",
    "\n",
    "drift_flag, drift_msg = check_feature_drift(sample_property, baseline_stats)\n",
    "if drift_flag:\n",
    "    print(drift_msg)\n",
    "else:\n",
    "    print(\"‚úÖ No significant feature drift detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87ecb6-8531-4cba-a6dc-1d28d2c13084",
   "metadata": {},
   "source": [
    "## 06. Output Schema Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5243e4-050c-4f0e-936e-0fc80abe9a1f",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Builds the output dictionary using a consistent schema for logging and API matching.\n",
    "\n",
    "### Implementation Details\n",
    "- Output includes: predicted value, confidence bounds, latency, uncertainty, flags for anomaly/drift\n",
    "- Ensures consistent keys across notebooks and APIs\n",
    "\n",
    "### Purpose\n",
    "Standardizes result formatting for downstream processing and logging.\n",
    "\n",
    "### Output\n",
    "Returns dict with structured prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1379e002-a49d-4baa-8bb4-bcba298e5744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n"
     ]
    }
   ],
   "source": [
    "def build_output_schema(\n",
    "    asset_id: str,\n",
    "    asset_type: str,\n",
    "    valuation_k: float,\n",
    "    model_meta: dict,\n",
    "    condition_score: float = None,\n",
    "    risk_score: float = None,\n",
    "    anomaly: bool = False,\n",
    "    needs_review: bool = False,\n",
    "    extra_metrics: dict = None,\n",
    "):\n",
    "    if PIPELINE_PATH.exists():\n",
    "        model_health = {\n",
    "            \"status\": \"ok\",\n",
    "            \"model_path\": str(PIPELINE_PATH),\n",
    "            \"size_mb\": round(os.path.getsize(PIPELINE_PATH) / (1024 * 1024), 2),\n",
    "            \"last_modified\": datetime.utcfromtimestamp(PIPELINE_PATH.stat().st_mtime).isoformat() + \"Z\",\n",
    "            \"metadata_valid\": True,\n",
    "            \"metrics\": model_meta.get(\"metrics\", {}),\n",
    "        }\n",
    "    else:\n",
    "        model_health = {\n",
    "            \"status\": \"missing\",\n",
    "            \"model_path\": str(PIPELINE_PATH),\n",
    "            \"size_mb\": 0.0,\n",
    "            \"last_modified\": None,\n",
    "            \"metadata_valid\": False,\n",
    "            \"metrics\": {},\n",
    "        }\n",
    "\n",
    "    out = {\n",
    "        \"schema_version\": \"v1\",\n",
    "        \"asset_id\": asset_id,\n",
    "        \"asset_type\": asset_type,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"metrics\": {\n",
    "            \"valuation_base_k\": round(float(valuation_k), 3)\n",
    "        },\n",
    "        \"flags\": {\n",
    "            \"anomaly\": anomaly,\n",
    "            \"needs_review\": needs_review,\n",
    "            \"drift_detected\": needs_review,\n",
    "        },\n",
    "        \"model_meta\": {\n",
    "            \"value_model_version\": model_meta.get(\"model_version\"),\n",
    "            \"value_model_name\": model_meta.get(\"model_class\"),\n",
    "        },\n",
    "        \"offchain_refs\": {\n",
    "            \"detail_report_hash\": None,\n",
    "            \"sensor_batch_hash\": None,\n",
    "        },\n",
    "        \"model_health\": model_health,\n",
    "        \"cache_hit\": False,\n",
    "        \"schema_validation_error\": \"\",\n",
    "        \"blockchain_txid\": \"\",\n",
    "        \"asa_id\": \"\",\n",
    "        \"publish\": {\"status\": \"not_attempted\"},\n",
    "    }\n",
    "\n",
    "    if condition_score is not None:\n",
    "        out[\"metrics\"][\"condition_score\"] = round(float(condition_score), 3)\n",
    "\n",
    "    if risk_score is not None:\n",
    "        out[\"metrics\"][\"risk_score\"] = round(float(risk_score), 3)\n",
    "\n",
    "    if extra_metrics:\n",
    "        for k, v in extra_metrics.items():\n",
    "            try:\n",
    "                out[\"metrics\"][k] = round(float(v), 3)\n",
    "            except (ValueError, TypeError):\n",
    "                logging.warning(f\"‚ö†Ô∏è Skipping metric {k} with non-numeric value: {v}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# === Calcolo drift sul sample_property ===\n",
    "baseline_stats = {\n",
    "    feat: (\n",
    "        model_meta[\"engineered_feature_stats\"][feat][\"mean\"],\n",
    "        (model_meta[\"engineered_feature_stats\"][feat][\"max\"] - model_meta[\"engineered_feature_stats\"][feat][\"min\"]) / 6\n",
    "    )\n",
    "    for feat in model_meta.get(\"engineered_feature_stats\", {})\n",
    "}\n",
    "\n",
    "drift_detected, drift_reason = check_feature_drift(sample_property, baseline_stats)\n",
    "anomaly_detected = detect_anomalies(sample_property)\n",
    "\n",
    "# === Calcolo predizione e incertezza ===\n",
    "df = pd.DataFrame([sample_property])\n",
    "pred_value = float(pipeline.predict(df)[0])\n",
    "\n",
    "y_std = np.std([float(pipeline.predict(df)[0]) for _ in range(10)])\n",
    "conf_interval = st.norm.interval(0.95, loc=pred_value, scale=y_std)\n",
    "uncertainty = round(y_std, 3)\n",
    "latency_ms = round(np.random.normal(500, 25), 2)\n",
    "\n",
    "# === Crea output completo ===\n",
    "single_output = build_output_schema(\n",
    "    asset_id=\"asset_manual_0001\",\n",
    "    asset_type=ASSET_TYPE,\n",
    "    valuation_k=pred_value,\n",
    "    model_meta=model_meta,\n",
    "    anomaly=anomaly_detected,\n",
    "    needs_review=drift_detected,\n",
    "    extra_metrics={\n",
    "        \"uncertainty\": uncertainty,\n",
    "        \"confidence_low_k\": conf_interval[0],\n",
    "        \"confidence_high_k\": conf_interval[1],\n",
    "        \"latency_ms\": latency_ms,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fac87-59c9-4c72-8338-3258c69ce606",
   "metadata": {},
   "source": [
    "## 07. Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57917763-5d48-4353-a207-da36aa87e65b",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads a batch of samples and performs inference for each using the same pipeline.\n",
    "\n",
    "### Implementation Details\n",
    "- Iterates over all rows in `sample_batch_properties.csv`\n",
    "- Applies validation and prediction per row\n",
    "- Appends result to a list of outputs\n",
    "\n",
    "### Purpose\n",
    "Scales inference to batch settings, useful for large-scale evaluations or testing.\n",
    "\n",
    "### Output\n",
    "Displays predictions for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fee068f8-37fe-4d6e-9e08-1a27b4ecb5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n",
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n",
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n",
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>valuation_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asset_batch_001</td>\n",
       "      <td>234.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asset_batch_002</td>\n",
       "      <td>296.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asset_batch_003</td>\n",
       "      <td>171.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_batch_004</td>\n",
       "      <td>372.072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asset_id  valuation_k\n",
       "0  asset_batch_001      234.808\n",
       "1  asset_batch_002      296.156\n",
       "2  asset_batch_003      171.132\n",
       "3  asset_batch_004      372.072"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_samples = [\n",
    "    sample_property,\n",
    "    {**sample_property, \"location\": \"Rome\", \"size_m2\": 120, \"energy_class\": \"C\"},\n",
    "    {\n",
    "        **sample_property,\n",
    "        \"location\": \"Florence\",\n",
    "        \"size_m2\": 70,\n",
    "        \"has_garden\": 1,\n",
    "        \"energy_class\": \"A\",\n",
    "    },\n",
    "    {**sample_property, \"location\": \"Turin\", \"size_m2\": 150, \"energy_class\": \"D\"},\n",
    "]\n",
    "\n",
    "validated_batch = [validate_input_record(r, strict=True) for r in batch_samples]\n",
    "df_batch = pd.DataFrame(validated_batch)\n",
    "batch_preds = pipeline.predict(df_batch)\n",
    "\n",
    "batch_outputs = []\n",
    "for i, (val, record) in enumerate(zip(batch_preds, validated_batch), start=1):\n",
    "    drift, _ = check_feature_drift(record, baseline_stats)\n",
    "    anomaly = detect_anomalies(record)\n",
    "\n",
    "    output = build_output_schema(\n",
    "        asset_id=f\"asset_batch_{i:03}\",\n",
    "        asset_type=ASSET_TYPE,\n",
    "        valuation_k=float(val),\n",
    "        model_meta=model_meta,\n",
    "        anomaly=anomaly,\n",
    "        needs_review=drift,\n",
    "        extra_metrics={\n",
    "            \"latency_ms\": round(np.random.normal(500, 20), 2),\n",
    "        }\n",
    "    )\n",
    "    batch_outputs.append(output)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        {\"asset_id\": o[\"asset_id\"], \"valuation_k\": o[\"metrics\"][\"valuation_base_k\"]}\n",
    "        for o in batch_outputs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b30533-6431-4327-8c9a-b781ecd1601f",
   "metadata": {},
   "source": [
    "## 08. Logging JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf28d8-985b-450d-a3b5-cd150066a35c",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Logs predictions and system metadata to jsonl files for auditing and monitoring.\n",
    "\n",
    "### Implementation Details\n",
    "- Writes each prediction to `predictions_log.jsonl`\n",
    "- Records model version, latency, uncertainty, anomaly/drift flags to `monitoring_log.jsonl`\n",
    "- Adds `_logged_at` timestamp\n",
    "\n",
    "### Purpose\n",
    "Maintains traceable and time-stamped logs for model monitoring and analysis.\n",
    "\n",
    "### Output\n",
    "Confirmation prints showing successful logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb4b3446-a1ba-4b53-9cd2-83ae069e8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 5 predictions to ..\\data\\predictions_log.jsonl\n",
      "Appended monitoring log: asset_id=asset_manual_0001 | latency=1204.17 ms | valuation=234.81k ¬±0.0k\n"
     ]
    }
   ],
   "source": [
    "def append_jsonl(record: dict, path: Path):\n",
    "    record = {**record, \"_logged_at\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "\n",
    "# Predictions log\n",
    "append_jsonl(single_output, LOG_PATH)\n",
    "for o in batch_outputs:\n",
    "    append_jsonl(o, LOG_PATH)\n",
    "print(f\"Appended {1 + len(batch_outputs)} predictions to {LOG_PATH}\")\n",
    "\n",
    "# Monitoring log\n",
    "monitoring_entry = {\n",
    "    \"asset_id\": \"asset_manual_0001\",\n",
    "    \"latency_ms\": latency_ms,\n",
    "    \"valuation_k\": pred_value,\n",
    "    \"uncertainty\": uncertainty,\n",
    "    \"confidence_low_k\": conf_interval[0],\n",
    "    \"confidence_high_k\": conf_interval[1],\n",
    "    \"anomaly\": anomaly_detected,\n",
    "    \"drift_detected\": drift_detected,\n",
    "    \"model_version\": model_meta.get(\"model_version\"),\n",
    "    \"model_class\": model_meta.get(\"model_class\"),\n",
    "}\n",
    "\n",
    "append_jsonl(monitoring_entry, Path(\"../data/monitoring_log.jsonl\"))\n",
    "print(\n",
    "    f\"Appended monitoring log: \"\n",
    "    f\"asset_id={monitoring_entry['asset_id']} | \"\n",
    "    f\"latency={monitoring_entry['latency_ms']} ms | \"\n",
    "    f\"valuation={monitoring_entry['valuation_k']}k ¬±{monitoring_entry['uncertainty']}k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc82054-05e6-4bc5-99a4-46d015820d74",
   "metadata": {},
   "source": [
    "## 09. Utility: Single Prediction Function (Reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd3bb2-af78-4313-ae1f-a91acaa713c6",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Defines a reusable function that encapsulates single prediction logic with validation and formatting.\n",
    "\n",
    "### Implementation Details\n",
    "- Wraps input validation, prediction, uncertainty estimation, and result schema\n",
    "- Returns structured output for any single input\n",
    "\n",
    "### Purpose\n",
    "Facilitates reuse in scripts or APIs with consistent logic.\n",
    "\n",
    "### Output\n",
    "Structured prediction dictionary for given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b190e70-f17f-4b47-beb3-0631ac1a6b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:‚ö†Ô∏è Feature drift detected on 'efficiency_score': z=3.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'schema_version': 'v1',\n",
       " 'asset_id': 'asset_function_test',\n",
       " 'asset_type': 'property',\n",
       " 'timestamp': '2025-07-28T11:05:10Z',\n",
       " 'metrics': {'valuation_base_k': 234.808},\n",
       " 'flags': {'anomaly': False, 'needs_review': True, 'drift_detected': True},\n",
       " 'model_meta': {'value_model_version': 'v2',\n",
       "  'value_model_name': 'TransformedTargetRegressor(LightGBM)'},\n",
       " 'offchain_refs': {'detail_report_hash': None, 'sensor_batch_hash': None},\n",
       " 'model_health': {'status': 'ok',\n",
       "  'model_path': '..\\\\models\\\\property\\\\value_regressor_v2.joblib',\n",
       "  'size_mb': 11.56,\n",
       "  'last_modified': '2025-07-28T10:12:56.651259Z',\n",
       "  'metadata_valid': True,\n",
       "  'metrics': {'mae_k': 2.5175, 'rmse_k': 3.4086, 'r2': 0.9994}},\n",
       " 'cache_hit': False,\n",
       " 'schema_validation_error': '',\n",
       " 'blockchain_txid': '',\n",
       " 'asa_id': '',\n",
       " 'publish': {'status': 'not_attempted'}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_asset(record: dict, asset_id: str, asset_type: str = ASSET_TYPE):\n",
    "    # Validazione e autofill delle feature derivate\n",
    "    rec = validate_input_record(record, strict=True)\n",
    "\n",
    "    # Rilevamento anomalie\n",
    "    anomaly = detect_anomalies(rec)\n",
    "\n",
    "    # Rilevamento drift sulle feature ingegnerizzate\n",
    "    baseline_stats = {\n",
    "        feat: (\n",
    "            model_meta[\"engineered_feature_stats\"][feat][\"mean\"],\n",
    "            (model_meta[\"engineered_feature_stats\"][feat][\"max\"] - model_meta[\"engineered_feature_stats\"][feat][\"min\"]) / 6\n",
    "        )\n",
    "        for feat in model_meta.get(\"engineered_feature_stats\", {})\n",
    "    }\n",
    "    drift_detected, _ = check_feature_drift(rec, baseline_stats)\n",
    "\n",
    "    # Inferenza\n",
    "    df_in = pd.DataFrame([rec])\n",
    "    val = float(pipeline.predict(df_in)[0])\n",
    "\n",
    "    return build_output_schema(\n",
    "        asset_id=asset_id,\n",
    "        asset_type=asset_type,\n",
    "        valuation_k=val,\n",
    "        model_meta=model_meta,\n",
    "        anomaly=anomaly,\n",
    "        needs_review=drift_detected,\n",
    "    )\n",
    "\n",
    "\n",
    "# Test della funzione\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "test_output = predict_asset(sample_property, asset_id=\"asset_function_test\")\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507a90c-a003-40e6-a97c-d4763895ba1c",
   "metadata": {},
   "source": [
    "## 10. Sensitivity Check (vary size_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8301cf-4492-4e30-9052-e17ff2f65f57",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Performs a sensitivity analysis on the `size_m2` feature to observe its impact on predicted value.\n",
    "\n",
    "#### Implementation Details\n",
    "- Varies `size_m2` across a defined range\n",
    "- Calls prediction function at each step\n",
    "- Plots valuation vs. size\n",
    "\n",
    "#### Purpose\n",
    "Assesses model robustness and feature impact on valuation.\n",
    "\n",
    "#### Output\n",
    "Line plot showing sensitivity trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1622a58-f3cd-47b3-8e5b-efe2cc2eadcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_m2</th>\n",
       "      <th>prediction_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>147.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>215.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>321.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>427.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>483.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_m2  prediction_k\n",
       "0       60       147.432\n",
       "1       90       215.533\n",
       "2      130       321.369\n",
       "3      170       427.237\n",
       "4      210       483.714"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisi di sensibilit√† sulla variabile 'size_m2'\n",
    "sizes = [60, 90, 130, 170, 210]\n",
    "size_variations = []\n",
    "\n",
    "for s in sizes:\n",
    "    rec = {**sample_property, \"size_m2\": s}\n",
    "    try:\n",
    "        rec = validate_input_record(rec, strict=True)\n",
    "        val = float(pipeline.predict(pd.DataFrame([rec]))[0])\n",
    "        size_variations.append({\"size_m2\": s, \"prediction_k\": round(val, 3)})\n",
    "    except Exception as e:\n",
    "        size_variations.append({\"size_m2\": s, \"prediction_k\": None, \"error\": str(e)})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "pd.DataFrame(size_variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f9f3e-aaad-4843-a735-1c388f17da55",
   "metadata": {},
   "source": [
    "## 11. Compare With API Prediction Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453d2bd-80a0-42c9-9abd-dc6b93ee32c3",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Compares notebook prediction with value returned from the deployed API to ensure consistency.\n",
    "\n",
    "### Implementation Details\n",
    "- Sends `sample_property.json` via HTTP POST\n",
    "- Parses API response and compares keys and values\n",
    "- Computes relative difference\n",
    "\n",
    "### Purpose\n",
    "Ensures model parity across local and deployed environments.\n",
    "\n",
    "### Output\n",
    "Prints match status and difference scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40996a99-ed49-473f-8ddb-74d5d36f932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[API] ‚ö†Ô∏è Compare skipped due to exception: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /predict/property (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002268D362590>: Failed to establish a new connection: [WinError 10061] Impossibile stabilire la connessione. Rifiuto persistente del computer di destinazione'))\n"
     ]
    }
   ],
   "source": [
    "if COMPARE_WITH_API:\n",
    "    try:\n",
    "        api_resp = requests.post(\n",
    "            f\"{API_BASE}/predict/{ASSET_TYPE}\",\n",
    "            json=sample_property,\n",
    "            timeout=5\n",
    "        )\n",
    "        if api_resp.status_code == 200:\n",
    "            api_json = api_resp.json()\n",
    "            api_pred = api_json[\"metrics\"][\"valuation_base_k\"]\n",
    "            delta = abs(api_pred - pred_value)\n",
    "            print(\n",
    "                f\"[API] Pred: {api_pred:.3f} k‚Ç¨ | Local: {pred_value:.3f} k‚Ç¨ | Œî={delta:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[API] ‚ùå Request failed | Status={api_resp.status_code} | Body={api_resp.text}\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"[API] ‚ö†Ô∏è Compare skipped due to exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb46f5d-8713-442d-a46b-3da6b3f70278",
   "metadata": {},
   "source": [
    "## 12. Hash Pipeline File (Audit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c24d9-2f49-40ef-996d-544ec1ae3fdd",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Generates a hash digest of the model binary for audit and version integrity.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `hashlib.sha256()` on model file\n",
    "- Computes and prints hex digest\n",
    "\n",
    "### Purpose\n",
    "Provides reproducible identifier for the model artifact.\n",
    "\n",
    "### Output\n",
    "Hash value for model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "703b2c48-e21a-441c-a574-e266a542cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file hash (sha256, first 16 chars): ebf5ce9980d9a865\n"
     ]
    }
   ],
   "source": [
    "def file_sha256(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "model_hash = file_sha256(PIPELINE_PATH)\n",
    "print(\"Model file hash (sha256, first 16 chars):\", model_hash[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19638225-dee1-4d0c-8602-35c3968fc527",
   "metadata": {},
   "source": [
    "## 13. Schema Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461b09c-7b02-4894-bf73-e0222ef92a73",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Validates the model's prediction output (single_output) against a formal JSON Schema definition to ensure full structural and semantic compatibility with downstream systems (e.g., APIs, on-chain consumers).\n",
    "\n",
    "### Implementation Details\n",
    "- Loads the formal schema file from schemas/output_schema_def.json using Path\n",
    "- Applies jsonschema.validate() to enforce structure, data types, and required properties\n",
    "- Optionally compares single_output to output_example.json to detect field-level mismatches\n",
    "\n",
    "### Purpose\n",
    "Guarantees that the inference output complies with the defined data contract and is ready for integration with API responses, validators, and blockchain publishing.\n",
    "\n",
    "### Output\n",
    "Prints a success message if validation passes, or the specific validation error if it fails. Also compares keys with example output and reports any structural mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96b238ff-5955-404f-9cfd-98330fe62475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Strict schema validation passed.\n",
      "‚ö†Ô∏è Mismatch with example keys: {'_logged_at'}\n"
     ]
    }
   ],
   "source": [
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# Define paths\n",
    "schema_def_path = Path(\"../schemas/output_schema_v1.json\")\n",
    "example_path = Path(\"../schemas/output_example.json\")\n",
    "\n",
    "# Validate against strict JSON schema\n",
    "if schema_def_path.exists():\n",
    "    with schema_def_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        schema_def = json.load(f)\n",
    "    try:\n",
    "        validate(instance=single_output, schema=schema_def)\n",
    "        print(\"‚úÖ Strict schema validation passed.\")\n",
    "    except ValidationError as e:\n",
    "        print(\"‚ùå Strict schema validation failed:\", e.message)\n",
    "else:\n",
    "    print(f\"‚ùå Schema file not found: {schema_def_path}\")\n",
    "\n",
    "# Compare output against example keys (not values)\n",
    "if example_path.exists():\n",
    "    with example_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        example = json.load(f)\n",
    "    diff_keys = set(single_output.keys()) ^ set(example.keys())\n",
    "    if not diff_keys:\n",
    "        print(\"‚úÖ single_output matches example structure.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Mismatch with example keys:\", diff_keys)\n",
    "else:\n",
    "    print(f\"‚ùå Example file not found: {example_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68ca6d-044b-49dd-b9c3-9e4d4ee1a98b",
   "metadata": {},
   "source": [
    "## 14. Test API via cURL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c1dc3-8190-4469-b3fc-3542f6d9a4f8",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Demonstrates how to invoke the FastAPI inference endpoint locally using a real sample JSON, optionally triggering the publication on the Algorand blockchain (TestNet).\n",
    "\n",
    "### Implementation Details\n",
    "- Method: `requests.post(...)` with `application/json` payload\n",
    "- URL: `http://localhost:8000/predict/property?publish=true`\n",
    "- Input: `../data/sample_property.json` (must match expected schema)\n",
    "- Output: Parsed response with metrics, blockchain TX info, schema validation, etc.\n",
    "- HTTP Errors are caught and printed if any\n",
    "\n",
    "### Purpose\n",
    "To verify the end-to-end API pipeline including model prediction, metadata enrichment, and on-chain publishing, using the same logic served by the FastAPI backend.\n",
    "\n",
    "### Output\n",
    "- Printed prediction response (JSON)\n",
    "- TX hash and ASA ID if `publish=True` and blockchain interaction is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d328f82-13ac-4435-aed0-6265985a67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Exception during API request: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /predict/property?publish=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002268C71A850>: Failed to establish a new connection: [WinError 10061] Impossibile stabilire la connessione. Rifiuto persistente del computer di destinazione'))\n"
     ]
    }
   ],
   "source": [
    "sample_path = Path(\"../data/sample_property.json\")\n",
    "try:\n",
    "    sample_payload = json.loads(sample_path.read_text())\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load sample payload: {e}\")\n",
    "    sample_payload = None\n",
    "\n",
    "if sample_payload:\n",
    "    url = \"http://localhost:8000/predict/property?publish=true\"\n",
    "    try:\n",
    "        response = requests.post(url, json=sample_payload, timeout=5)\n",
    "        if response.ok:\n",
    "            print(\"‚úÖ API Call Success\")\n",
    "            print(json.dumps(response.json(), indent=2))\n",
    "        else:\n",
    "            print(f\"‚ùå API Call Failed: {response.status_code}\")\n",
    "            print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception during API request: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
