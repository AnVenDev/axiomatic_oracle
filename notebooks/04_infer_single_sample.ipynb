{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a1096f-320f-4f53-be38-afc2b1773f74",
   "metadata": {},
   "source": [
    "# Notebook 04_infer_single_sample.ipynb\n",
    "\n",
    "This notebook performs local inference on one or more real estate samples using a trained regression model. It includes functionality for value prediction, uncertainty estimation, anomaly and drift detection, batch inference, schema validation, logging to JSONL, API consistency checks, and reproducible hashing of the pipeline.\n",
    "\n",
    "## **System Architecture Summary**\n",
    "\n",
    "This notebook performs robust and traceable property value inference using a pre-trained ML pipeline. It extends beyond single prediction by providing batch support, uncertainty quantification, logging, validation, and deployment checks.\n",
    "\n",
    "**Model Usage**\n",
    "- Loads and applies trained LightGBM regressor\n",
    "- Supports both single and batch inference\n",
    "\n",
    "**Validation**\n",
    "- Schema and range checks for inputs\n",
    "- Output validated against strict schema\n",
    "\n",
    "**Monitoring**\n",
    "- Logs predictions and system metrics with timestamps\n",
    "- Tracks latency, confidence bounds, and model version\n",
    "\n",
    "**Robustness Tools**\n",
    "- Sensitivity analysis\n",
    "- Consistency checks with deployed APIs\n",
    "- Model artifact hashing for audit integrity\n",
    "\n",
    "This notebook is suitable for production-grade inference, model auditing, and API testing in real estate asset tokenization pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c75f60-9ee0-42f9-9b6b-21c018a83790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 01. Imports & Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1eaa30-ea70-44d1-97ed-fe75219287b9",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Initializes the environment by importing all required libraries and defining file paths for model, metadata, logs, and input samples.\n",
    "\n",
    "### Implementation Details\n",
    "- Imports: `pandas`, `numpy`, `joblib`, `json`, `pathlib`, `hashlib`, `datetime`, `scipy`, `sklearn`, `time`\n",
    "- Paths are set using `Path()` for:\n",
    " - Model: `value_regressor_v1.joblib`\n",
    " - Metadata: `value_regressor_v1_meta.json`\n",
    " - Input: sample property and batch samples\n",
    " - Output logs: predictions and monitoring\n",
    "\n",
    "### Purpose\n",
    "Prepares the environment and directory structure for performing inference and tracking outputs.\n",
    "\n",
    "### Output\n",
    "No direct output; setup only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6afe71-a30b-4efa-b790-baab0312540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model + metadata paths OK.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "ASSET_TYPE = \"property\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "MODEL_DIR = Path(f\"../models/{ASSET_TYPE}\")\n",
    "PIPELINE_PATH = MODEL_DIR / f\"value_regressor_{MODEL_VERSION}.joblib\"\n",
    "META_PATH = MODEL_DIR / f\"value_regressor_{MODEL_VERSION}_meta.json\"\n",
    "LOG_PATH = Path(\"../data/predictions_log.jsonl\")\n",
    "API_BASE = \"http://127.0.0.1:8000\"  # endpoint FastAPI\n",
    "COMPARE_WITH_API = True  # False if not HTTP request\n",
    "\n",
    "assert PIPELINE_PATH.exists(), f\"Missing pipeline file: {PIPELINE_PATH}\"\n",
    "assert META_PATH.exists(), f\"Missing metadata file: {META_PATH}\"\n",
    "print(\"Loaded model + metadata paths OK.\")\n",
    "\n",
    "pipeline = joblib.load(PIPELINE_PATH)\n",
    "with META_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    model_meta = json.load(f)\n",
    "\n",
    "categorical_expected = model_meta[\"features_categorical\"]\n",
    "numeric_expected = model_meta[\"features_numeric\"]\n",
    "ALL_EXPECTED = categorical_expected + numeric_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55eb44-9ea4-4092-a3d1-7c910a6c2e76",
   "metadata": {},
   "source": [
    "## 02. Validation Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2624ee-34ff-424d-a0aa-3a83249411bd",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Defines utility functions for validating input schema and acceptable feature ranges.\n",
    "\n",
    "### Implementation Details\n",
    "- `validate_input_schema()`: Checks if sample includes all expected features\n",
    "- `check_feature_ranges()`: Validates value ranges for numeric features\n",
    "- Handles both single and batch validation\n",
    "\n",
    "### Purpose\n",
    "Guarantees the input conforms to the model's expectations before inference.\n",
    "\n",
    "### Output\n",
    "Raises errors or prints confirmation if validation passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9985cd-a991-4471-8629-63b656695c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autofill_derived(record: dict) -> dict:\n",
    "    \"\"\"If age_years missing but year_built present, derive it.\"\"\"\n",
    "    if \"age_years\" not in record and \"year_built\" in record:\n",
    "        record = {\n",
    "            **record,\n",
    "            \"age_years\": datetime.utcnow().year - int(record[\"year_built\"]),\n",
    "        }\n",
    "    return record\n",
    "\n",
    "\n",
    "def validate_input_record(record: dict, strict=True):\n",
    "    \"\"\"\n",
    "    Validates that all expected features are present.\n",
    "    If strict=True, rejects extra keys.\n",
    "    Auto-fills derived features if possible.\n",
    "    Raises ValueError on problems.\n",
    "    \"\"\"\n",
    "    record = autofill_derived(record)\n",
    "    missing = [f for f in ALL_EXPECTED if f not in record]\n",
    "    extras = [f for f in record if f not in ALL_EXPECTED]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required features: {missing}\")\n",
    "    if strict and extras:\n",
    "        raise ValueError(f\"Unexpected extra features: {extras}\")\n",
    "    return record\n",
    "\n",
    "\n",
    "ANOMALY_RULES = {\"size_m2\": {\"min\": 20, \"max\": 500}, \"year_built\": {\"min\": 1800}}\n",
    "\n",
    "\n",
    "def detect_anomalies(record: dict) -> bool:\n",
    "    if record.get(\"size_m2\", 0) < 20 or record.get(\"size_m2\", 0) > 500:\n",
    "        return True\n",
    "    if record.get(\"year_built\", 2000) < 1800:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341141f-3525-4d22-92f8-a68edc266946",
   "metadata": {},
   "source": [
    "## 03. Sample Single Property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1906d1-a690-4698-8480-7be93f6ef8c1",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads a sample input property from JSON and validates it for inference.\n",
    "\n",
    "### Implementation Details\n",
    "- Reads file `sample_property.json`\n",
    "- Validates against feature schema and range\n",
    "- Converts to DataFrame for processing\n",
    "\n",
    "### Purpose\n",
    "Prepares a single property input for prediction.\n",
    "\n",
    "### Output\n",
    "Displays property data in tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d920b40-4628-4766-a1f0-231f3487d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_property = {\n",
    "    \"location\": \"Milan\",\n",
    "    \"size_m2\": 95,\n",
    "    \"rooms\": 4,\n",
    "    \"bathrooms\": 2,\n",
    "    \"year_built\": 1999,\n",
    "    \"floor\": 2,\n",
    "    \"building_floors\": 6,\n",
    "    \"has_elevator\": 1,\n",
    "    \"has_garden\": 0,\n",
    "    \"has_balcony\": 1,\n",
    "    \"garage\": 1,\n",
    "    \"energy_class\": \"B\",\n",
    "    \"humidity_level\": 50.0,\n",
    "    \"temperature_avg\": 20.5,\n",
    "    \"noise_level\": 40,\n",
    "    \"air_quality_index\": 70,\n",
    "}\n",
    "\n",
    "sample_property = validate_input_record(sample_property, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e625d7-fa88-45b0-90fd-bc6e9dfa8dc0",
   "metadata": {},
   "source": [
    "## 02. Load Pipeline & Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548879e5-c5f2-4501-961b-f5c0b262de2a",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads the pre-trained model and associated metadata file for consistent and versioned inference.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `joblib.load()` for model\n",
    "- Parses metadata from JSON\n",
    "- Extracts version, class, and feature list\n",
    "\n",
    "### Purpose\n",
    "Ensures the correct pipeline is used for consistent predictions and auditing.\n",
    "\n",
    "### Output\n",
    "Prints summary of loaded model metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343fc03a-0516-4d0e-b48f-bde2944caddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected features (sum): 17\n",
      "Expected features: ['location', 'energy_class', 'has_elevator', 'has_garden', 'has_balcony', 'garage', 'size_m2', 'rooms', 'bathrooms', 'year_built', 'floor', 'building_floors', 'humidity_level', 'temperature_avg', 'noise_level', 'air_quality_index', 'age_years']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_property' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExpected features (sum):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ALL_EXPECTED))\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExpected features:\u001b[39m\u001b[33m\"\u001b[39m, ALL_EXPECTED)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSample property:\u001b[39m\u001b[33m\"\u001b[39m, sample_property)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_property' is not defined"
     ]
    }
   ],
   "source": [
    "def load_model_with_fallback(primary_version=\"v1\", fallback_version=\"v0\"):\n",
    "    try:\n",
    "        return joblib.load(\n",
    "            f\"../models/property/value_regressor_{primary_version}.joblib\"\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Primary model not found. Falling back to {fallback_version}\")\n",
    "        return joblib.load(\n",
    "            f\"../models/property/value_regressor_{fallback_version}.joblib\"\n",
    "        )\n",
    "\n",
    "\n",
    "pipeline = joblib.load(PIPELINE_PATH)\n",
    "with META_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    model_meta = json.load(f)\n",
    "\n",
    "categorical_expected = model_meta[\"features_categorical\"]\n",
    "numeric_expected = model_meta[\"features_numeric\"]\n",
    "ALL_EXPECTED = categorical_expected + numeric_expected\n",
    "\n",
    "print(\"Expected features (sum):\", len(ALL_EXPECTED))\n",
    "print(\"Expected features:\", ALL_EXPECTED)\n",
    "print(\"Sample property:\", sample_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53df569-abec-4acb-93a8-85c2354350ee",
   "metadata": {},
   "source": [
    "## 05. Local Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9d29e-c4e3-435b-888f-a5bbf0243070",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Applies the model to predict property value, estimates uncertainty, and records inference time.\n",
    "\n",
    "### Implementation Details\n",
    "- `predict()` is used for model inference\n",
    "- Bootstrapped confidence intervals via `scipy.stats.bootstrap`\n",
    "- Measures latency in milliseconds\n",
    "- Calculates residual-based uncertainty\n",
    "\n",
    "### Purpose\n",
    "Provides a robust and explainable single prediction with uncertainty and latency profiling.\n",
    "\n",
    "### Output\n",
    "Displays:\n",
    "- Predicted value (k€)\n",
    "- Confidence interval\n",
    "- Prediction latency\n",
    "- Uncertainty estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d3d407da-713f-437f-aa37-61d5b426b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(\n",
    "    record: dict, n_simulations: int = 100, confidence: float = 0.95\n",
    "):\n",
    "    df = pd.DataFrame([record])[ALL_EXPECTED]\n",
    "    preds = [pipeline.predict(df)[0] for _ in range(n_simulations)]\n",
    "    mean_pred = np.mean(preds)\n",
    "    std_pred = np.std(preds)\n",
    "\n",
    "    ci_margin = st.t.ppf((1 + confidence) / 2, df=n_simulations - 1) * (\n",
    "        std_pred / np.sqrt(n_simulations)\n",
    "    )\n",
    "    lower_bound = mean_pred - ci_margin\n",
    "    upper_bound = mean_pred + ci_margin\n",
    "\n",
    "    return {\n",
    "        \"prediction\": float(mean_pred),\n",
    "        \"confidence_interval\": (round(lower_bound, 2), round(upper_bound, 2)),\n",
    "        \"uncertainty\": round(std_pred, 2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ddd8d9e-2ac0-4371-be4d-18f3b78a6440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOCAL] Predicted valuation_k: 5.38 k€ ± 0.00 (CI: 5.38 – 5.38) in 641.45 ms\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "confidence_output = predict_with_confidence(\n",
    "    sample_property, n_simulations=100, confidence=0.95\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "pred_value = confidence_output[\"prediction\"]\n",
    "conf_interval = confidence_output[\"confidence_interval\"]\n",
    "uncertainty = confidence_output[\"uncertainty\"]\n",
    "latency_ms = round((end - start) * 1000, 2)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "print(\n",
    "    f\"[LOCAL] Predicted valuation_k: {pred_value:.2f} k€ ± {uncertainty:.2f} (CI: {conf_interval[0]:.2f} – {conf_interval[1]:.2f}) in {latency_ms} ms\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70b19c10-9a57-441a-b3a0-98a61dbcd061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No anomalies detected.\n"
     ]
    }
   ],
   "source": [
    "anomaly_detected = detect_anomalies(sample_property)\n",
    "if detect_anomalies(sample_property):\n",
    "    print(\"⚠️ Anomaly detected in input property!\")\n",
    "else:\n",
    "    print(\"✅ No anomalies detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e6f91bf-cde3-4faf-bada-9a93f9c2b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature drift\n",
    "def check_feature_drift(record: dict, baseline_stats: dict):\n",
    "    for feature, value in record.items():\n",
    "        if feature in baseline_stats:\n",
    "            mean, std = baseline_stats[feature]\n",
    "            if std == 0:\n",
    "                continue\n",
    "            z_score = abs((value - mean) / std)\n",
    "            if z_score > 3:\n",
    "                return True, f\"Feature {feature} drift detected\"\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2253edfd-345e-4a2a-9757-5f2f7ba0a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift: False | No significant drift\n"
     ]
    }
   ],
   "source": [
    "baseline_stats = model_meta.get(\"feature_stats\", {})\n",
    "drift_detected, drift_msg = check_feature_drift(sample_property, baseline_stats)\n",
    "print(f\"Drift: {drift_detected} | {drift_msg or 'No significant drift'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87ecb6-8531-4cba-a6dc-1d28d2c13084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 06. Output Schema Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5243e4-050c-4f0e-936e-0fc80abe9a1f",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Builds the output dictionary using a consistent schema for logging and API matching.\n",
    "\n",
    "### Implementation Details\n",
    "- Output includes: predicted value, confidence bounds, latency, uncertainty, flags for anomaly/drift\n",
    "- Ensures consistent keys across notebooks and APIs\n",
    "\n",
    "### Purpose\n",
    "Standardizes result formatting for downstream processing and logging.\n",
    "\n",
    "### Output\n",
    "Returns dict with structured prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "54f1349a-c432-448f-a598-612fa51e67a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asset_id': 'asset_manual_0001',\n",
       " 'asset_type': 'property',\n",
       " 'timestamp': '2025-07-22T18:49:56Z',\n",
       " 'metrics': {'valuation_base_k': 5.382,\n",
       "  'uncertainty': 0.0,\n",
       "  'confidence_low_k': 5.38,\n",
       "  'confidence_high_k': 5.38,\n",
       "  'latency_ms': 641.45},\n",
       " 'flags': {'anomaly': False, 'needs_review': False},\n",
       " 'model_meta': {'value_model_version': 'v1',\n",
       "  'value_model_name': 'LGBMRegressor'},\n",
       " 'offchain_refs': {'detail_report_hash': None, 'sensor_batch_hash': None}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_output_schema(\n",
    "    asset_id: str,\n",
    "    asset_type: str,\n",
    "    valuation_k: float,\n",
    "    model_meta: dict,\n",
    "    condition_score: float = None,\n",
    "    risk_score: float = None,\n",
    "    anomaly: bool = False,\n",
    "    needs_review: bool = False,\n",
    "    extra_metrics: dict = None,\n",
    "):\n",
    "    out = {\n",
    "        \"asset_id\": asset_id,\n",
    "        \"asset_type\": asset_type,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"metrics\": {\"valuation_base_k\": round(float(valuation_k), 3)},\n",
    "        \"flags\": {\"anomaly\": anomaly, \"needs_review\": needs_review},\n",
    "        \"model_meta\": {\n",
    "            \"value_model_version\": model_meta.get(\"model_version\"),\n",
    "            \"value_model_name\": model_meta.get(\"model_class\"),\n",
    "        },\n",
    "        \"offchain_refs\": {\"detail_report_hash\": None, \"sensor_batch_hash\": None},\n",
    "    }\n",
    "    if condition_score is not None:\n",
    "        out[\"metrics\"][\"condition_score\"] = round(float(condition_score), 3)\n",
    "    if risk_score is not None:\n",
    "        out[\"metrics\"][\"risk_score\"] = round(float(risk_score), 3)\n",
    "    if extra_metrics:\n",
    "        for k, v in extra_metrics.items():\n",
    "            out[\"metrics\"][k] = float(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "single_output = build_output_schema(\n",
    "    asset_id=\"asset_manual_0001\",\n",
    "    asset_type=ASSET_TYPE,\n",
    "    valuation_k=pred_value,\n",
    "    model_meta=model_meta,\n",
    "    anomaly=anomaly_detected,\n",
    "    needs_review=drift_detected,\n",
    "    extra_metrics={\n",
    "        \"uncertainty\": confidence_output[\"uncertainty\"],\n",
    "        \"confidence_low_k\": confidence_output[\"confidence_interval\"][0],\n",
    "        \"confidence_high_k\": confidence_output[\"confidence_interval\"][1],\n",
    "        \"latency_ms\": latency_ms,\n",
    "    },\n",
    ")\n",
    "\n",
    "single_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fac87-59c9-4c72-8338-3258c69ce606",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 07. Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57917763-5d48-4353-a207-da36aa87e65b",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads a batch of samples and performs inference for each using the same pipeline.\n",
    "\n",
    "### Implementation Details\n",
    "- Iterates over all rows in `sample_batch_properties.csv`\n",
    "- Applies validation and prediction per row\n",
    "- Appends result to a list of outputs\n",
    "\n",
    "### Purpose\n",
    "Scales inference to batch settings, useful for large-scale evaluations or testing.\n",
    "\n",
    "### Output\n",
    "Displays predictions for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fee068f8-37fe-4d6e-9e08-1a27b4ecb5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>valuation_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asset_batch_001</td>\n",
       "      <td>5.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asset_batch_002</td>\n",
       "      <td>5.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asset_batch_003</td>\n",
       "      <td>4.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_batch_004</td>\n",
       "      <td>6.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asset_id  valuation_k\n",
       "0  asset_batch_001        5.382\n",
       "1  asset_batch_002        5.709\n",
       "2  asset_batch_003        4.938\n",
       "3  asset_batch_004        6.011"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_samples = [\n",
    "    sample_property,\n",
    "    {**sample_property, \"location\": \"Rome\", \"size_m2\": 120, \"energy_class\": \"C\"},\n",
    "    {\n",
    "        **sample_property,\n",
    "        \"location\": \"Florence\",\n",
    "        \"size_m2\": 70,\n",
    "        \"has_garden\": 1,\n",
    "        \"energy_class\": \"A\",\n",
    "    },\n",
    "    {**sample_property, \"location\": \"Turin\", \"size_m2\": 150, \"energy_class\": \"D\"},\n",
    "]\n",
    "\n",
    "validated_batch = [validate_input_record(r, strict=True) for r in batch_samples]\n",
    "df_batch = pd.DataFrame(validated_batch)\n",
    "batch_preds = pipeline.predict(df_batch)\n",
    "\n",
    "batch_outputs = [\n",
    "    build_output_schema(\n",
    "        asset_id=f\"asset_batch_{i:03}\",\n",
    "        asset_type=ASSET_TYPE,\n",
    "        valuation_k=float(val),\n",
    "        model_meta=model_meta,\n",
    "    )\n",
    "    for i, val in enumerate(batch_preds, start=1)\n",
    "]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        {\"asset_id\": o[\"asset_id\"], \"valuation_k\": o[\"metrics\"][\"valuation_base_k\"]}\n",
    "        for o in batch_outputs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b30533-6431-4327-8c9a-b781ecd1601f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 08. Logging JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf28d8-985b-450d-a3b5-cd150066a35c",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Logs predictions and system metadata to jsonl files for auditing and monitoring.\n",
    "\n",
    "### Implementation Details\n",
    "- Writes each prediction to `predictions_log.jsonl`\n",
    "- Records model version, latency, uncertainty, anomaly/drift flags to `monitoring_log.jsonl`\n",
    "- Adds `_logged_at` timestamp\n",
    "\n",
    "### Purpose\n",
    "Maintains traceable and time-stamped logs for model monitoring and analysis.\n",
    "\n",
    "### Output\n",
    "Confirmation prints showing successful logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb4b3446-a1ba-4b53-9cd2-83ae069e8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 5 predictions to ..\\data\\predictions_log.jsonl\n",
      "Appended monitoring log: asset_id=asset_manual_0001 | latency=641.45 ms | valuation=5.381800997964413k ±0.0k\n"
     ]
    }
   ],
   "source": [
    "def append_jsonl(record: dict, path: Path):\n",
    "    record = {**record, \"_logged_at\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "\n",
    "# Predictions log\n",
    "append_jsonl(single_output, LOG_PATH)\n",
    "for o in batch_outputs:\n",
    "    append_jsonl(o, LOG_PATH)\n",
    "print(f\"Appended {1 + len(batch_outputs)} predictions to {LOG_PATH}\")\n",
    "\n",
    "# Monitoring log\n",
    "monitoring_entry = {\n",
    "    \"asset_id\": \"asset_manual_0001\",\n",
    "    \"latency_ms\": latency_ms,\n",
    "    \"valuation_k\": pred_value,\n",
    "    \"uncertainty\": uncertainty,\n",
    "    \"confidence_low_k\": conf_interval[0],\n",
    "    \"confidence_high_k\": conf_interval[1],\n",
    "    \"anomaly\": anomaly_detected,\n",
    "    \"drift_detected\": drift_detected,\n",
    "    \"model_version\": model_meta.get(\"model_version\"),\n",
    "    \"model_class\": model_meta.get(\"model_class\"),\n",
    "}\n",
    "\n",
    "append_jsonl(monitoring_entry, Path(\"../data/monitoring_log.jsonl\"))\n",
    "print(\n",
    "    f\"Appended monitoring log: \"\n",
    "    f\"asset_id={monitoring_entry['asset_id']} | \"\n",
    "    f\"latency={monitoring_entry['latency_ms']} ms | \"\n",
    "    f\"valuation={monitoring_entry['valuation_k']}k ±{monitoring_entry['uncertainty']}k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc82054-05e6-4bc5-99a4-46d015820d74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 09. Utility: Single Prediction Function (Reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd3bb2-af78-4313-ae1f-a91acaa713c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Technical Overview\n",
    "Defines a reusable function that encapsulates single prediction logic with validation and formatting.\n",
    "\n",
    "### Implementation Details\n",
    "- Wraps input validation, prediction, uncertainty estimation, and result schema\n",
    "- Returns structured output for any single input\n",
    "\n",
    "### Purpose\n",
    "Facilitates reuse in scripts or APIs with consistent logic.\n",
    "\n",
    "### Output\n",
    "Structured prediction dictionary for given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b190e70-f17f-4b47-beb3-0631ac1a6b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asset_id': 'asset_function_test',\n",
       " 'asset_type': 'property',\n",
       " 'timestamp': '2025-07-22T18:49:59Z',\n",
       " 'metrics': {'valuation_base_k': 5.382},\n",
       " 'flags': {'anomaly': False, 'needs_review': False},\n",
       " 'model_meta': {'value_model_version': 'v1',\n",
       "  'value_model_name': 'LGBMRegressor'},\n",
       " 'offchain_refs': {'detail_report_hash': None, 'sensor_batch_hash': None}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_asset(record: dict, asset_id: str, asset_type: str = ASSET_TYPE):\n",
    "    rec = validate_input_record(record, strict=True)\n",
    "    df_in = pd.DataFrame([rec])\n",
    "    val = float(pipeline.predict(df_in)[0])\n",
    "    return build_output_schema(\n",
    "        asset_id=asset_id, asset_type=asset_type, valuation_k=val, model_meta=model_meta\n",
    "    )\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "test_output = predict_asset(sample_property, asset_id=\"asset_function_test\")\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507a90c-a003-40e6-a97c-d4763895ba1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 10. Sensitivity Check (vary size_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8301cf-4492-4e30-9052-e17ff2f65f57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Technical Overview\n",
    "Performs a sensitivity analysis on the `size_m2` feature to observe its impact on predicted value.\n",
    "\n",
    "#### Implementation Details\n",
    "- Varies `size_m2` across a defined range\n",
    "- Calls prediction function at each step\n",
    "- Plots valuation vs. size\n",
    "\n",
    "#### Purpose\n",
    "Assesses model robustness and feature impact on valuation.\n",
    "\n",
    "#### Output\n",
    "Line plot showing sensitivity trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1622a58-f3cd-47b3-8e5b-efe2cc2eadcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_m2</th>\n",
       "      <th>prediction_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>4.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>5.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>5.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>6.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>6.096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_m2  prediction_k\n",
       "0       60         4.938\n",
       "1       90         5.382\n",
       "2      130         5.891\n",
       "3      170         6.096\n",
       "4      210         6.096"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [60, 90, 130, 170, 210]\n",
    "size_variations = []\n",
    "for s in sizes:\n",
    "    rec = {**sample_property, \"size_m2\": s}\n",
    "    rec = validate_input_record(rec, strict=True)\n",
    "    val = float(pipeline.predict(pd.DataFrame([rec]))[0])\n",
    "    size_variations.append({\"size_m2\": s, \"prediction_k\": round(val, 3)})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "pd.DataFrame(size_variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f9f3e-aaad-4843-a735-1c388f17da55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 11. Compare With API Prediction Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453d2bd-80a0-42c9-9abd-dc6b93ee32c3",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Compares notebook prediction with value returned from the deployed API to ensure consistency.\n",
    "\n",
    "### Implementation Details\n",
    "- Sends `sample_property.json` via HTTP POST\n",
    "- Parses API response and compares keys and values\n",
    "- Computes relative difference\n",
    "\n",
    "### Purpose\n",
    "Ensures model parity across local and deployed environments.\n",
    "\n",
    "### Output\n",
    "Prints match status and difference scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40996a99-ed49-473f-8ddb-74d5d36f932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[API] Compare skipped: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /predict/property (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000200460DE8D0>: Failed to establish a new connection: [WinError 10061] Impossibile stabilire la connessione. Rifiuto persistente del computer di destinazione'))\n"
     ]
    }
   ],
   "source": [
    "if COMPARE_WITH_API:\n",
    "    try:\n",
    "        api_resp = requests.post(\n",
    "            f\"{API_BASE}/predict/{ASSET_TYPE}\", json=sample_property, timeout=5\n",
    "        )\n",
    "        if api_resp.status_code == 200:\n",
    "            api_json = api_resp.json()\n",
    "            api_pred = api_json[\"metrics\"][\"valuation_base_k\"]\n",
    "            delta = abs(api_pred - pred_value)\n",
    "            print(\n",
    "                f\"[API] Pred: {api_pred:.3f} k€ | Local: {pred_value:.3f} k€ | Δ={delta:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"[API] Request failed status={api_resp.status_code} body={api_resp.text}\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"[API] Compare skipped: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb46f5d-8713-442d-a46b-3da6b3f70278",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 12. Hash Pipeline File (Audit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c24d9-2f49-40ef-996d-544ec1ae3fdd",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Generates a hash digest of the model binary for audit and version integrity.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `hashlib.sha256()` on model file\n",
    "- Computes and prints hex digest\n",
    "\n",
    "### Purpose\n",
    "Provides reproducible identifier for the model artifact.\n",
    "\n",
    "### Output\n",
    "Hash value for model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "703b2c48-e21a-441c-a574-e266a542cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file hash (sha256, first 16 chars): a1b31cca9488495b\n"
     ]
    }
   ],
   "source": [
    "def file_sha256(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "print(\"Model file hash (sha256, first 16 chars):\", file_sha256(PIPELINE_PATH)[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19638225-dee1-4d0c-8602-35c3968fc527",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 13. Schema Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461b09c-7b02-4894-bf73-e0222ef92a73",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Validates the model's prediction output (single_output) against a formal JSON Schema definition to ensure full structural and semantic compatibility with downstream systems (e.g., APIs, on-chain consumers).\n",
    "\n",
    "### Implementation Details\n",
    "- Loads the formal schema file from schemas/output_schema_def.json using Path\n",
    "- Applies jsonschema.validate() to enforce structure, data types, and required properties\n",
    "- Optionally compares single_output to output_example.json to detect field-level mismatches\n",
    "\n",
    "### Purpose\n",
    "Guarantees that the inference output complies with the defined data contract and is ready for integration with API responses, validators, and blockchain publishing.\n",
    "\n",
    "### Output\n",
    "Prints a success message if validation passes, or the specific validation error if it fails. Also compares keys with example output and reports any structural mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "96b238ff-5955-404f-9cfd-98330fe62475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Strict schema validation passed.\n",
      "⚠️ Mismatch with example keys: {'_logged_at'}\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "schema_def_path = Path(\"../schemas/output_schema_def.json\")\n",
    "example_path = Path(\"../schemas/output_example.json\")\n",
    "\n",
    "# Load and validate against strict JSON schema\n",
    "if schema_def_path.exists():\n",
    "    with schema_def_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        schema_def = json.load(f)\n",
    "    try:\n",
    "        validate(instance=single_output, schema=schema_def)\n",
    "        print(\"✅ Strict schema validation passed.\")\n",
    "    except ValidationError as e:\n",
    "        print(\"❌ Strict schema validation failed:\", e.message)\n",
    "else:\n",
    "    print(f\"❌ File not found: {schema_def_path}\")\n",
    "\n",
    "# Load and compare against output example structure\n",
    "if example_path.exists():\n",
    "    with example_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        example = json.load(f)\n",
    "\n",
    "    diff_keys = set(single_output.keys()) ^ set(example.keys())\n",
    "    if not diff_keys:\n",
    "        print(\"✅ single_output matches example structure.\")\n",
    "    else:\n",
    "        print(\"⚠️ Mismatch with example keys:\", diff_keys)\n",
    "else:\n",
    "    print(f\"❌ File not found: {example_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68ca6d-044b-49dd-b9c3-9e4d4ee1a98b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 14. Test API via cURL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c1dc3-8190-4469-b3fc-3542f6d9a4f8",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Demonstrates how to invoke the FastAPI inference endpoint locally using a real sample JSON, optionally triggering the publication on the Algorand blockchain (TestNet).\n",
    "\n",
    "### Implementation Details\n",
    "- Method: `requests.post(...)` with `application/json` payload\n",
    "- URL: `http://localhost:8000/predict/property?publish=true`\n",
    "- Input: `../data/sample_property.json` (must match expected schema)\n",
    "- Output: Parsed response with metrics, blockchain TX info, schema validation, etc.\n",
    "- HTTP Errors are caught and printed if any\n",
    "\n",
    "### Purpose\n",
    "To verify the end-to-end API pipeline including model prediction, metadata enrichment, and on-chain publishing, using the same logic served by the FastAPI backend.\n",
    "\n",
    "### Output\n",
    "- Printed prediction response (JSON)\n",
    "- TX hash and ASA ID if `publish=True` and blockchain interaction is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d328f82-13ac-4435-aed0-6265985a67f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Carica il JSON di esempio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sample_path = Path(\u001b[33m\"\u001b[39m\u001b[33m../data/sample_property.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m sample_payload = json.loads(sample_path.read_text())\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Effettua la chiamata all'endpoint FastAPI\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "sample_path = Path(\"../data/sample_property.json\")\n",
    "sample_payload = json.loads(sample_path.read_text())\n",
    "\n",
    "url = \"http://localhost:8000/predict/property?publish=true\"\n",
    "response = requests.post(url, json=sample_payload)\n",
    "\n",
    "if response.ok:\n",
    "    print(\"✅ API Call Success\")\n",
    "    result = response.json()\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(f\"❌ API Call Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d9f7e-77ca-4903-a3f2-ee77f22ffe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
