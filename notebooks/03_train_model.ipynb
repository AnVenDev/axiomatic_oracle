{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8232d9e1-0ad5-492e-b77b-e773aa1fef9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook: 03_train_model.ipynb\n",
    "\n",
    "This notebook trains a regression model to predict property values (`valuation_k`) from the synthetic real estate dataset. It includes preprocessing, data validation, Optuna hyperparameter tuning, LightGBM training, model persistence, and feature importance analysis.\n",
    "\n",
    "## **System Architecture Summary**\n",
    "\n",
    "This notebook represents the core modeling and training phase in the pipeline. It leverages structured training procedures, hyperparameter optimization, and metadata versioning to produce a robust real estate valuation model.\n",
    "\n",
    "**Data Validation & Splitting:**\n",
    "- Train/test and train/valid splits\n",
    "- Overfitting risk management\n",
    "\n",
    "**Preprocessing:**\n",
    "- Categorical encoding and pipeline standardization\n",
    "\n",
    "**Model Training:**\n",
    "- LightGBM + Optuna for tree-based regression\n",
    "- Optimization focused on MAE\n",
    "\n",
    "**Evaluation & Interpretability:**\n",
    "- Test set evaluation\n",
    "- Feature importance diagnostics\n",
    "\n",
    "**Persistence & Audit:**\n",
    "- Trained model and metadata saved\n",
    "- Enables reproducible and explainable predictions\n",
    "\n",
    "This notebook transforms clean tabular data into a fully functional and deployable predictive model with structured tuning and quality controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc119a1-28bd-47af-8a5d-38204c005bdf",
   "metadata": {},
   "source": [
    "## 01. Imports & Dataset Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c68d40-b899-4a88-b370-7ff806df9788",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Initializes environment by importing key libraries and reading the training dataset.\n",
    "\n",
    "### Implementation Details\n",
    "- Libraries: `pandas`, `lightgbm`, `optuna`, `sklearn`, `joblib`, `json`, `os`\n",
    "- Loads data from `property_dataset_v1.csv`\n",
    "- Sets metadata paths and prints loaded shape\n",
    "\n",
    "### Purpose\n",
    "Ensures required packages are available and dataset is loaded for training.\n",
    "\n",
    "### Output\n",
    "Printed shape of dataset; basic confirmation that data load was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba165936-c2d9-4dd5-b388-62912b63f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import joblib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb_optuna\n",
    "import lightgbm as lgb\n",
    "from lightgbm import Dataset as lgbDataset\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "ASSET_TYPE = \"property\"\n",
    "DATA_PATH = \"../data/property_dataset_v1.csv\"\n",
    "MODEL_BASE_DIR = \"../models\"\n",
    "\n",
    "ASSET_CONFIG = {\n",
    "    \"property\": {\n",
    "        \"target\": \"valuation_k\",\n",
    "        \"categorical\": [\n",
    "            \"location\",\n",
    "            \"energy_class\",\n",
    "            \"has_elevator\",\n",
    "            \"has_garden\",\n",
    "            \"has_balcony\",\n",
    "            \"garage\",\n",
    "        ],\n",
    "        \"numeric\": [\n",
    "            \"size_m2\",\n",
    "            \"rooms\",\n",
    "            \"bathrooms\",\n",
    "            \"year_built\",\n",
    "            \"floor\",\n",
    "            \"building_floors\",\n",
    "            \"humidity_level\",\n",
    "            \"temperature_avg\",\n",
    "            \"noise_level\",\n",
    "            \"air_quality_index\",  # base environment\n",
    "            # \"age_years\" sar√† aggiunta se esiste / derivata\n",
    "        ],\n",
    "        \"exclude\": [\n",
    "            \"asset_id\",\n",
    "            \"asset_type\",\n",
    "            \"condition_score\",\n",
    "            \"risk_score\",\n",
    "            \"last_verified_ts\",\n",
    "        ],\n",
    "    },\n",
    "    # Placeholder for future assets\n",
    "    \"art\": {\"target\": \"valuation_k\", \"categorical\": [], \"numeric\": [], \"exclude\": []},\n",
    "}\n",
    "\n",
    "assert ASSET_TYPE in ASSET_CONFIG, f\"Unknown asset_type: {ASSET_TYPE}\"\n",
    "cfg = ASSET_CONFIG[ASSET_TYPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f3f96-b7be-48ff-a9b2-2c9b9569cb63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 02. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c8d4b-ca43-4dc5-9b7b-2bf2cec4705e",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Loads the full dataset, verifies required fields, and prepares the data for training.\n",
    "\n",
    "### Implementation Details\n",
    "- Reads `property_dataset_v1.csv` with `pandas.read_csv`  \n",
    "- Displays sample rows for manual inspection  \n",
    "- Validates presence of critical features (e.g., `valuation_k`, `size_m2`, `location`, `energy_class`)\n",
    "\n",
    "### Purpose\n",
    "Confirms input format and expected content, and ensures the dataset is valid and usable for training.\n",
    "\n",
    "### Output\n",
    "Sample DataFrame preview with confirmed schema and content integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "38892f35-5a7d-488c-83d2-a99bca1e6fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: ../data/property_dataset_v1.csv | shape: (150, 23)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset:\", DATA_PATH, \"| shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c1d08-0b0e-4ed0-bbd9-94c27b0909e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 03. Normalization / Derivations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5387a5-eb72-42d9-9198-bec94aefb437",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Creates derived fields and performs basic normalization where needed.\n",
    "\n",
    "### Implementation Details\n",
    "- May include log-scaling, ratio computation, or transformation of categorical fields\n",
    "\n",
    "### Purpose\n",
    "Prepares feature space for better model interpretability and generalization.\n",
    "\n",
    "### Output\n",
    "DataFrame with added columns (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e773326-72f1-480d-8473-b685af965df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>location</th>\n",
       "      <th>size_m2</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>year_built</th>\n",
       "      <th>age_years</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_floors</th>\n",
       "      <th>...</th>\n",
       "      <th>garage</th>\n",
       "      <th>energy_class</th>\n",
       "      <th>humidity_level</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>air_quality_index</th>\n",
       "      <th>valuation_k</th>\n",
       "      <th>condition_score</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>last_verified_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asset_0000</td>\n",
       "      <td>property</td>\n",
       "      <td>Naples</td>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1964</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>53.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>42</td>\n",
       "      <td>104</td>\n",
       "      <td>348.41</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.140</td>\n",
       "      <td>2025-06-03T09:40:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asset_0001</td>\n",
       "      <td>property</td>\n",
       "      <td>Milan</td>\n",
       "      <td>170</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>69.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>222.10</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.261</td>\n",
       "      <td>2025-07-15T07:09:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asset_0002</td>\n",
       "      <td>property</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>64.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>78.45</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.271</td>\n",
       "      <td>2025-07-05T22:46:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_0003</td>\n",
       "      <td>property</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>47.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>27</td>\n",
       "      <td>76</td>\n",
       "      <td>90.58</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.216</td>\n",
       "      <td>2025-06-29T05:14:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asset_0004</td>\n",
       "      <td>property</td>\n",
       "      <td>Rome</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1955</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>37.4</td>\n",
       "      <td>24.6</td>\n",
       "      <td>45</td>\n",
       "      <td>73</td>\n",
       "      <td>591.70</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.254</td>\n",
       "      <td>2025-06-28T01:45:42Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     asset_id asset_type location  size_m2  rooms  bathrooms  year_built  \\\n",
       "0  asset_0000   property   Naples      142      5          1        1964   \n",
       "1  asset_0001   property    Milan      170      6          2        1979   \n",
       "2  asset_0002   property  Palermo       54      4          3        2013   \n",
       "3  asset_0003   property  Palermo       48      3          1        1951   \n",
       "4  asset_0004   property     Rome      171      3          2        1955   \n",
       "\n",
       "   age_years  floor  building_floors  ...  garage  energy_class  \\\n",
       "0         61      2                7  ...       1             B   \n",
       "1         46      1                9  ...       0             A   \n",
       "2         12      0                3  ...       1             F   \n",
       "3         74      3                7  ...       0             B   \n",
       "4         70      1                5  ...       1             D   \n",
       "\n",
       "   humidity_level  temperature_avg noise_level  air_quality_index  \\\n",
       "0            53.9             17.8          42                104   \n",
       "1            69.7             20.0          77                 51   \n",
       "2            64.4             20.8          28                 68   \n",
       "3            47.6             13.6          27                 76   \n",
       "4            37.4             24.6          45                 73   \n",
       "\n",
       "   valuation_k  condition_score  risk_score      last_verified_ts  \n",
       "0       348.41            0.852       0.140  2025-06-03T09:40:42Z  \n",
       "1       222.10            0.730       0.261  2025-07-15T07:09:42Z  \n",
       "2        78.45            0.742       0.271  2025-07-05T22:46:42Z  \n",
       "3        90.58            0.776       0.216  2025-06-29T05:14:42Z  \n",
       "4       591.70            0.764       0.254  2025-06-28T01:45:42Z  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_year = datetime.utcnow().year\n",
    "if \"year_build\" in df.columns and \"year_built\" not in df.columns:\n",
    "    df = df.rename(columns={\"year_build\": \"year_built\"})\n",
    "\n",
    "if \"age_years\" not in df.columns and \"year_built\" in df.columns:\n",
    "    df[\"age_years\"] = current_year - df[\"year_built\"]\n",
    "\n",
    "# Ensure age_years in numeric list if present\n",
    "if \"age_years\" in df.columns and \"age_years\" not in cfg[\"numeric\"]:\n",
    "    cfg[\"numeric\"].append(\"age_years\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd9da4-99c6-42a0-9bb3-575d54a25cc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04. Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e16e1a-394c-411e-9d05-08612e7f043a",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Performs logical checks to ensure feature-target consistency.\n",
    "\n",
    "### Implementation Details\n",
    "- Range checks, missing values, and valid class inclusion\n",
    "\n",
    "### Purpose\n",
    "Ensure training data quality before modeling.\n",
    "\n",
    "### Output\n",
    "Prints or flags if any validation issues arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "69b68095-70f4-4b5d-ad0d-7b47ba5f9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: valuation_k\n",
      "Categorical: ['location', 'energy_class', 'has_elevator', 'has_garden', 'has_balcony', 'garage']\n",
      "Numeric: ['size_m2', 'rooms', 'bathrooms', 'year_built', 'floor', 'building_floors', 'humidity_level', 'temperature_avg', 'noise_level', 'air_quality_index', 'age_years']\n",
      "Excluded: ['asset_id', 'asset_type', 'condition_score', 'risk_score', 'last_verified_ts']\n",
      "Feature candidates (pre-filter): ['location', 'size_m2', 'rooms', 'bathrooms', 'year_built', 'age_years', 'floor', 'building_floors', 'has_elevator', 'has_garden', 'has_balcony', 'garage', 'energy_class', 'humidity_level', 'temperature_avg', 'noise_level', 'air_quality_index']\n"
     ]
    }
   ],
   "source": [
    "required_base = [cfg[\"target\"]] + cfg[\"categorical\"] + cfg[\"numeric\"]\n",
    "missing = [c for c in required_base if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in dataset: {missing}\")\n",
    "\n",
    "# Remove excluded & target from feature candidates\n",
    "excluded = set(cfg[\"exclude\"] + [cfg[\"target\"]])\n",
    "feature_candidates = [c for c in df.columns if c not in excluded]\n",
    "\n",
    "print(\"Target:\", cfg[\"target\"])\n",
    "print(\"Categorical:\", cfg[\"categorical\"])\n",
    "print(\"Numeric:\", cfg[\"numeric\"])\n",
    "print(\"Excluded:\", cfg[\"exclude\"])\n",
    "print(\"Feature candidates (pre-filter):\", feature_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60aec06-522b-4e18-ad3b-71c1f0e62d1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 05. Overfitting check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adf8cc-badc-419d-a7ec-5da2908d208e",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Evaluates risk of overfitting by exploring baseline distributions or correlations.\n",
    "\n",
    "### Implementation Details\n",
    "- May include stats like target variance or basic model fitting\n",
    "\n",
    "### Purpose\n",
    "Assesses model complexity risk in advance.\n",
    "\n",
    "### Output\n",
    "Initial MAE or distribution range to inform tuning constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3379aac2-ab77-48cc-a77d-693a20d1104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_overfitting_check(pipeline, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "    cv_mae = -cv_scores.mean()\n",
    "\n",
    "    print(f\"\\nüîç OVERFITTING ANALYSIS\")\n",
    "    print(f\"Training MAE: {train_mae:.2f}\")\n",
    "    print(f\"CV MAE:       {cv_mae:.2f}\")\n",
    "    print(f\"Test MAE:     {test_mae:.2f}\")\n",
    "\n",
    "    if train_mae < cv_mae * 0.5:\n",
    "        print(\"‚ùå SEVERE OVERFITTING: Train << CV\")\n",
    "    if test_mae > cv_mae * 2:\n",
    "        print(\"‚ùå POOR GENERALIZATION: Test >> CV\")\n",
    "\n",
    "    return {\"train\": train_mae, \"cv\": cv_mae, \"test\": test_mae}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c915f13-189c-4380-9c72-a30680dfdd1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 06. Final feature list = categorical + numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbb2fc-10d1-4b70-b92f-301128efa57d",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Defines lists of input features by type for preprocessing pipeline.\n",
    "\n",
    "### Implementation Details\n",
    "- Categorical: `location`, `energy_class`\n",
    "- Numeric: `size_m2`, `condition_score`, etc.\n",
    "\n",
    "### Purpose\n",
    "Prepares clear schema for modeling stages.\n",
    "\n",
    "### Output\n",
    "Feature lists printed or stored in variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd171f89-0d87-4a14-b26a-3e39db97ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature_list used: ['location', 'energy_class', 'has_elevator', 'has_garden', 'has_balcony', 'garage', 'size_m2', 'rooms', 'bathrooms', 'year_built', 'floor', 'building_floors', 'humidity_level', 'temperature_avg', 'noise_level', 'air_quality_index', 'age_years']\n"
     ]
    }
   ],
   "source": [
    "feature_list = cfg[\"categorical\"] + cfg[\"numeric\"]\n",
    "print(\"Final feature_list used:\", feature_list)\n",
    "\n",
    "X = df[feature_list].copy()\n",
    "y = df[cfg[\"target\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdc4b9-98c5-43ac-9804-13c954b02c63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 07. Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10318e42-6d65-4a25-b45b-f736e8c88066",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Splits dataset into training and testing sets for model validation.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `train_test_split` from `sklearn.model_selection`\n",
    "- 80/20 or similar ratio with random seed for reproducibility\n",
    "\n",
    "### Purpose\n",
    "Prevents model leakage and allows generalization testing.\n",
    "\n",
    "### Output\n",
    "Two sets: `X_train`, `X_test`, `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db6b742a-3fcc-4633-98df-09ba4c635c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(df[\"valuation_k\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "91aed31d-f657-4b2e-a37a-5bf3a588b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "\n",
    "for col in X_train.select_dtypes(include=\"object\").columns:\n",
    "    all_categories = (\n",
    "        pd.Series(pd.concat([X_train[col], X_test[col]]))\n",
    "        .astype(\"category\")\n",
    "        .cat.categories\n",
    "    )\n",
    "    X_train[col] = X_train[col].astype(\"category\").cat.set_categories(all_categories)\n",
    "    X_test[col] = X_test[col].astype(\"category\").cat.set_categories(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cc11f-e303-48de-92c6-d38c9ec38bf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 08. Tune/valid split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf8023-9ef8-4c21-bcdc-eeb92d3ef973",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Further splits training set into internal train/valid for Optuna tuning.\n",
    "\n",
    "### Implementation Details\n",
    "- Creates `X_train_tune`, `X_valid_tune` subsets\n",
    "- Validation set used inside Optuna objective function\n",
    "\n",
    "### Purpose\n",
    "Supports parameter tuning without leaking into test data.\n",
    "\n",
    "### Output\n",
    "Tuning-specific train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f60248f-1ad5-4421-9376-d0e52ed50990",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_tune, X_valid, y_tune, y_valid = train_test_split(X_train, y_train, test_size=\u001b[32m0.2\u001b[39m, random_state=RANDOM_STATE)\n\u001b[32m      3\u001b[39m dtrain = lgb.Dataset(X_tune, label=y_tune, categorical_feature=[\u001b[33m'\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_class\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m dvalid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=[\u001b[33m'\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_class\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_tune, X_valid, y_tune, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "dtrain = lgb.Dataset(\n",
    "    X_tune, label=y_tune, categorical_feature=[\"location\", \"energy_class\"]\n",
    ")\n",
    "dvalid = lgb.Dataset(\n",
    "    X_valid, label=y_valid, categorical_feature=[\"location\", \"energy_class\"]\n",
    ")\n",
    "\n",
    "# Parametri base di partenza (non ottimizzati)\n",
    "base_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "# Tuning Optuna\n",
    "optuna_result = lgb_optuna.train(\n",
    "    params=base_params,\n",
    "    train_set=dtrain,\n",
    "    valid_sets=[dvalid],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=10),  # ‚Üê pi√π aggressivo\n",
    "        log_evaluation(period=25),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8b0c9-97a8-474b-aac3-e31c9cdb58c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 09. Validate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0dba13-384e-4548-9081-bb148b13ba0a",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Confirms training data integrity post-split.\n",
    "\n",
    "### Implementation Details\n",
    "- Basic printouts, class balance, missing values check\n",
    "\n",
    "### Purpose\n",
    "Final check before training pipeline starts.\n",
    "\n",
    "### Output\n",
    "Basic prints showing data summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe014bd9-acd1-4be4-989a-16455c836842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VALIDATING TRAINING DATA\n",
      "‚úÖ Training data validation passed\n"
     ]
    }
   ],
   "source": [
    "def validate_training_data(X, y):\n",
    "    \"\"\"Validate data quality before training\"\"\"\n",
    "    print(\"üîç VALIDATING TRAINING DATA\")\n",
    "    missing_X = X.isnull().sum()\n",
    "    if missing_X.any():\n",
    "        raise ValueError(f\"Missing values in features:\\\\n{missing_X[missing_X > 0]}\")\n",
    "    if y.std() == 0:\n",
    "        raise ValueError(\"Target variable has zero variance\")\n",
    "    print(\"‚úÖ Training data validation passed\")\n",
    "\n",
    "\n",
    "validate_training_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1f075-89a4-4e49-a30c-2031f17ab419",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 10. Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba989890-27a6-47fd-b675-afca461cfb09",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Builds preprocessing pipeline for categorical encoding and numeric processing.\n",
    "\n",
    "### Implementation Details\n",
    "- One-Hot Encoding for categoricals using `ColumnTransformer`\n",
    "- No scaling for tree-based model\n",
    "\n",
    "### Purpose\n",
    "Creates clean feature matrix aligned with LightGBM input expectations.\n",
    "\n",
    "### Output\n",
    "Fitted `preprocessor` object for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a90328c1-1e44-4551-a9e9-bb18e4a8817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = cfg[\"categorical\"]\n",
    "numeric_cols = cfg[\"numeric\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4618b9bd-e561-4dc2-8702-6485f743f85f",
   "metadata": {},
   "source": [
    "## 11. Optuna & LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9c21c-7db3-4ab4-8d30-013efc14682a",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Tunes LightGBM hyperparameters using Optuna.\n",
    "\n",
    "### Implementation Details\n",
    "- Defines Optuna `objective()` using validation MAE\n",
    "- Explores search space for:\n",
    " - `num_leaves`, `max_depth`, `learning_rate`, `min_child_samples`, `reg_alpha`, `reg_lambda`\n",
    "- Executes trials and saves best params\n",
    "\n",
    "### Purpose\n",
    "Optimizes model for generalization and performance.\n",
    "\n",
    "### Output\n",
    "Best parameter set with validation MAE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1ccbdf0-f566-45e8-be90-8afd54adcfc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:42,936] A new study created in memory with name: no-name-20ac2aea-52f3-4230-bd03-cba1871c2d64\n",
      "[I 2025-07-22 05:53:42,971] Trial 0 finished with value: 0.3044620806960473 and parameters: {'num_leaves': 37, 'max_depth': 9, 'learning_rate': 0.039558317138941854, 'min_child_samples': 26, 'subsample': 0.7286599421150959, 'colsample_bytree': 0.8206448784448872, 'reg_alpha': 0.7157032275682446, 'reg_lambda': 0.8645868451268238}. Best is trial 0 with value: 0.3044620806960473.\n",
      "[I 2025-07-22 05:53:43,013] Trial 1 finished with value: 0.33009361749179966 and parameters: {'num_leaves': 90, 'max_depth': 8, 'learning_rate': 0.05106812741396067, 'min_child_samples': 10, 'subsample': 0.8342468101552619, 'colsample_bytree': 0.8675839388890634, 'reg_alpha': 0.5737954898523215, 'reg_lambda': 0.20679955838987457}. Best is trial 0 with value: 0.3044620806960473.\n",
      "[I 2025-07-22 05:53:43,036] Trial 2 finished with value: 0.31380220137403453 and parameters: {'num_leaves': 78, 'max_depth': 4, 'learning_rate': 0.09193935658954291, 'min_child_samples': 38, 'subsample': 0.7261978584379942, 'colsample_bytree': 0.8262854341755381, 'reg_alpha': 0.4163974045426339, 'reg_lambda': 0.8042648916580305}. Best is trial 0 with value: 0.3044620806960473.\n",
      "[I 2025-07-22 05:53:43,061] Trial 3 finished with value: 0.3266550122150866 and parameters: {'num_leaves': 64, 'max_depth': 10, 'learning_rate': 0.04704625296277968, 'min_child_samples': 27, 'subsample': 0.9276266433660063, 'colsample_bytree': 0.6787716897682526, 'reg_alpha': 0.3839729544561363, 'reg_lambda': 0.47467962442897854}. Best is trial 0 with value: 0.3044620806960473.\n",
      "[I 2025-07-22 05:53:43,085] Trial 4 finished with value: 0.29552201057418404 and parameters: {'num_leaves': 31, 'max_depth': 9, 'learning_rate': 0.07010352744758944, 'min_child_samples': 41, 'subsample': 0.9714811692728788, 'colsample_bytree': 0.721012518498917, 'reg_alpha': 0.20940012663815255, 'reg_lambda': 0.6299028404835283}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,116] Trial 5 finished with value: 0.32083137079538077 and parameters: {'num_leaves': 34, 'max_depth': 5, 'learning_rate': 0.044865143412557956, 'min_child_samples': 12, 'subsample': 0.6159538760820148, 'colsample_bytree': 0.6674270378269467, 'reg_alpha': 0.7433008971290832, 'reg_lambda': 0.451523547482705}. Best is trial 4 with value: 0.29552201057418404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Avvio hyperparameter tuning con Optuna + LightGBM...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[68]\tvalid_0's rmse: 0.304462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's rmse: 0.330094\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 0.313802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[53]\tvalid_0's rmse: 0.326655\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's rmse: 0.295522\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.320831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:43,146] Trial 6 finished with value: 0.30400302332084145 and parameters: {'num_leaves': 38, 'max_depth': 6, 'learning_rate': 0.03061147593427014, 'min_child_samples': 23, 'subsample': 0.7963779834958085, 'colsample_bytree': 0.8918898416100669, 'reg_alpha': 0.732629157507701, 'reg_lambda': 0.16322067309872546}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,169] Trial 7 finished with value: 0.30587877886114434 and parameters: {'num_leaves': 64, 'max_depth': 4, 'learning_rate': 0.0912226301164973, 'min_child_samples': 20, 'subsample': 0.8179450382698401, 'colsample_bytree': 0.7982770061759245, 'reg_alpha': 0.5661992524613584, 'reg_lambda': 0.7928795906794547}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,191] Trial 8 finished with value: 0.31222157348002477 and parameters: {'num_leaves': 82, 'max_depth': 8, 'learning_rate': 0.09131294571808514, 'min_child_samples': 38, 'subsample': 0.6576193436731063, 'colsample_bytree': 0.8455946017016429, 'reg_alpha': 0.11960374894338145, 'reg_lambda': 0.779308814100693}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,216] Trial 9 finished with value: 0.3063096642707741 and parameters: {'num_leaves': 24, 'max_depth': 7, 'learning_rate': 0.09668036589326355, 'min_child_samples': 17, 'subsample': 0.8892686699846788, 'colsample_bytree': 0.9787692508366664, 'reg_alpha': 0.5232349414301414, 'reg_lambda': 0.9365325688469829}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,281] Trial 10 finished with value: 0.3310911207333756 and parameters: {'num_leaves': 53, 'max_depth': 10, 'learning_rate': 0.07120388937324525, 'min_child_samples': 48, 'subsample': 0.9969981490198736, 'colsample_bytree': 0.7330633393967753, 'reg_alpha': 0.024796094552826164, 'reg_lambda': 0.6115531071713417}. Best is trial 4 with value: 0.29552201057418404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.304003\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's rmse: 0.305879\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 0.312222\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's rmse: 0.30631\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[78]\tvalid_0's rmse: 0.331091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:43,352] Trial 11 finished with value: 0.31167942401414855 and parameters: {'num_leaves': 45, 'max_depth': 6, 'learning_rate': 0.014213244205784233, 'min_child_samples': 36, 'subsample': 0.7550464691506262, 'colsample_bytree': 0.9399604268151396, 'reg_alpha': 0.9553543963558491, 'reg_lambda': 0.05465311189276878}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,419] Trial 12 finished with value: 0.3435256859728021 and parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.02137082560896484, 'min_child_samples': 49, 'subsample': 0.9881973010073375, 'colsample_bytree': 0.6152941815466668, 'reg_alpha': 0.23121282353033387, 'reg_lambda': 0.2732333026242829}. Best is trial 4 with value: 0.29552201057418404.\n",
      "[I 2025-07-22 05:53:43,487] Trial 13 finished with value: 0.27997424868973225 and parameters: {'num_leaves': 38, 'max_depth': 3, 'learning_rate': 0.0653573978764749, 'min_child_samples': 31, 'subsample': 0.8824758177258434, 'colsample_bytree': 0.9083933427085294, 'reg_alpha': 0.9428341589347032, 'reg_lambda': 0.6250648660943926}. Best is trial 13 with value: 0.27997424868973225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\tvalid_0's rmse: 0.311679\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.343526\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's rmse: 0.279974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:43,555] Trial 14 finished with value: 0.3069714203908374 and parameters: {'num_leaves': 49, 'max_depth': 3, 'learning_rate': 0.06836965083987845, 'min_child_samples': 33, 'subsample': 0.9104614305183403, 'colsample_bytree': 0.7439845285610837, 'reg_alpha': 0.9369074010374681, 'reg_lambda': 0.6298173783742429}. Best is trial 13 with value: 0.27997424868973225.\n",
      "[I 2025-07-22 05:53:43,624] Trial 15 finished with value: 0.29315065431920895 and parameters: {'num_leaves': 26, 'max_depth': 3, 'learning_rate': 0.06656033906264314, 'min_child_samples': 43, 'subsample': 0.9425340843406955, 'colsample_bytree': 0.7592992837509881, 'reg_alpha': 0.23805844916382912, 'reg_lambda': 0.5987122517679684}. Best is trial 13 with value: 0.27997424868973225.\n",
      "[I 2025-07-22 05:53:43,692] Trial 16 finished with value: 0.29471221343432974 and parameters: {'num_leaves': 27, 'max_depth': 3, 'learning_rate': 0.06142329066967155, 'min_child_samples': 44, 'subsample': 0.8671557920177685, 'colsample_bytree': 0.9295467177617802, 'reg_alpha': 0.36489486546958444, 'reg_lambda': 0.3456232797848094}. Best is trial 13 with value: 0.27997424868973225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's rmse: 0.306971\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tvalid_0's rmse: 0.293151\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.294712\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's rmse: 0.280462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:43,759] Trial 17 finished with value: 0.2804620843391413 and parameters: {'num_leaves': 42, 'max_depth': 4, 'learning_rate': 0.07992248276147704, 'min_child_samples': 30, 'subsample': 0.9469915905019404, 'colsample_bytree': 0.7822572406523027, 'reg_alpha': 0.2574230315501454, 'reg_lambda': 0.5712949393421348}. Best is trial 13 with value: 0.27997424868973225.\n",
      "[I 2025-07-22 05:53:43,825] Trial 18 finished with value: 0.2787179013501493 and parameters: {'num_leaves': 56, 'max_depth': 4, 'learning_rate': 0.08102412204849659, 'min_child_samples': 31, 'subsample': 0.8635293516890639, 'colsample_bytree': 0.9005239377704137, 'reg_alpha': 0.9975168592264588, 'reg_lambda': 0.6998781813653674}. Best is trial 18 with value: 0.2787179013501493.\n",
      "[I 2025-07-22 05:53:43,890] Trial 19 finished with value: 0.2780178256976923 and parameters: {'num_leaves': 57, 'max_depth': 5, 'learning_rate': 0.08206228004287347, 'min_child_samples': 31, 'subsample': 0.8407413590440636, 'colsample_bytree': 0.9980301459539828, 'reg_alpha': 0.8567122136068024, 'reg_lambda': 0.712788998286795}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:43,955] Trial 20 finished with value: 0.30060928536991344 and parameters: {'num_leaves': 71, 'max_depth': 5, 'learning_rate': 0.08114954517656017, 'min_child_samples': 27, 'subsample': 0.784938461715841, 'colsample_bytree': 0.9975215433549571, 'reg_alpha': 0.839967117006205, 'reg_lambda': 0.9959459880839634}. Best is trial 19 with value: 0.2780178256976923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's rmse: 0.278718\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's rmse: 0.278018\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 0.300609\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 0.306672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:44,022] Trial 21 finished with value: 0.306672166160071 and parameters: {'num_leaves': 54, 'max_depth': 5, 'learning_rate': 0.08001522872511428, 'min_child_samples': 33, 'subsample': 0.8479281458614257, 'colsample_bytree': 0.9177860974485732, 'reg_alpha': 0.8612379825710968, 'reg_lambda': 0.7411205600483921}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,096] Trial 22 finished with value: 0.2782675880124469 and parameters: {'num_leaves': 61, 'max_depth': 4, 'learning_rate': 0.058375528814417356, 'min_child_samples': 32, 'subsample': 0.8820176649101189, 'colsample_bytree': 0.9544180031354192, 'reg_alpha': 0.9767548826429602, 'reg_lambda': 0.7038838260603468}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,163] Trial 23 finished with value: 0.3092747775513648 and parameters: {'num_leaves': 58, 'max_depth': 4, 'learning_rate': 0.056894040442701514, 'min_child_samples': 35, 'subsample': 0.8603431148649733, 'colsample_bytree': 0.95740919311814, 'reg_alpha': 0.998887254566721, 'reg_lambda': 0.7077627405157755}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,230] Trial 24 finished with value: 0.3012613497475091 and parameters: {'num_leaves': 70, 'max_depth': 5, 'learning_rate': 0.08393656825941696, 'min_child_samples': 29, 'subsample': 0.8986630772275196, 'colsample_bytree': 0.9706388273521678, 'reg_alpha': 0.8255079453667336, 'reg_lambda': 0.8600407804156119}. Best is trial 19 with value: 0.2780178256976923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 0.278268\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 0.309275\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's rmse: 0.301261\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:44,302] Trial 25 finished with value: 0.30275871253175884 and parameters: {'num_leaves': 62, 'max_depth': 4, 'learning_rate': 0.07555476240090538, 'min_child_samples': 22, 'subsample': 0.8151656458366023, 'colsample_bytree': 0.8852137320355099, 'reg_alpha': 0.6709236174631036, 'reg_lambda': 0.7043163608296983}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,370] Trial 26 finished with value: 0.3048479345672865 and parameters: {'num_leaves': 77, 'max_depth': 5, 'learning_rate': 0.05784849514149448, 'min_child_samples': 33, 'subsample': 0.7750913143854956, 'colsample_bytree': 0.9988485383055329, 'reg_alpha': 0.8818481597314975, 'reg_lambda': 0.47523692853241783}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,441] Trial 27 finished with value: 0.296679819982339 and parameters: {'num_leaves': 69, 'max_depth': 7, 'learning_rate': 0.08641055334317813, 'min_child_samples': 24, 'subsample': 0.8402917197946864, 'colsample_bytree': 0.9566711516195253, 'reg_alpha': 0.9988414459666215, 'reg_lambda': 0.8886232100297711}. Best is trial 19 with value: 0.2780178256976923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's rmse: 0.302759\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's rmse: 0.304848\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's rmse: 0.29668\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 05:53:44,516] Trial 28 finished with value: 0.3042254110191455 and parameters: {'num_leaves': 56, 'max_depth': 4, 'learning_rate': 0.03851143865459168, 'min_child_samples': 20, 'subsample': 0.9140696672294315, 'colsample_bytree': 0.8676735484105902, 'reg_alpha': 0.8023992526392951, 'reg_lambda': 0.3773720196791857}. Best is trial 19 with value: 0.2780178256976923.\n",
      "[I 2025-07-22 05:53:44,586] Trial 29 finished with value: 0.3000926297099919 and parameters: {'num_leaves': 47, 'max_depth': 6, 'learning_rate': 0.07532739342614014, 'min_child_samples': 26, 'subsample': 0.7044549253796116, 'colsample_bytree': 0.9466165139783278, 'reg_alpha': 0.6889166003605507, 'reg_lambda': 0.5360776869115752}. Best is trial 19 with value: 0.2780178256976923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[74]\tvalid_0's rmse: 0.304225\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's rmse: 0.300093\n",
      "‚úÖ Migliori parametri trovati: {'num_leaves': 57, 'max_depth': 5, 'learning_rate': 0.08206228004287347, 'min_child_samples': 31, 'subsample': 0.8407413590440636, 'colsample_bytree': 0.9980301459539828, 'reg_alpha': 0.8567122136068024, 'reg_lambda': 0.712788998286795, 'objective': 'regression', 'metric': 'rmse', 'boosting_type': 'gbdt', 'verbosity': -1, 'force_col_wise': True, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Converti i dati in Dataset LightGBM\n",
    "dtrain = lgb.Dataset(\n",
    "    X_train, label=y_train, categorical_feature=[\"location\", \"energy_class\"]\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"seed\": RANDOM_STATE,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1.0),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # Per garantire compatibilit√† massima, evitiamo 'early_stopping_rounds' direttamente\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)],\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # Calcolo manuale dell'RMSE per compatibilit√† massima\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(\"üîç Avvio hyperparameter tuning con Optuna + LightGBM...\")\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30, timeout=600)\n",
    "\n",
    "# Migliori parametri\n",
    "best_params = study.best_params\n",
    "best_params.update(\n",
    "    {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"force_col_wise\": True,\n",
    "        \"n_estimators\": 1000,\n",
    "    }\n",
    ")\n",
    "print(f\"‚úÖ Migliori parametri trovati: {best_params}\")\n",
    "\n",
    "regressor = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "# Ricostruisci il pipeline con i nuovi parametri\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "21ae9235-4192-47c4-98ec-8b6362ed1d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cross-Validation MAE: 0.29 ¬± 0.03\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, module=\"sklearn.utils.validation\"\n",
    ")\n",
    "\n",
    "# Cross-validation su tutto il training set (escludendo test set!)\n",
    "cv_scores = cross_val_score(\n",
    "    pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    ")\n",
    "\n",
    "cv_mae = -cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "print(f\"‚úÖ Cross-Validation MAE: {cv_mae:.2f} ¬± {cv_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc1d70-e1f4-48ce-ac17-2592e450c444",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 12. Fit, Eval, Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7c685-ef21-4a80-8432-48eb596396db",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Fits LightGBM on full training data using best Optuna parameters.\n",
    "\n",
    "### Implementation Details\n",
    "- Trains with `LGBMRegressor`\n",
    "- Evaluates on test set (`X_test`, `y_test`)\n",
    "- Saves model with `joblib.dump`\n",
    "\n",
    "### Purpose\n",
    "Builds final predictive model for deployment.\n",
    "\n",
    "### Output\n",
    "Trained model object and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7c1bc313-6854-4dff-bd07-acd9dbf857bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç OVERFITTING ANALYSIS\n",
      "Training MAE: 0.20\n",
      "CV MAE:       0.29\n",
      "Test MAE:     0.23\n",
      "üìä MAE:  66.12 k‚Ç¨\n",
      "üìä RMSE: 86.81 k‚Ç¨\n",
      "üìä R¬≤:   0.54\n",
      "\n",
      "‚úÖ Fine training e valutazione modello ottimizzato LightGBM con Optuna\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, module=\"sklearn.utils.validation\"\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "comprehensive_overfitting_check(pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "y_pred_log = pipeline.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_true = np.expm1(y_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_true, y_pred)\n",
    "mse = mean_squared_error(y_test_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_true, y_pred)\n",
    "\n",
    "print(f\"üìä MAE:  {mae:.2f} k‚Ç¨\")\n",
    "print(f\"üìä RMSE: {rmse:.2f} k‚Ç¨\")\n",
    "print(f\"üìä R¬≤:   {r2:.2f}\")\n",
    "print(f\"\\n‚úÖ Fine training e valutazione modello ottimizzato LightGBM con Optuna\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7e416-e4b5-493f-86d4-30f9b02de1b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 13. Feature importance (only for tree model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39260e61-f902-4209-b388-d52cf97786f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Technical Overview\n",
    "Computes and visualizes feature importances from trained model.\n",
    "\n",
    "### Implementation Details\n",
    "- Uses `.feature_importances_` from `LGBMRegressor`\n",
    "- Displays barplot of importance scores\n",
    "\n",
    "### Purpose\n",
    "Interpret model behavior and highlight predictive features.\n",
    "\n",
    "### Output\n",
    "Plot of top features with relative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f2bb987e-dafa-4842-9b9c-aefe4593cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Top 10 Feature Importances (by gain):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>size_m2</td>\n",
       "      <td>161.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_quality_index</td>\n",
       "      <td>2.760065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temperature_avg</td>\n",
       "      <td>2.713822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>1.978242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humidity_level</td>\n",
       "      <td>1.675291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>floor</td>\n",
       "      <td>0.785118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>building_floors</td>\n",
       "      <td>0.464668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>noise_level</td>\n",
       "      <td>0.390045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>garage_0</td>\n",
       "      <td>0.147675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age_years</td>\n",
       "      <td>0.130961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "0            size_m2  161.773600\n",
       "1  air_quality_index    2.760065\n",
       "2    temperature_avg    2.713822\n",
       "3          bathrooms    1.978242\n",
       "4     humidity_level    1.675291\n",
       "5              floor    0.785118\n",
       "6    building_floors    0.464668\n",
       "7        noise_level    0.390045\n",
       "8           garage_0    0.147675\n",
       "9          age_years    0.130961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Aggregated Importance of Categorical Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregated_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>garage</th>\n",
       "      <td>0.147675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy_class</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_elevator</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_garden</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_balcony</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              aggregated_importance\n",
       "garage                     0.147675\n",
       "location                   0.000000\n",
       "energy_class               0.000000\n",
       "has_elevator               0.000000\n",
       "has_garden                 0.000000\n",
       "has_balcony                0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estrai i nomi delle feature codificate (OHE) + numeriche\n",
    "ohe = pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "encoded_cat_features = list(ohe.get_feature_names_out(categorical_cols))\n",
    "encoded_feature_names = encoded_cat_features + numeric_cols\n",
    "\n",
    "# Estrai modello finale (LightGBM dentro Pipeline)\n",
    "lgb_model = pipeline.named_steps[\"regressor\"]\n",
    "\n",
    "# Calcola importanza feature con 'gain' (pi√π robusto di 'split')\n",
    "importances = lgb_model.booster_.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "# Costruisci dataframe ordinato\n",
    "feat_importance = (\n",
    "    pd.DataFrame({\"feature\": encoded_feature_names, \"importance\": importances})\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Top 10 Feature Importances (by gain):\")\n",
    "display(feat_importance.head(10))\n",
    "\n",
    "\n",
    "# Funzione per aggregare l'importanza delle feature OHE per colonna categorica originale\n",
    "def get_categorical_importance_summary(feat_importance, categorical_cols):\n",
    "    cat_importance = {}\n",
    "    for cat_col in categorical_cols:\n",
    "        cat_features = [\n",
    "            f for f in feat_importance[\"feature\"] if f.startswith(f\"{cat_col}_\")\n",
    "        ]\n",
    "        total = feat_importance[feat_importance[\"feature\"].isin(cat_features)][\n",
    "            \"importance\"\n",
    "        ].sum()\n",
    "        cat_importance[cat_col] = total\n",
    "    return cat_importance\n",
    "\n",
    "\n",
    "# Calcolo importanza aggregata delle variabili categoriche originali\n",
    "cat_importance_summary = get_categorical_importance_summary(\n",
    "    feat_importance, categorical_cols\n",
    ")\n",
    "\n",
    "# Ordina per importanza decrescente e mostra\n",
    "cat_importance_df = pd.DataFrame.from_dict(\n",
    "    cat_importance_summary, orient=\"index\", columns=[\"aggregated_importance\"]\n",
    ").sort_values(\"aggregated_importance\", ascending=False)\n",
    "\n",
    "print(\"\\nüìä Aggregated Importance of Categorical Features:\")\n",
    "display(cat_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c11449-9757-42a3-942b-e91ead0c922c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 14. Save model & metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b7b26-9b86-4f3d-9b44-e4baa4cb1481",
   "metadata": {},
   "source": [
    "### Technical Overview\n",
    "Saves final model and associated metadata for inference usage.\n",
    "\n",
    "### Implementation Details\n",
    "- Exports model with `joblib`\n",
    "- Saves JSON metadata with model version, feature list, and training config\n",
    "\n",
    "### Purpose\n",
    "Enables downstream inference and auditability.\n",
    "\n",
    "### Output\n",
    "`value_regressor_v1.joblib`, `value_regressor_v1_meta.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0b2e3e4f-8e12-4028-a0c6-de17ea9fc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved pipeline: ../models/property/value_regressor_v1.joblib\n",
      "‚úÖ Saved metadata: ../models/property/value_regressor_v1_meta.json\n"
     ]
    }
   ],
   "source": [
    "# Create model directory\n",
    "os.makedirs(f\"{MODEL_BASE_DIR}/{ASSET_TYPE}\", exist_ok=True)\n",
    "model_version = \"v1\"\n",
    "\n",
    "# Save pipeline\n",
    "pipeline_filename = (\n",
    "    f\"{MODEL_BASE_DIR}/{ASSET_TYPE}/value_regressor_{model_version}.joblib\"\n",
    ")\n",
    "joblib.dump(pipeline, pipeline_filename)\n",
    "\n",
    "# Calculate dataset hash\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    dataset_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "\n",
    "# Feature names\n",
    "ohe = pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "encoded_cat_features = list(ohe.get_feature_names_out(categorical_cols))\n",
    "encoded_feature_names = numeric_cols + encoded_cat_features\n",
    "\n",
    "# Build metadata\n",
    "metadata = {\n",
    "    \"asset_type\": ASSET_TYPE,\n",
    "    \"model_task\": \"valuation_regression\",\n",
    "    \"model_version\": model_version,\n",
    "    \"model_class\": type(pipeline.named_steps[\"regressor\"]).__name__,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"dataset_file\": DATA_PATH,\n",
    "    \"dataset_hash_sha256\": dataset_hash,\n",
    "    \"n_rows_total\": int(len(df)),\n",
    "    \"n_rows_train\": int(len(X_train)),\n",
    "    \"n_rows_test\": int(len(X_test)),\n",
    "    \"features_categorical\": categorical_cols,\n",
    "    \"features_numeric\": numeric_cols,\n",
    "    \"feature_list_ordered\": feature_list,\n",
    "    \"features_encoded\": encoded_feature_names,\n",
    "    \"encoded_feature_count\": len(encoded_feature_names),\n",
    "    \"metrics\": {\n",
    "        \"mae_k\": float(round(mae, 4)),\n",
    "        \"rmse_k\": float(round(rmse, 4)),\n",
    "        \"r2\": float(round(r2, 4)),\n",
    "    },\n",
    "    \"feature_importance_top10\": feat_importance.head(10).to_dict(orient=\"records\"),\n",
    "    \"best_params\": best_params,\n",
    "    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "}\n",
    "\n",
    "# Save metadata to JSON\n",
    "meta_filename = (\n",
    "    f\"{MODEL_BASE_DIR}/{ASSET_TYPE}/value_regressor_{model_version}_meta.json\"\n",
    ")\n",
    "with open(meta_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Logs\n",
    "print(f\"‚úÖ Saved pipeline: {pipeline_filename}\")\n",
    "print(f\"‚úÖ Saved metadata: {meta_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
